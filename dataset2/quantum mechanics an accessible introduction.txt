An Accessible Introduction
QUANTUM MECHANICS
Second EditionThis page intentionally left blankNEW JERSEY • LONDON • SINGAPORE • BEIJING • SHANGHAI • HONG KONG • TAIPEI • CHENNAI • TOKYO
An Accessible Introduction
QUANTUM MECHANICS
Second Edition
Robert Scherrer
Vanderbilt University, USAPublished by
World Scientific Publishing Co. Pte. Ltd.
5 Toh Tuck Link, Singapore 596224
USA office: 27 Warren Street, Suite 401-402, Hackensack, NJ 07601
UK office: 57 Shelton Street, Covent Garden, London WC2H 9HE
Library of Congress Control Number: 2023947989
British Library Cataloguing-in-Publication Data
A catalogue record for this book is available from the British Library.
This book was previously published by Pearson Education, Inc.
QUANTUM MECHANICS
An Accessible Introduction
Second Edition
Copyright © 2024 by World Scientific Publishing Co. Pte. Ltd. 
All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means, 
electronic or mechanical, including photocopying, recording or any information storage and retrieval 
system now known or to be invented, without written permission from the publisher.
For photocopying of material in this volume, please pay a copying fee through the Copyright Clearance 
Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy 
is not required from the publisher.
ISBN 978-981-12-8665-0 (hardcover)
ISBN 978-981-12-8729-9 (paperback)
ISBN 978-981-12-8673-5 (ebook for institutions)
ISBN 978-981-12-8674-2 (ebook for individuals)
For any available supplementary material, please visit 
https://www.worldscientific.com/worldscibooks/10.1142/13687#t=suppl
Desk Editor: Carmen Teo Bin Jie 
Printed in SingaporeTo Elizabeth, who missed the first editionThis page intentionally left blankPreface
For the Instructor
The world is full of quantum mechanics textbooks. Does it really need
another one? This book is designed to be an “accessible introduction” to
quantum mechanics, suitable for students with a wide range of abilities
and backgrounds. It grew out of a quantum mechanics course that I taught
at Ohio State University. The chief problem I encountered in teaching
this course was the enormous diversity of the student body, ranging from
students headed toward careers as academic physicists to students who
had never encountered the basic properties of complex numbers. Teaching
students with such a wide range of abilities is a fundamental challenge, and
it is to this challenge that this book is addressed. It assumes very little
knowledge or mathematical background on the part of the students as it
takes them through the major topics of quantum mechanics.
Much of the trouble that students encounter in their study of quantum
mechanics centers around mathematics. A strong facility with complex
numbers is required; although most of this material is at the level of high￾school algebra, many students have forgotten it by the time they take a
quantum mechanics course. Similarly, linear algebra is normally a prereq￾uisite for any course in quantum mechanics. Often a single course in linear
algebra is more than adequate preparation, but sometimes such courses
spend weeks on matrix manipulation and linear equations, neglecting the
more abstract elements of linear algebra that are necessary to fully under￾stand quantum mechanics.
This book, therefore, contains three “math interludes” (Chapters 2, 5,
and 7) which develop the mathematics needed in the book. Physicists
have a long tradition of teaching mathematics in their courses; these math
viiviii Quantum Mechanics: An Accessible Introduction
interludes simply formalize that tradition. In presenting this material, I
have avoided formal proofs. Instead, my approach has been to present an
intuitive motivation and then simply state the relevant results. This allows
a large amount of mathematics to be presented compactly. Instructors of
students with a stronger math background can simply skip this material,
while others will want to go over it in detail.
This book takes a similar approach to many of the physics topics, as￾suming almost no initial knowledge on the part of the student and providing
detailed motivation and explanation before launching into the calculations.
Unlike many other areas of physics, it is difficult to develop intuition re￾garding the phenomena of quantum mechanics, so I have made free use of
classical analogies to help the student get a better understanding of what
is happening. I have pushed some of these analogies into a regime in which
classical physics clearly does not apply; but quantum mechanics began as
an outgrowth of classical mechanics, so it does no service to the student
to treat quantum mechanics as though it popped spontaneously out of the
vacuum with no connection to classical physics.
The one area in which I have neglected detailed explanations is the
first topic of this book: blackbody radiation. A rigorous treatment of
this subject requires a knowledge of statistical physics that students often
acquire later than their study of quantum mechanics. Rather than attempt
a one-chapter course in statistical physics, the necessary results are simply
stated without proof. These results are, in any case, used nowhere else in
the book.
With regard to the content of the book, I have omitted one topic which is
often considered standard in undergraduate quantum mechanics textbooks:
degenerate perturbation theory. Experience has taught me that students
rarely grasp this topic during their first exposure to quantum mechanics,
so their time in a first course is better spent in getting a firm grasp of
nondegenerate perturbation theory. I conclude the book with an elementary
introduction to relativistic quantum mechanics. This material is beyond
the scope of most standard texts, but it is always of interest to the more
advanced students, and it represents the next step in their study of quantum
physics.
This book is intended for a standard, full-year, first course in quan￾tum mechanics. A one-semester treatment should bring students through
the end of Chapter 8, allowing a discussion of spins and concluding with
the interesting topic of measurement theory. With the inclusion of the
math interlude chapters, the mathematical background assumed is a goodPreface ix
knowledge of calculus and a rudimentary exposure to differential equations.
All of the more difficult integrals (both indefinite and definite) in the text
and in the end-of-chapter problems can be found in a standard table of
integrals or derived using Mathematica or an equivalent program. The re￾quired physics background is a standard, first-year sequence in mechanics
and electromagnetism. The first chapter will be a review for students with
a previous course in modern physics, but it will be useful for most students.
A flowchart of the prerequisite structure of the book is given here, where
I have indicated the math interlude chapters as circles and the other chap￾ters as squares. This diagram shows that the first part of the book is
organized in a linear fashion, while the second part allows more freedom
for the instructor to pick and choose chapters of greatest interest.
1 3 4 6 8
2 5 7
15 10 13 14 12
9 11
I have used MKS units throughout the book, particularly in the equa￾tions for electromagnetism. Although this often makes the derivations
clumsier, the use of MKS units has become standard throughout the un￾dergraduate curriculum, and it only confuses students to study electromag￾netism with one set of equations, and then to see a different set appear in
quantum mechanics. While I have sometimes introduced different units in
the book (eV, ˚A, etc.), the basic equations in the text are all in MKS units.
I would like to thank my colleagues at Ohio State University, where this
project was begun, and at Vanderbilt University, where it was completed.
Among the latter, I owe particular thanks to John Gore of the Vander￾bilt University Institute of Imaging Science for his insights into magnetic
resonance imaging and to Donald Pickert for administrative assistance. I
am also grateful to my own undergraduate (1979–80) quantum mechan￾ics instructor, P.J.E. Peebles of Princeton University, for first piquing myx Quantum Mechanics: An Accessible Introduction
interest in this subject. And of course, thanks to my wife Sarah for putting
up with my many late nights editing at the kitchen table.
Robert Scherrer
Nashville, Tennessee
2005
Notes on the Second Edition
Like all first editions, this one contained errors, typos, and omissions that
colleagues were kind enough to point out to me over the years. I have
attempted to correct all of the errors and have added sections that were
requested by various instructors, particularly the Heisenberg uncertainty
principle and the use of ladder operators to solve the harmonic oscillator.
Otherwise, the changes to the first edition are relatively minor.
Robert Scherrer
Nashville, Tennessee
2023Preface xi
For the Student
Quantum mechanics is the gateway to modern physics. By the time most
undergraduates come to quantum mechanics, they have spent one year, or
possibly two, on the intricacies of classical physics. But classical mechanics
is nearly 400 years old, and classical electromagnetism is more than 100
years old; most students do not decide to study physics because of a deep￾rooted interest in blocks sliding down inclined planes. Instead, they go into
this field because of the exciting modern developments: subatomic particles,
cosmology, and all of the other exotic discoveries and theories that physics
has produced over the past few decades.
Quantum mechanics provides the foundation for all of these subjects.
Atomic, nuclear, and particle physics are all based on quantum mechanics,
as is condensed matter physics. Indeed, the story of 20th century physics is,
to a large extent, the story of quantum mechanics and its various offshoots.
While this book will not venture into all of these subjects, it will provide
the basis for understanding the ideas underlying all of them.
Quantum mechanics requires a radical shift in the way that we view re￾ality, and this is a shift that some students find troublesome. Furthermore,
unlike classical mechanics, the results of quantum mechanics frequently run
counter to our own physical intuition. Because of these issues, I have at￾tempted to provide plenty of motivation throughout the book, as well as
to make extensive use of analogies with classical physics where possible.
Of course, these analogies have their own limitations; much of quantum
mechanics runs counter to our experience of how the world behaves at the
macroscopic level, and no explanation or analogy can make it conform to
classical ideas. On the other hand, it is precisely the more bizarre aspects
of quantum mechanics which make it such a fascinating subject.
Quantum mechanics uses several areas of mathematics that are not
frequently encountered in classical mechanics or electromagnetism. In
particular, complex numbers are central to the mathematics of quantum
mechanics, as is the branch of mathematics called linear algebra; the latter
is a generalization of our familiar ideas of vectors into the realm of abstract
“vector spaces.” Because much of this mathematics may be unfamiliar, I
have included three chapters (2, 5, and 7) which develop all of the necessary
mathematical machinery. In these chapters, I have tried to avoid formal
proofs and have presented just the essential results. A previous course in
linear algebra is certainly helpful, but it is not required for using this book.xii Quantum Mechanics: An Accessible Introduction
On the other hand, a good knowledge of calculus is essential. Note,
however, that many of the more complicated integrals in this book can be
found in standard tables of integrals, and I have assumed that they will
be solved that way. (Practicing physicists rarely perform more than the
most elementary integrals “by hand”; they look them up or use a program
like Mathematica. This is akin to using a calculator instead of a pencil
to do arithmetical calculations.) While I have also assumed at least a
rudimentary exposure to differential equations, the solutions for all of the
differential equations encountered in this book are derived in the book itself.
In terms of physics prerequisites, this book assumes at least a standard,
first-year, one-semester course in classical mechanics and a one-semester
course in electricity and magnetism. Most of the applications of quantum
mechanics presented in this book are at the atomic level, where the primary
interactions of interest are electromagnetic (e.g., the attraction between
the proton and electron in the hydrogen atom and the multiple magnetic
interactions in hydrogen). A prior introduction to modern physics is not
essential; the first chapter covers much of this material in condensed form.
This book is an “accessible introduction.” In other words, it starts
at the very beginning, but it progresses through all of the major ideas of
quantum mechanics. In making the book accessible, I have tried to provide
the maximum amount of explanation, leaving out as few intermediate steps
in derivations as possible. Most of all, I have attempted to convey some of
the fun and bizarreness of this subject, which revolutionized physics and
fundamentally changed our views of physical reality. A student completing
this book will develop a good grasp of many of the most important ideas
developed by physicists in the first half of the 20th century, laying the
groundwork for understanding much of modern physics.Contents
Preface vii
1. The origins of quantum mechanics 1
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Blackbody Radiation . . . . . . . . . . . . . . . . . . . . . 3
1.3 The Nature of Light . . . . . . . . . . . . . . . . . . . . . 11
1.4 The Wave Nature of Matter . . . . . . . . . . . . . . . . . 17
1.5 The Bohr Atom . . . . . . . . . . . . . . . . . . . . . . . . 19
1.6 Where Do We Stand? . . . . . . . . . . . . . . . . . . . . 22
2. Math interlude A: Complex numbers and linear operators 27
2.1 Complex Numbers . . . . . . . . . . . . . . . . . . . . . . 27
2.2 Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3. The Schr¨odinger equation 41
3.1 Derivation of the Schr¨odinger Equation . . . . . . . . . . . 42
3.2 The Meaning of the Wave Function . . . . . . . . . . . . . 51
3.3 The Time-Independent Schr¨odinger Equation: Qualitative
Solutions and the Origin of Quantization . . . . . . . . . . 58
4. Solutions of the one-dimensional time-independent
Schr¨odinger equation 71
4.1 Unbound States: Scattering and Tunneling . . . . . . . . 72
4.2 Bound Systems . . . . . . . . . . . . . . . . . . . . . . . . 88
xiiixiv Quantum Mechanics: An Accessible Introduction
5. Math interlude B: Linear algebra 107
5.1 Properties of Linear Operators . . . . . . . . . . . . . . . 107
5.2 Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . 112
6. Solutions of the three-dimensional time-independent
Schr¨odinger equation 125
6.1 Solution in Rectangular Coordinates . . . . . . . . . . . . 126
6.2 Angular Momentum . . . . . . . . . . . . . . . . . . . . . 129
6.3 The Schr¨odinger Equation in Spherical Coordinates . . . . 141
6.4 The Hydrogen Atom . . . . . . . . . . . . . . . . . . . . . 149
7. Math interlude C: Matrices, Dirac notation, and the
Dirac delta function 163
7.1 The Matrix Formulation of Linear Operators . . . . . . . 163
7.2 Dirac Notation . . . . . . . . . . . . . . . . . . . . . . . . 170
7.3 The Dirac Delta Function . . . . . . . . . . . . . . . . . . 172
8. Spin angular momentum 179
8.1 Spin Operators . . . . . . . . . . . . . . . . . . . . . . . . 179
8.2 Evidence for Spin . . . . . . . . . . . . . . . . . . . . . . . 180
8.3 Adding Angular Momentum . . . . . . . . . . . . . . . . . 185
8.4 The Matrix Representation of Spin . . . . . . . . . . . . . 187
8.5 The Stern–Gerlach Experiment . . . . . . . . . . . . . . . 194
8.6 Spin Precession . . . . . . . . . . . . . . . . . . . . . . . . 197
8.7 Spin Systems with Two Particles . . . . . . . . . . . . . . 202
8.8 Measurement Theory . . . . . . . . . . . . . . . . . . . . . 208
9. Time-independent perturbation theory 219
9.1 Derivation of Time-Independent Perturbation Theory . . . 220
9.2 Perturbations to the Atomic Energy Levels . . . . . . . . 229
9.3 The Atom in External Electric or Magnetic Fields . . . . 239
10. The variational principle 251
10.1 Variational Principle: Theory . . . . . . . . . . . . . . . . 252
10.2 Variational Principle: Application to the Helium Atom . . 256Contents xv
11. Time-dependent perturbation theory 265
11.1 Derivation of Time-Dependent Perturbation Theory . . . 266
11.2 Application: Selection Rules for Electromagnetic Radiation 276
12. Scattering theory 287
12.1 Definition of the Cross Section . . . . . . . . . . . . . . . 287
12.2 The Born Approximation . . . . . . . . . . . . . . . . . . 292
12.3 Partial Waves . . . . . . . . . . . . . . . . . . . . . . . . . 303
13. Multiparticle Schr¨odinger equation 313
13.1 Wave Function for Identical Particles . . . . . . . . . . . . 313
13.2 Multielectron Atoms . . . . . . . . . . . . . . . . . . . . . 326
14. Modern applications of quantum mechanics 339
14.1 Magnetic Resonance Imaging . . . . . . . . . . . . . . . . 339
14.2 Quantum Computing . . . . . . . . . . . . . . . . . . . . . 344
15. Relativistic quantum mechanics 351
15.1 The Klein–Gordon Equation . . . . . . . . . . . . . . . . . 351
15.2 The Dirac Equation . . . . . . . . . . . . . . . . . . . . . 355
Index 363This page intentionally left blankChapter 1
The origins of quantum mechanics
1.1 Introduction
The story of the development of quantum mechanics has attained mythic
stature in the history of physics. By the turn of the 20th century (c. 1900),
physics encompassed the fields of classical mechanics, electricity and mag￾netism, and thermodynamics, a set of subjects now known collectively as
“classical physics.” Indeed, with a few minor exceptions, the concepts of
classical physics seemed capable of explaining all known physical phenom￾ena. In a few decades, this entire framework would be superseded by the
development of quantum mechanics. The importance of this development
can hardly be exaggerated. The term “modern physics” is practically a
synonym for the areas of physics which grew out of quantum mechanics:
atomic physics, nuclear physics, particle physics, and condensed matter
physics.
The predictions of quantum mechanics are rather bizarre from a classical
point of view. Consider the following propositions, which are all postulates
of classical physics:
1. The physical universe is deterministic, i.e., given enough informa￾tion about a physical system, its future evolution can be predicted
exactly. Who would dispute this obvious point? The entire func￾tion of classical mechanics is to derive such predictions.
2. Light consists of waves, while ordinary matter is composed of par￾ticles. The former statement is one of the triumphs of classical
electromagnetism, while the latter seems self-evident.
12 Quantum Mechanics: An Accessible Introduction
3. Physical quantities, such as energy and angular momentum, can
be treated as continuous variables. Again, this assumption is built
into the structure of classical mechanics.
4. There exists an objective physical reality independent of any ob￾server. If a tree falls in the woods, of course it makes a sound.
All of these ideas seem obvious. In fact, we know from quantum mechanics
that none of them is completely accurate:
1. The physical universe is not deterministic. At the subatomic level,
we can assign probabilities to the outcomes of certain experiments
but never predict the exact result with certainty. Uncertainty is an
intrinsic property of matter at this scale.
2. Both light and matter exhibit behavior that seems characteristic
of both particles and waves.
3. Under certain circumstances, some physical quantities are quan￾tized, i.e., they can take on only certain discrete values.
4. Finally, it appears that the observer always affects the experiment;
it is impossible to disentangle the two.
Why would anyone believe such a preposterous set of ideas? For the
only reason that any theory in physics is given credence: because it works.
Quantum mechanics allows us to explain physical phenomena, primarily
at very small length scales, for which classical physics simply offers no ex￾planation. Physicists in the first half of the 20th century were themselves
often hesitant to accept many of the more bizarre consequences of quan￾tum mechanics, but the theory ultimately prevailed because it agreed with
experiment.
Because quantum mechanics is so counterintuitive, so strange in many of
its predictions, we will begin by examining some of the experiments which
led to its birth. In each of the experiments examined below, physicists
had developed a classical theory which failed to correctly account for the
experimental results. These experiments led to the idea that light could
behave as both a particle and a wave and then to the more radical suggestion
that matter also had both particle and wave properties. These ideas set
the stage for the development of quantum mechanics.The origins of quantum mechanics 3
1.2 Blackbody Radiation
It is one of the ironies of physics that the greatest discoveries often occur in
the areas where one would least expect to find them. This is particularly
true of quantum mechanics, whose origins are often traced back to perhaps
the least glamorous subject in all of physics: thermodynamics. Specifically,
quantum mechanics was launched by a solution to a nagging problem in
thermodynamics: the behavior of blackbody radiation. Although the so￾lution to this problem is not the most compelling argument for quantum
mechanics, it is of such historical importance that we examine it in some
detail.
The problem with blackbody radiation
Blackbody radiation seems like a contradiction: objects are black precisely
because they absorb radiation, so how can a blackbody be said to emit
radiation? The confusion arises because there are two different ways that
we can detect radiation from an object: it can reflect light, or it can emit
light from its own internal energy. Almost all objects in our everyday
environment give off visible light by reflection, and it is in this sense that
a black object absorbs everything and reflects nothing. However, we are
interested in the second case, the emission of radiation from an object’s
internal energy. When objects are heated to a high enough temperature,
they emit visible light. Familiar examples include the filament in an electric
light bulb or the burner element in an electric stove. The actual spectrum
of radiation produced at a given temperature will vary from one object to
the next, but a blackbody is unique in this regard: it emits radiation with
equal efficiency at all frequencies.
The reason for this lies in a concept from thermodynamics called Kirch￾hoff’s law: a body at the same temperature as its surroundings will emit
radiation with the same efficiency at which it absorbs it. Imagine what
would happen if this was not the case; if the body absorbed radiation at a
different rate than it emitted it, over time the object would gradually heat
up or cool down catastrophically! However, this argument can be made
stronger: a body must absorb and give off radiation at the same rate at
every frequency. Again, imagine an object at the same temperature as its
environment but now surrounded with a filter which allows only a narrow
range of frequencies of radiation to pass through. Emission and absorption
must be exactly balanced within this range of frequencies in order for the
object to remain at the same temperature as its surroundings.4 Quantum Mechanics: An Accessible Introduction
Fig. 1.1 A cavity with a small hole behaves like a blackbody.
So Kirchhoff’s law says that a good absorber of radiation will also be
a good emitter. Hence, a body which absorbs radiation with perfect ef￾ficiency at all frequencies (a “blackbody”) must also emit radiation with
perfect efficiency at all frequencies. In practice, most things in nature are
not perfectly black; they reflect some light and are therefore not perfect
blackbodies. To construct a practical blackbody emitter, we can use a cav￾ity with a very small hole (Figure 1.1). Then light inside the cavity will
reflect many times before it can leave the cavity. Even if the walls of the
cavity are not perfectly absorbing, the probability that the light will escape
becomes smaller with each reflection and can be made infinitesimally small.
Then the hole of the cavity acts like a blackbody, and the cavity itself is
filled with blackbody radiation.
The experimental properties of blackbody radiation were well estab￾lished in the 19th century. First consider the total power given off by a
blackbody. This was first measured by J. Stefan in 1879. The power emit￾ted scales as the surface area A of the blackbody, and Stefan discovered
that it also scales as the fourth power of the temperature T, measured in
Kelvin:
P = σAT4
(1.1)The origins of quantum mechanics 5
where σ is a constant called the Stefan–Boltzmann constant, and Equa￾tion (1.1) is called the Stefan–Boltzmann law. (Boltzmann showed how
the T
4 dependence could be derived theoretically.) The Stefan–Boltzmann
constant is measured to be
σ = 5.67 × 10−8
J sec−1 m−2 K
−4
A more convenient quantity to work with is the total energy density ρ of
radiation inside a blackbody cavity. In terms of the power radiated, this is
given by ρ = (4/c)(P/A), where c is the speed of light, so that
ρ = aT4
(1.2)
with
a = 7.56 × 10−16 J m−3 K
−4
The spectrum of radiation, i.e., the energy density at a given frequency,
can also be measured. This spectrum is expressed as ρ(ν) dν, the total
energy density in blackbody radiation between ν and ν +dν, where ν is the
frequency of the radiation in Hz. (Of course, ρ(ν) dν will also be a function
of temperature; it is understood that the spectrum is measured at a fixed
value of T.) A plot of the measured spectrum is shown in Figure 1.2 for
three different temperatures.
The spectrum shows two obvious features. First, the amplitude of the
spectrum increases with temperature. This is not surprising, since we know
that the total energy density must increase as T
4
, and this total energy
density is just the spectrum integrated over all frequencies:
ρ =
Z ∞
0
ρ(ν) dν = aT4
In Figure 1.2, the total energy density is just the area under each curve.
A second interesting feature is that the curves shift to the right (higher
frequencies) as we go to higher temperatures. More quantitatively, it is ob￾served that the frequency of the peak energy density (or peak emission from
the blackbody) scales linearly with the temperature: νpeak ∝ T. Since the
wavelength scales inversely with frequency, this relation is often expressed
as
λpeak = w/T
where w is a constant (w = 2.90×10−3 m K). This empirical result is known
as Wien’s displacement law. At room temperature, blackbodies radiate
primarily in the infrared (hence the usefulness of night vision goggles).6 Quantum Mechanics: An Accessible Introduction
0 2 3 1014 4 3 1014
2 3 10–17
4 3 10–17
6 3 10–17
8 3 10–17
n (Hz)
r(n) (J m–3 Hz–1)
1000 K
1500 K
2000 K
Fig. 1.2 The energy density ρ(ν) of blackbody radiation as a function of the frequency
ν at temperatures of T = 1000 K, 1500 K, and 2000 K. The vertical lines show the peak
in the energy density at each temperature.
At temperatures of several thousands of degrees, the radiation shifts into
the optical range, giving the familiar phenomenon of a heated object first
glowing “red-hot” then “white-hot.” Physicists of the 19th century had
a theory to explain the observed behavior of the blackbody spectrum; the
only problem was that their theory failed to produce the observed spectrum.
To understand this classical theory, we need several ideas from thermo￾dynamics, which we will quote without derivation. Consider a collection of
electromagnetic waves inside a blackbody cavity at a temperature T. The
energy density of the radiation is just the average energy of the waves mul￾tiplied by their number density. The average energy E¯ of a set of classical
oscillators is proportional to the temperature T:
E¯ = kT
where the constant k = 1.38× 10−23 J K−1
is called Boltzmann’s constant.The origins of quantum mechanics 7
Classical physics also predicts the number density of waves n(ν) dν with
frequencies between ν and ν + dν to be
n(ν) dν =
8π
c
3
ν
2
dν (1.3)
Then the total energy density is just the number density of waves multiplied
by the average energy per wave:
ρ(ν) = n(ν)E¯
giving
ρ(ν) dν =
8πkT
c
3
ν
2
dν (1.4)
Equation (1.4) is called the Rayleigh–Jeans formula for blackbody radiation,
and it is based on correct arguments from thermodynamics. The only
problem is that it doesn’t work. In Figure 1.3, we compare the predictions of
this formula to an actual blackbody spectrum at a temperature T = 2000 K.
0 2 3 1014 4 3 1014
2 3 10–17
4 3 10–17
6 3 10–17
8 3 10–17
n (Hz)
r(n) (J m–3 Hz–1)
Fig. 1.3 The solid curve gives the observed spectrum of blackbody radiation at T =
2000 K, and the dashed curve gives the prediction of the Rayleigh–Jeans formula.8 Quantum Mechanics: An Accessible Introduction
The Rayleigh–Jeans formula is not a complete failure. At the low￾frequency end of the spectrum, it gives good agreement with the observa￾tions. But it fails at the high-energy end of the spectrum, and here it fails
in a spectacular fashion. According to Equation (1.4), the energy density
of radiation should increase with increasing frequency all of the way up to
infinity! A heated object would give off more ultraviolet light than visible
light and more X-rays than either; a person sitting in front of a fireplace
would be killed by radiation! This problem came to be known as the ultra￾violet catastrophe. (In physics, it is common to use the terms “infrared” and
“ultraviolet” to refer generically to the low-frequency and high-frequency
limits of any spectrum.)
It was Max Planck who found the correct formula for the blackbody
radiation spectrum, and in so doing, inadvertently developed the beginnings
of quantum mechanics. In order to understand Planck’s reasoning, we need
to make use of another result from thermodynamics. Consider a collection
of interacting particles such as gas molecules in a box or radiation in a
blackbody cavity. We have already seen that the average energy of these
particles E¯ is proportional to their temperature: E¯ = kT. Now we need
an expression for the distribution of energies for these particles, i.e., the
probability that a randomly-chosen particle will have a particular energy.
If we pick a random particle in our distribution, then we will define P(E) dE
to be the probability that it has energy between E and E+dE. It is observed
that for a wide variety of systems, P(E) has a universal form called the
Boltzmann distribution, given by
P(E) = e
−E/kT
kT (1.5)
Using this expression, the mean energy of the particles is given by its clas￾sical value:
E¯ =
R ∞
0
P(E)E dE
R ∞
0
P(E) dE
= kT (1.6)
So if we blindly use the Boltzmann distribution given by Equation (1.5),
we will still end up with the Rayleigh–Jeans formula, Equation (1.4), which
fails at high frequencies.
Planck’s idea was to modify the theory to make E¯ a function of fre￾quency in such a way that E¯ = kT at low frequencies (where the Rayleigh–
Jeans formula works well), while E¯ ̸= kT at high frequencies (where the
Rayleigh–Jeans formula fails). In order to do this, Planck assumed that
E could no longer take on arbitrary values but only discrete multiples ofThe origins of quantum mechanics 9
some fundamental energy. Further, he took this fundamental energy to be
proportional to the frequency ν, with a constant of proportionality h. (The
value of h is not predicted by Planck’s theory but must be chosen to fit the
observations.) Therefore, according to Planck, the allowed values for E are
simply
E = 0, hν, 2hν, 3hν, . . .
Clearly, h must have units of energy/frequency, or J·sec. With this as￾sumption, Equation (1.6) can no longer be taken to be an integral over a
continuous range of values for E, but instead is a sum over the allowed
discrete values:
E¯ =
X
E=0, hν, 2hν,...
P(E)E
 X
E=0, hν, 2hν,...
P(E)
=
X∞
n=0
nhν
kT e
−nhν/kTX∞
n=0
1
kT e
−nhν/kT
=
hν
e
hν/kT − 1
which is obviously different from Equation (1.6). Taking this expression for
E¯ and multiplying by the number density of waves in Equation (1.3), we
obtain Planck’s expression for the spectrum of blackbody radiation:
ρ(ν) dν =
8πh
c
3
ν
3
e
hν/kT − 1
dν (1.7)
Example 1.1. The Classical Limit of the Planck Blackbody
Spectrum
Show that the Planck blackbody spectrum reduces to the Rayleigh–Jeans
formula in the limit of low frequencies.
We begin with Equation (1.7) and assume that hν/kT ≪ 1. Recall that
for small x,
e
x ≈ 1 + x
Thus, Equation (1.7) becomes, for hν/kT ≪ 1,
ρ(ν) dν =
8πh
c
3
ν
3
1 + hν/kT − 1
dν
=
8πkT
c
3
ν
2
dν
which is the Rayleigh–Jeans formula.10 Quantum Mechanics: An Accessible Introduction
This result explains why the Rayleigh–Jeans formula works well at low
frequencies but fails at high frequencies. It also indicates the frequency
range over which the Rayleigh–Jeans formula works well: ν ≪ kT /h.
The Planck spectrum can be used to derive both the Stefan–Boltzmann
law and Wien’s law, and these results can be used, in turn, to calculate the
value of h. The total energy density of blackbody radiation is simply the
integral of the Planck spectrum over all frequencies:
ρ =
Z ∞
0
ρ(ν) dν
=
Z ∞
0
8πh
c
3
ν
3
e
hν/kT − 1
dν
The integral can be put into simpler form by making the change of variables
x = hν/kT; this gives
ρ =
8π(kT)
4
c
3h
3
Z ∞
x=0
x
3
e
x − 1
The integral can be evaluated exactly:
Z ∞
x=0
x
3 dx
e
x − 1
=
π
4
15
giving
ρ =
8
15
π
5
k
4
c
3h
3
T
4
(1.8)
A comparison of Equation (1.8) with Equation (1.2) shows the correct T
4
dependence of ρ.
Now consider the frequency at which the maximum emission occurs.
We begin with Equation (1.7) for ρ(ν), and set dρ/dν = 0 to find frequency
νpeak at which ρ(ν) is a maximum:
dρ(νpeak)
dν =

3 −
hνpeak
kT 
e
hνpeak/kT − 3 = 0
This has a trivial solution at νpeak = 0. The nontrivial solution, which is
the one we want, cannot be calculated algebraically, but it can be found
numerically: hνpeak/kT ≈ 2.8, so
νpeak = 2.8kT /h
This result is consistent with Wien’s law: the value of νpeak is proportional
to the temperature T.The origins of quantum mechanics 11
Not only have we shown that the Planck spectrum predicts both the
Stefan–Boltzmann law and Wien’s law, but we have derived expressions
for the corresponding constants of proportionality in both laws. Since the
speed of light c is known from other experiments, it is possible to com￾pare these two expressions with the experimentally-measured constants of
proportionality to derive values for both h and k; Planck did exactly that,
obtaining very accurate results (in terms of modern measurements) for both
constants. The best current measurements of k and h give
k = 1.381 × 10−23 J K−1
and
h = 6.626 × 10−34 J sec
When these values are inserted into Equation (1.7), the result is a predicted
blackbody spectrum in excellent agreement with the observed spectrum.
1.3 The Nature of Light
Planck showed that the spectrum of blackbody radiation could be explained
only if the energies of light waves in a blackbody cavity were restricted to
discrete values proportional to their frequency, E = nhν. Planck’s solu￾tion to the problem of blackbody radiation clearly indicated something odd
about the nature of the radiation, but the physical interpretation of his
proposal was not at all obvious. In the decade after Planck made this pro￾posal, several subsequent experiments clarified what was really going on:
light behaves like a gas of particles called photons, and the energy of each
photon is given by hν.
This idea hearkens back to the original theory of light proposed by
Newton in the 1600’s. In Newton’s “corpuscular theory,” light consisted of
particles, which obeyed the laws of classical mechanics. This theory could
explain, for instance, the way in which light reflects from surfaces. How￾ever, by the 1800’s, it was clear that many observations could be explained
only if light consisted of waves rather than particles. These observations
included well-known phenomena such as diffraction and interference (Fig￾ure 1.4). Maxwell’s equations, derived from observations of electromagnetic
phenomena, actually predict the wave nature of light in the form of oscil￾lating electric and magnetic fields. By the beginning of the 20th century,
the wave nature of light was well established. We will now consider two
experiments that reestablished the interpretation of light as a collection of
particles.12 Quantum Mechanics: An Accessible Introduction
Fig. 1.4 Diffraction (left) and interference (right) indicate that light consists of waves.
The photoelectric effect
Light shining on a metal plate is observed to produce a current; this effect
is called the photoelectric effect (see Figure 1.5). The current and maximum
energy of the photoelectrons can be measured as the intensity and frequency
of the light are varied. [The maximum energy is measured by putting a
potential across the circuit until the current stops; if Φ0 is the potential
which stops the current from flowing, then the corresponding maximum
electron energy is Emax = eΦ0.]
Here is what is observed:
1. The current is proportional to the intensity of the light (i.e., the power
per unit area falling on the plate, measured in W/m2
).
2. The maximum energy of the photoelectrons Emax is proportional to
the frequency of the light (Figure 1.6). Furthermore, there is a minimum
frequency below which no current is observed; this minimum frequency
depends on the composition of the metal plate.
It is the second of these observations which is puzzling. In the classical
theory of electromagnetic radiation, the energy put into the system should
be proportional to the intensity of the light, and the frequency should play
no role at all in determining Emax.The origins of quantum mechanics 13
Electrons
Light
Variable V
Fig. 1.5 A schematic representation of the photoelectric effect.
Emax (J)
n (Hz)
1 3 1015 2 3 1015 3 3 1015
0.5 3 10–18
1 3 10–18
1.5 3 10–18
0
Fig. 1.6 The maximum electron energy Emax measured in the photoelectron effect, as
a function of the frequency of light ν.
It was Albert Einstein who, in 1905, came up with the explanation for
the photoelectric effect. He proposed that light, in this case, behaves as
a collection of particles called photons. Furthermore, the energy of each
photon is given by hν. When a photon strikes an electron in the metal
plate, it can transfer a maximum energy of hν to the electron. This would14 Quantum Mechanics: An Accessible Introduction
suggest that Emax = hν. However, there is an additional complication.
The electrons are bound in the metal with some binding energy EB. The
photon must transfer enough energy to remove the electron from the metal;
whatever energy is left over then goes into the kinetic energy of the electron.
We therefore have
Emax = hν − EB
Although EB will vary from one metal to the next, Einstein’s theory makes
one universal prediction: the slope of the graph of Emax versus ν should
be given by Planck’s constant h. This is exactly what is observed. In fact,
although Einstein is most famous for the theory of relativity, he won his
Nobel Prize for this explanation of the photoelectric effect.
The fact that Planck’s constant appears in two very different phenomena
(blackbody radiation and the photoelectric effect) suggests that it has a
fundamental physical significance. Furthermore, Einstein’s theory indicates
something very radical about the nature of light: it behaves as a particle
with energy hν. Further confirmation of this behavior was provided by the
Compton effect.
The Compton effect
One of the characteristics of particles is that they can scatter off of each
other, conserving both energy and momentum in the scattering process. If
light truly does behave like a particle, it should be possible to observe such
scattering processes and to predict the change in the energy and momentum
of the light when it scatters. One such process that is observed to occur is
Compton scattering, which refers to the scattering of X-rays or gamma rays
off of the electrons in a metal (Figure 1.7). Experimentally, it is observed
that the wavelength of the scattered radiation λf is larger than that of
the incident radiation λi
, and the change in wavelength is well fit by the
relation
λf − λi = λC (1 − cos θ) (1.9)
where λC , called the Compton wavelength of the electron, is a constant with
units of length
λC = 2.4 × 10−12 m (1.10)
and θ is the scattering angle shown in Figure 1.7. Note from Equation (1.9)
that the change in wavelength is actually independent of the initial wave￾length λi
; it depends only on the scattering angle θ.The origins of quantum mechanics 15
g source
u
Detector
Metal rod
Fig. 1.7 An example of the Compton scattering experiment. Gamma rays from a
radioactive source scatter off of electrons in a cylindrical metal target. The wavelength
of the scattered radiation is measured as a function of the scattering angle θ.
The Compton effect cannot be explained by the classical wave theory
of light. Classically, a light wave scattering off of an electron excites the
electron to oscillate at the same frequency as the incident wave, and the os￾cillating electron produces radiation with the same frequency. Hence, light
scattering from an electron undergoes no change in frequency. However,
if we treat the light as consisting of particles, we will not only be able to
derive the correct behavior given in Equation (1.9), but also to obtain the
correct value for λC .
To derive Equation (1.9), we will assume that the radiation consists
of particles with energy hν, and we will treat the Compton effect as a
scattering problem in classical mechanics (see Figure 1.8). We need to be
careful to use the correct relativistic expressions for energy and momentum
here. Recall that special relativity gives
E
2 = p
2
c
2 + m2
0
c
4
for a particle with mass m0. For the electron we simply take m0 = me. For
a photon we know that E = hν, but what do we assume for the rest mass?
Any particle moving at the speed of light must have zero rest mass, so that
E2 = p
2
c
2
, and
E = pc
for photons.16 Quantum Mechanics: An Accessible Introduction
p
i u
, Ei
p
f
, Ef
pe
, Ee
Fig. 1.8 A photon is incident with energy Ei and momentum pi. It scatters off of an
electron, emerging at an angle θ with final energy Ef and final momentum pf . The
electron ends up with final energy Ee and final momentum pe.
Applying conservation of momentum to the system in Figure 1.8 gives
pi = pf + pe (1.11)
while energy conservation gives
Ei + mec
2 = Ef + Ee (1.12)
where i and f refer to the incoming and outgoing photon respectively, and
e refers to the final state of the electron after scattering (see Figure 1.8).
Note that since we are using a fully relativistic treatment, we include the
rest energy of the electron on the left-hand side of the equation. We want
to eliminate the electron energy and momentum from both equations, so
we begin by rewriting Equation (1.11) as pi − pf = pe and squaring both
sides (i.e., taking the dot product of each side with itself) to get
p
2
i + p
2
f − 2pipf (cos θ) = p
2
e
(1.13)
Similarly, rearranging terms in Equation (1.12) and squaring, we get
(Ei − Ef + mec
2
)
2 = E
2
e
(1.14)
We now make the appropriate substitutions Ei = pic, Ef = pf c, and
E2
e = p
2
e
c
2 + m2
e
c
4
into Equation (1.14), and simplify to obtain
(pi − pf )
2 + 2(pi − pf )mec = p
2
e
(1.15)
We can now equate the right-hand sides of Equations (1.13) and (1.15) and
reduce the resulting equation to the form
1
pf
−
1
pi
=
1
mec
(1 − cos θ) (1.16)The origins of quantum mechanics 17
At this point, we need to express the photon momenta in terms of their
wavelengths. Since we have E = hν, ν = c/λ, and E = pc, we obtain
p = h/λ (1.17)
Then Equation (1.16) reduces to
λf − λi =
h
mec
(1 − cos θ)
This is exactly the same form as Equation (1.9) with
λC = h/mec
Substituting the values for h, me, and c, we indeed obtain the measured
value of λC (= 2.4 × 10−12 m). Thus, the Compton effect can be explained
by assuming that the X-rays or gamma rays act as particles with energy
E = hν and momentum p = h/λ.
Is it a Particle or a Wave?
Both the photoelectric effect and the Compton effect provide evidence that
light acts like a particle with energy given by E = hν. But this does not
eliminate the results of classical optics in which light behaves like a wave.
Instead, we are forced to accept the idea of wave-particle duality: light
behaves sometimes as wave and sometimes as a particle. This provides the
stepping-stone to a more radical idea: if light can exhibit both wave and
particle properties, what about matter?
1.4 The Wave Nature of Matter
We saw in Section 1.3 that light can behave as both a particle and a wave.
On this basis, Louis de Broglie made a much more startling proposal: that
matter, which is composed of particles, might also behave like a wave.
(Louis de Broglie was one of the last surviving founders of quantum me￾chanics, passing away in 1987 at the age of 95.) In particular, de Broglie
proposed using the relation between momentum and wavelength appropri￾ate for a photon (Equation (1.17)) and applying it to matter. The de Broglie
wavelength for a particle is then
λ = h/p (1.18)
This proposal seems absurd. If someone’s body behaved like a wave, it
would diffract every time that person walked through a door. He or she18 Quantum Mechanics: An Accessible Introduction
could even walk through a classroom wall having two doors and form an
interference pattern on the front wall! But there is a good reason that these
phenomena are not observed.
Example 1.2. The de Broglie Wavelength of a Walking Human
Consider a 70 kg human being walking at 1 m sec−1
. The momentum is
p = mv = 70 kg m sec−1
and Equation (1.18) gives a de Broglie wavelength of
λ = h/p = 9 × 10−36 m
This is a tiny wavelength compared to ordinary human length scales; in
fact, it is tiny compared to atomic or nuclear scales! Therefore, it is not
surprising that we do not see any wave-like effects at human length scales.
In order to see some effect from the wave nature of matter, it is necessary
to conduct an experiment in which λ is significant compared to the charac￾teristic size of the physical system. To maximize λ, it is desirable to use the
smallest possible momentum p. For a nonrelativistic particle of mass m,
the relation between (kinetic) energy E and momentum p is p =
√
2mE.
Hence, at fixed energy, p will be minimized and λ maximized when m is
as small as possible. This makes the electron (which has a much smaller
mass than the proton or neutron) a convenient particle to use, and in or￾der for the electrons to behave like waves, they must be scattered through
an “aperture” with a size comparable to or smaller than their wavelength.
This can be achieved by scattering electrons from a crystal lattice, since
the separation of the atoms in the lattice is on the order of 10−10 m.
In an experiment called the Davisson–Germer experiment (Figure 1.9),
Davisson and Germer scattered electrons off of a nickel sheet and measured
the intensity of the electrons as a function of the scattering angle. An
interference pattern was produced, which can be explained by taking the
electrons to behave like waves with wavelength given by Equation (1.18).
Although we have applied the de Broglie postulate only to electrons, it
was proposed for all matter. Thus, we are left with an interesting symmetry
between radiation and matter: both can be considered to behave as both
particles and waves.The origins of quantum mechanics 19
Incident electrons Scattered electrons
Fig. 1.9 In the Davisson–Germer experiment, electrons are scattered from a crystal
lattice. Constructive interference occurs when the path difference between rays scattering
from adjacent planes is an integer multiple of the wavelength of the electrons.
1.5 The Bohr Atom
We now examine the most important result from the early stages of quan￾tum mechanics: Neils Bohr’s model of the atom. Ernest Rutherford’s
experiments in the scattering of alpha particles from atoms led to our famil￾iar modern picture of the atom: a small, positively-charged, central nucleus
surrounded by negatively-charged electrons orbiting the nucleus. There are,
however, two problems with this picture. According to classical electromag￾netic theory, any accelerating charge will emit electromagnetic radiation.
Since the electrons must undergo centripetal acceleration in order to orbit
the nucleus, they should give off radiation. Not only is this radiation not
observed, but if it did occur, the electrons would lose energy and spiral into
the nucleus; every atom would be unstable!
The second problem with this classical picture is that it cannot explain
one of the most striking features of hot gasses. If hydrogen gas, for example,
is heated, the radiation it emits is not a continuous spectrum of wavelengths.
Instead, the radiation is confined to discrete wavelengths, producing a series
of bright lines in the spectrum. These lines were measured in the 19th
century and found to obey a regular pattern. For hydrogen, for example,
the wavelengths at which radiation is emitted are given by the formula
1
λ
= R

1
m2
−
1
n2

(1.19)20 Quantum Mechanics: An Accessible Introduction
where m = 1, 2, 3, . . . and n = 2, 3, 4, . . . with n > m, and R is a constant
(called the Rydberg constant) with a value of R = 1.097 × 107 m−1
. This
was a purely empirical relation discovered (for the special case m = 2)
by Johann Balmer in 1885. (In his honor, the m = 2 series of spectral
lines is called the Balmer series.) Later, spectral lines were found for the
other values of m; these are called the Lyman series (m = 1), the Paschen
series, (m = 3), and so on. The Rutherford model of the atom provides no
explanation for this observed numerological result.
Neils Bohr proposed a model for the atom which solves both of these
problems. Bohr assumed that the angular momentum of the electron in a
hydrogen atom could not take on arbitrary (continuous) values but instead
was quantized, i.e., constrained to take on only discrete values, which he
took to have units of h/2π: L = nh/2π, n = 1, 2, 3, . . . . We now introduce
a new version of Planck’s constant, ℏ (pronounced “h-bar”), given by
ℏ = h/2π
In terms of ℏ, Bohr’s quantization condition becomes
L = mvr = nℏ, n = 1, 2, 3, . . . (1.20)
Although Bohr expressed this condition in terms of angular momentum,
it follows immediately from de Broglie’s later hypothesis of matter waves.
If the electron behaves like a standing wave around the hydrogen nucleus,
then the circumference of its orbit must correspond to an integer number
of wavelengths (Figure 1.10).
+ +
OK Not OK!
Fig. 1.10 The circumference of the electron orbit must correspond to an integer number
of wavelengths of the electron.
Taking
2πr = nλ = nh/p
we get
L = pr = nh/2π = nℏ
which is just the Bohr quantization condition in Equation (1.20).The origins of quantum mechanics 21
The rest of Bohr’s calculation is purely classical. For a classical orbit,
the Coulomb force on the electron must be equal to the centripetal force:
FCoulomb = Fcentripetal
e
2
4πϵ0
1
r
2
=
mv2
r
(1.21)
Solving Equations (1.20) and (1.21) for v and r, we find that the electron
orbiting the hydrogen atom can have only certain discrete values for its
orbital radius and velocity, expressed in terms of the integer n. Specifically,
r =
4πϵ0ℏ
2
me2
n
2
, n = 1, 2, 3 . . . (1.22)
and
v =
e
2
4πϵ0ℏ
1
n
, n = 1, 2, 3 . . . (1.23)
The total energy of an electron with orbital radius r and velocity v is just
the sum of its kinetic and potential energies:
E =
1
2
mv2 −
e
2
4πϵ0
1
r
(1.24)
Substituting the allowed discrete values for r and v from Equations (1.22)
and (1.23) into Equation (1.24) gives a set of discrete allowed energy levels
En:
En = −
m
2ℏ
2

e
2
4πϵ0
2
1
n2
= −13.6 eV 1
n2
where we have expressed the hydrogen energy levels in units of electron-volts
(eV); 1 eV = 1.6 × 10−19 J (Figure 1.11). The energies in Equation (1.25)
are negative because the electron is in a bound state.
The origin of the discrete spectral lines in the Bohr model arises from
the discrete nature of the allowed energy levels. When an electron makes
a transition from n1 to n2, it gives off a photon with energy En1 − En2
,
and frequency ν = (En1 − En2
)/h. So the integers m and n which appear
in Equation (1.19) have a real physical significance: they give the final
and initial energy levels, respectively, for the electron, as parametrized in
Equation (1.25). It is straightforward to use Equation (1.25) to derive
the wavelengths of the spectral lines given in Equation (1.19) (see Prob￾lem 1.15).22 Quantum Mechanics: An Accessible Introduction
E2
 = –3.4 eV
E1
 = –13.6 eV
E3
 = –1.5 eV
E = 0
.
.
.
Fig. 1.11 In the Bohr model of the atom, the energy levels are given by En =
−13.6 eV(1/n2
).
The Bohr model was a triumph of the early stages of quantum mechan￾ics. Since the n = 1 state in Equation (1.25) has the lowest possible energy,
an electron in this state cannot lose more energy via radiation, so the Bohr
model explains the stability of the atom. Further, the Bohr model predicts
the existence and correct wavelengths for the discrete lines observed in the
spectrum of hydrogen. However, the Bohr model leaves much to be desired.
It mixes classical mechanics and quantum mechanics in a regime for which,
as we shall see later, classical mechanics does not apply at all. In particu￾lar, in the fully quantum mechanical theory of the atom, the electrons do
not have a well-defined radius or velocity. Nonetheless, the full quantum
mechanical theory of the hydrogen atom (discussed in Chapter 6) predicts
the same energy levels as those given by the Bohr theory.
1.6 Where Do We Stand?
In this chapter, we have explored the development of quantum theory which
took place up to the 1920’s. In order to explain various experimental re￾sults, it was necessary to postulate that both matter and light could behave
sometimes like a particle and sometimes like a wave. An application of the
wave nature of matter could then explain the discrete energy levels in theThe origins of quantum mechanics 23
hydrogen spectrum, as well as the stability of the hydrogen atom. This
collection of ideas did not really form a coherent theory, but it became the
basis for a more complete quantum theory that began to be developed in
the late 1920’s, based on the Schr¨odinger equation. It is this theory of
quantum mechanics which is the primary topic of the remainder of this
book.
PROBLEMS
1.1 Assume that a human body emits blackbody radiation at the stan￾dard body temperature.
(a) Estimate how much energy is radiated by the body in one hour.
(b) At what wavelength does this radiation have its maximum in￾tensity?
1.2 A distant star is observed to have a blackbody spectrum with a
maximum at a wavelength of 350 nm [1 nm = 10−9 m]. What is
the temperature of the star?
1.3 The universe is filled with blackbody radiation at a temperature of
2.7 K left over from the Big Bang. [This radiation was discovered
in 1965 by Bell Laboratory scientists, who thought at one point
that they were seeing interference from pigeon droppings on their
microwave receiver.]
(a) What is the total energy density of this radiation?
(b) What is the total energy density with wavelengths between
1 mm and 1.01 mm? Is the Rayleigh–Jeans formula a good ap￾proximation at these wavelengths?
1.4 Over what range in frequencies does the Rayleigh–Jeans formula
give a result within 10% of the Planck blackbody spectrum?
1.5 Let ρ(< ν0) be the total energy density of blackbody radiation in
all frequencies less than ν0, where hν0 ≪ kT. Derive an expression
for ρ(< ν0).
1.6 Suppose we want to measure the total energy density in black￾body radiation above some cutoff frequency ν0. Let ρ(> ν0)
be the total radiation density in all frequencies greater than ν0.
Using the Planck blackbody spectrum show that ρ(> ν0) =24 Quantum Mechanics: An Accessible Introduction
(8π/c3
)kT ν3
0
e
−hν0/kT is a good approximation when hν0 is much
larger than kT.
1.7 (a) Express the Planck spectrum (Equation (1.7)) as a function of
the wavelength λ of the radiation, rather than the frequency ν.
(b) Use this expression to derive the wavelength λpeak at which the
spectrum is a maximum.
(c) Does λpeakνpeak = c?
1.8 In a photoelectric experiment, electrons are emitted from a surface
illuminated by light of wavelength 4000 ˚A, and the stopping po￾tential for these electrons is found to be Φ0 = 0.5 V . What is the
longest wavelength of light that can illuminate this surface and still
produce a photoelectric current?
1.9 A laser emits 40 W of power at a wavelength of 6.0 × 10−7 m.
(a) What is the total number of photons emitted per second?
(b) What is the energy of each photon?
1.10 (a) Using the Planck blackbody spectrum, and the fact that a pho￾ton with a frequency ν has an energy of hν, derive an expression
for n(ν) dν, the total number density of photons with frequencies
between ν and ν + dν in blackbody radiation.
(b) Using the expression from part (a), show that the total number
density of photons in blackbody radiation is given by
n = β(kT /hc)
3
where β is a constant given by β ≈ 60. [Note that the integral
R ∞
0
x
2 dx/(e
x−1) cannot be done analytically, so use the numerical
result that R ∞
0
x
2 dx/(e
x − 1) ≈ 2.4.]
1.11 A gamma ray with energy 1 MeV is scattered off of an unknown par￾ticle which is at rest. The gamma ray is reflected directly backward
with a final energy of 0.98 MeV. What is m0c
2
for the unknown
particle? (Express your answer in MeV.)
1.12 Calculate the de Broglie wavelength of a proton (mc2 = 938 MeV)
with (a) a kinetic energy of 0.1 MeV (b) a total energy of 3 GeV.
1.13 The Balmer series (the m = 2 case in Equation (1.19)) was discov￾ered before the other series of spectral lines (m = 1, m = 3, etc.).The origins of quantum mechanics 25
Why? (Hint: Plug in some numbers and calculate wavelengths for
m = 1, m = 2, and m = 3.)
1.14 Verify that ℏ has units of angular momentum.
1.15 Beginning with the Bohr energy levels (Equation (1.25)), derive
the expression for the wavelengths of the spectral lines in hydrogen
(Equation (1.19)) and use this result to express R as a function of
m, e, ℏ, c, and ϵ0. Plug in values for these constants and verify
that the correct result for R is obtained.
1.16 Suppose that the attractive force between the electron and proton
in the hydrogen atom is given by some power law other than the
inverse square law, i.e., assume that the magnitude of the force is
given by F = krβ
, where k is a constant, and β is an arbitrary
number with β ̸= 1. [For example, the ordinary Coulomb law cor￾responds to the case β = −2. The harmonic oscillator corresponds
to β = 1.] Use the Bohr quantization rule to show that for β ̸= −1,
the energy levels of the atom are give by
E =
ℏ
2n
2
m
(β+1)/(β+3)
k
2/(β+3)1
2
+
1
β + 1

This formula gives an absurd answer when β = −3; why?This page intentionally left blankChapter 2
Math interlude A: Complex numbers
and linear operators
2.1 Complex Numbers
Classical physics, with a few exceptions, relies on real numbers for its math￾ematical basis. Quantum mechanics marked the entry of complex numbers,
in a fundamental way, into physics. Here we review the main properties of
complex numbers for use in the remainder of this book.
Consider a set of numbers 0, 1, 2, . . . and some operation such as ad￾dition. The set is said to be closed under the operation if whenever the
operation is applied to the numbers in the set, the result is also in the set.
For instance, the set of integers is closed under addition and multiplication.
However, to get a set which is closed under subtraction, we need to include
the negative numbers. Closure under division requires fractions, and the
taking of various roots forces us to include the irrational numbers.
Complex numbers arise when we try to take the square root of nega￾tive numbers. The square roots of the negative numbers are said to be
imaginary, beginning with the square root of −1:
√
−1 = i
It is convenient to think of the imaginary numbers as occupying a sec￾ond number line perpendicular to the line occupied by the real numbers.
The real and imaginary numbers can then be added just like two￾dimensional vectors, resulting in the complex numbers which occupy this
two-dimensional number plane (Figure 2.1). In general, an arbitrary com￾plex number z can be written as the sum of a real number a and an imag￾inary number bi:
z = a + bi (2.1)
In Equation (2.1), a and b are both real numbers.
2728 Quantum Mechanics: An Accessible Introduction
–5 1 2 3 4 5 –4 –2 –1 –3
–4i
–5i
–3i
–2i
–i
i
2i
3i
4i
5i
–3 – 2i
3 + 4i
Imaginary axis
Real axis
Fig. 2.1 The complex numbers can be treated as two-dimensional vectors in the complex
plane; the real part of a complex number gives the horizontal coordinate in this plane,
and the imaginary part gives the vertical coordinate.
Addition and subtraction of complex numbers is easy; just as for two￾dimensional vectors, the real and imaginary parts are added or subtracted
separately:
(a + bi) + (c + di) = (a + c) + (b + d)i
(a + bi) − (c + di) = (a − c) + (b − d)i
Multiplication and division are more subtle. For multiplication, it is pos￾sible to simply multiply out two complex numbers using the distributive
property:
(a + bi)(c + di) = ac + bci + adi + bd(i)(i)
= (ac − bd) + (bc + ad)i
However, there is another way to implement complex multiplication based
on a different way to represent complex numbers. Recall that the complex
numbers form a two-dimensional plane, and there are two types of coordi￾nate systems in the plane: Cartesian (or rectangular) coordinates and polarMath interlude A: Complex numbers and linear operators 29
coordinates. The representation of a complex number as z = a + bi corre￾sponds to Cartesian coordinates; we will now derive a polar representation.
To do this, first consider exponentials of imaginary numbers. For an
imaginary number iθ (where θ is real), we can use the Taylor expansion of
the exponential to give
e
iθ = 1 + (iθ) + 1
2
(iθ)
2 +
1
6
(iθ)
3 +
1
24
(iθ)
4 +
1
120
(iθ)
5 + · · ·
The terms on the right-hand side of this equation that are even powers
of (iθ) will give real numbers, while the odd powers will give imaginary
numbers. Collecting the even and odd powers separately, and factoring out
i from the latter, gives
e
iθ =

1 −
1
2
θ
2 +
1
24
θ
4 − · · · 
+ i

θ −
1
6
θ
3 +
1
120
θ
5 − · · · 
But the two sums on the right-hand side of this equation are the Taylor
expansions for cosine and sine, respectively. Hence, this equation can be
written as
e
iθ = cos θ + isin θ (2.2)
As θ increases from 0 to 2π, the function e
iθ traces out a unit circle in the
complex plane with angle θ relative to the positive real axis (Figure 2.2).
Multiplying by the real number R then gives a complex number at a dis￾tance R from the origin and at an angle θ relative to the positive real axis
(Figure 2.3), written as Reiθ. This gives the polar representation of a com￾plex number. Any complex number can be written in either Cartesian or
polar form. When a complex number z is written in the form z = Reiθ
,
then R is called the modulus or the absolute value of z, and θ is called
the argument of z. Note that θ must be expressed in radians. Using the
standard notation for absolute value, we can write |z| = R.30 Quantum Mechanics: An Accessible Introduction
e
iu
sin u
cos u
u
1
Imaginary axis
Real axis
Fig. 2.2 Since e
iθ = cos θ + i sin θ, the complex number e
iθ has unit absolute value and
lies at an angle θ relative to the real axis.
To convert from the Cartesian form of a complex number, a + bi, to
polar form, Reiθ, and vice versa, we use Equation (2.2) to give
Reiθ = R cos θ + iR sin θ
so that
a = R cos θ
b = R sin θ
and conversely,
R =
p
a
2 + b
2
θ = tan−1
(b/a)
Note that there is a subtlety in determining the value of θ for a given a
and b, because tan−1
(x) actually has two different values for a given choice
of x, separated from each other by the angle π. This ambiguity is resolvedMath interlude A: Complex numbers and linear operators 31
u
z = Reiu
R
Imaginary axis
Real axis
Fig. 2.3 The complex number z = Reiθ is located at a distance R from the origin and
at an angle θ relative to the positive real axis.
by noting that θ must be chosen so that the complex number lies in the
correct quadrant of the complex plane:
0 < θ < π/2 → a > 0, b > 0
π/2 < θ < π → a < 0, b > 0
π < θ < 3π/2 → a < 0, b < 0
3π/2 < θ < 2π → a > 0, b < 0
Example 2.1. Converting a Complex Number to Polar Form
Express 2 + 2i and 1 − i in polar form.
For 2 + 2i, we have
R =
p
2
2 + 22 = 2√
2
and
θ = tan−1
(2/2) = tan−1
(1) = π/4 or 5π/432 Quantum Mechanics: An Accessible Introduction
Since a > 0 and b > 0, the correct choice for θ is π/4. Similarly, for 1 − i,
we get
R =
p
1
2 + 12 =
√
2
and
θ = tan−1
(−1/1) = tan−1
(−1) = 3π/4 or 7π/4
and since a > 0 and b < 0, we must choose 7π/4. Hence, we have
2 + 2i = 2√
2e
iπ/4
and
1 − i =
√
2e
i7π/4
It is now straightforward to multiply or divide two complex numbers,
represented as z1 = R1e
iθ1 and z2 = R2e
iθ2
: For multiplication,
z1z2 = (R1e
iθ1
)(R2e
iθ2
) = R1R2e
i(θ1+θ2)
Thus, when multiplying two complex numbers, the R’s are multiplied and
the θ’s are added. For example, multiplying a complex number by i simply
rotates it 90◦
in the complex plane without changing its distance from the
origin, while multiplication by −1 is equivalent to rotation through 180◦
.
Similarly, for division,
z1/z2 = (R1e
iθ1
)/(R2e
iθ2
) = (R1/R2)e
i(θ1−θ2)
Example 2.2. Multiplication of Complex Numbers
What is (2 + 2i)(1 − i)?
This can be solved in two different ways. Using the Cartesian form for
these numbers,
(2 + 2i)(1 − i) = (2)(1) + (2i)(1) + (2)(−i) + (2i)(−i)
= 2 + 2i − 2i + 2
= 4
In polar form, we use the results from Example 2.1:
2 + 2i = 2√
2e
iπ/4
and
1 − i =
√
2e
i7π/4Math interlude A: Complex numbers and linear operators 33
Then
(2 + 2i)(1 − i) = (2√
2e
iπ/4
)(√
2e
i7π/4
)
= 4e
i2π
= 4
Of course, the final answer cannot depend on whether we perform the mul￾tiplication in Cartesian or polar form.
When a complex number is expressed in polar form, it is straightforward
to take it to an arbitrary power:
(Reiθ)
n = R
n
e
inθ
and the roots of a complex number can be determined in a similar way:
√n
Reiθ = (Reiθ)
1/n =
√n Reiθ/n
Example 2.3. The Cube Root of 1
What is the cube root of 1?
In terms of real numbers, the cube root of 1 is just 1. However, when we
consider complex numbers, we discover that 1 actually has three different
cube roots! We have in polar form:
1
3 = 1
￾
e
i2π/3
3
= e
i2π = 1
￾
e
i4π/3
3
= e
i4π = 1
In the complex plane, these three numbers all lie on a unit circle separated
from each other by an angle of 2π/3 (or 60◦
).
Finally, we must deal with one operation that is unique to complex
numbers. This is called complex conjugation. If z = a + bi is an arbitrary
complex number, then its complex conjugate, written as ¯z or z
∗
(we will
use the latter notation), is given by
z
∗ = a − bi
This corresponds to reflection in the complex plane through the real axis
(Figure 2.434 Quantum Mechanics: An Accessible Introduction
w*
z*
z
w
Imaginary axis
Real axis
Fig. 2.4 If z = a + bi, then z
∗ = a − bi, corresponding to reflection through the real
axis.
Some important properties of complex conjugation are
z
∗
z = (a − bi)(a + bi) = a
2 + b
2 = |z|
2
(z
∗
)
∗ = z
(w + z)
∗ = w
∗ + z
∗
(wz)
∗ = w
∗
z
∗
(2.3)
where w and z are any two complex numbers. In polar form, we have
￾
Reiθ∗
= Re−iθ
More generally, the complex conjugate of a complicated expression can be
obtained simply by changing i to −i everywhere in the expression, e.g.,
(1 + i + e
−ix)
∗ = 1 − i + e
iMath interlude A: Complex numbers and linear operators 35
2.2 Operators
Definition of an Operator
The idea of a function is very familiar: a function is simply a fixed rule
for taking a number and changing it into another number. A number is
plugged into a function and out comes a different number. An operator is
a rule for changing one function into another function (Figure 2.5).
A familiar example of an operator is the derivative operator D, which
takes an input function f(x) and produces as its output the derivative of
that function, df /dx:
D[f(x)] = df
dx
e.g.,
D[x
2
] = 2x
D[sin x] = cos x
(2.4)
and so on. We will be interested only in a special class of operators called
linear operators. In order for an operator L to be a linear operator, it must
satisfy two properties: first, for every pair of functions f(x) and g(x),
L[f(x) + g(x)] = L[f(x)] + L[g(x)]
and second, for every function f(x) and real or complex number c,
L[cf(x)] = cL[f(x)]
Function
f(x) = x
3
f(1) = 1
f(2) = 8
f(3) = 27
Operator
D[g(x)] =
D[x
2
] = 2x
D[sin x] = cos x
D[ln x] =
dg
dx
1
x
Number in Number out Function in Function out
Fig. 2.5 A function is a rule for taking a number and turning it into a different number.
An operator is a rule for taking a function and turning it into a different function.36 Quantum Mechanics: An Accessible Introduction
Example 2.4. Determining Whether Operators are Linear
Determine whether or not the following operators are linear:
(a) A[g(x)] = g(x)
2
,
(b) the derivative operator, D[g(x)] = dg/dx.
(a) Note that
A[f(x) + g(x)] = [f(x) + g(x)]2 = f(x)
2 + g(x)
2 + 2f(x)g(x)
and
A[f(x)] + A[g(x)] = f(x)
2 + g(x)
2
Thus, A[f(x) + g(x)] ̸= A[f(x)] + A[g(x)], so A is not a linear operator.
(b) For the derivative operator, we have
D[f(x) + g(x)] = d
dx[f(x) + g(x)] = df
dx +
dg
dx = D[f(x)] + D[g(x)]
and
D[cf(x)] = d
dx[cf(x)] = c
df
dx = cD[f(x)]
So the derivative operator is a linear operator.
Eigenfunctions and Eigenvalues
Suppose that for a particular linear operator L, we can find a function f(x)
which has the property
L[f(x)] = cf(x)
where c can be a real or a complex number. In other words, applying L to
the function f simply gives us f back again multiplied by the number c.
In this case, we say that f is an eigenfunction of L with eigenvalue c. The
actual set of eigenfunctions, along with their corresponding eigenvalues, will
depend on L.Math interlude A: Complex numbers and linear operators 37
Example 2.5. The Eigenfunctions and Eigenvalues of the
Derivative Operator
If g is an eigenfunction of the derivative operator D, it must satisfy
D[g(x)] = dg
dx = cg(x) (2.5)
This differential equation has the general solution g(x) = Aecx, where A is
an arbitrary constant, and c is the eigenvalue appearing in Equation (2.5).
Hence, g(x) = Aecx is the most general possible eigenfunction of D with
eigenvalue c. Note that in this case, any complex number can be an eigen￾value of D.
Of course, most functions are not eigenfunctions of a given operator.
For example, in the case of the derivative operator, it is obvious that
D[sin(x)] = cos(x) ̸= c sin(x)
D[x
2
] = 2x ̸= cx2
D[ln(x)] = 1/x ̸= c ln(x)
Thus, an eigenfunction is a very special kind of function.
Example 2.6. The Eigenfunctions and Eigenvalues of the
One-Dimensional Parity Operator
Find the eigenfunctions and eigenvalues of the one-dimensional parity op￾erator, Π, defined by
Π[g(x)] = g(−x)
i.e., the parity operator reflects the function g(x) through x = 0 (Fig￾ure 2.6).
Again, we must solve the equation Π[g(x)] = cg(x). Using the definition
of the parity operator, we get
Π[g(x)] = g(−x) = cg(x) (2.6)
This equation has no obvious solution, so we apply Π twice to the function
g(x):
Π
2
[g(x)] = Π[g(−x)] = g(x) (2.7)38 Quantum Mechanics: An Accessible Introduction
x x
g(x) Π[g(x)]
Fig. 2.6 The one-dimensional parity operator Π reflects the function g(x) through x = 0.
(Note that the notation L
n[g(x)] means to apply the operator n times to
the function g(x), e.g., L
3
[g(x)] = L[L[L[g(x)]]].) If we assume that g(x) is
an eigenfunction of Π with eigenvalue c, we also have
Π
2
[g(x)] = Π[cg(x)] = cΠ[g(x)] = c
2
g(x) (2.8)
Combining Equations (2.7) and (2.8), we get
g(x) = c
2
g(x)
which has the solutions c = ±1. Note that in contrast to Example 2.5, there
are not an infinite number of eigenvalues but only two discrete eigenvalues.
We can now determine what functions correspond to each eigenvalue. For
c = +1, Equation (2.6) gives g(−x) = g(x), so that g(x) is an arbitrary
even function. For c = −1, Equation (2.6) yields g(−x) = −g(x), so g(x)
is an arbitrary odd function.
Note that when an eigenfunction of a linear operator is multiplied by an
arbitrary constant, it remains an eigenfunction with the same eigenvalue
(Problem 2.11).
PROBLEMS
2.1 Evaluate all of the following, and express all of your final answers
in the form a + bi:
(a) i(2 − 3i)(3 + 5i)Math interlude A: Complex numbers and linear operators 39
(b) i/(i − 1)
(c) (1 + i)
30
2.2 In the complex plane, there are 5 different fifth roots of 1. Deter￾mine the five values for √5
1, and express them in polar form.
2.3 Suppose that z = 1 + e
iθ. Calculate z
∗
, z
2
, and |z|
2
. Your expres￾sion for |z|
2
should not contain any imaginary numbers.
2.4 Suppose that a complex number z has the property that z
∗ = z.
What does this indicate about z?
2.5 Reduce i
i
to a real number.
2.6 What is wrong with the following argument?
r
1
−1
=
√
1
√
−1
√
−1 =
1
i
i =
1
i
(2.9)
Therefore,
(i)(i) = 1
−1 = 1
(2.10)
2.7 Determine which of the following are linear operators, and which
are not.
(i) The parity operator Π[f(x)] = f(−x).
(ii) The translation operator T[f(x)] = f(x + 1).
(iii) The operator L[f(x)] = f(x) + 1.
2.8 Consider the identity operator I, defined by I[f(x)] = f(x).
(a) Show that I is a linear operator.
(b) Find the eigenfunctions and corresponding eigenvalues of I.
2.9 Suppose that the function f(x) is an eigenfunction of the linear
operator P with eigenvalue p, and f(x) is also an eigenfunction of
the linear operator Q with eigenvalue q. Show that P Q[f(x)] =40 Quantum Mechanics: An Accessible Introduction
QP[f(x)], where P Q[f(x)] means to first apply the operator Q to
f(x), and then apply P to the result.
2.10 Consider the square of the derivative operator D2
.
(a) Show that D2
is a linear operator.
(b) Find the eigenfunctions and corresponding eigenvalues of D2
.
(c) Give an example of an eigenfunction of D2 which is not an
eigenfunction of D.
2.11 Let f(x) be an eigenfunction of a linear operator L with eigenvalue
a. Show that cf(x) (where c is a constant) is an eigenfunction of
L with eigenvalue a.
2.12 Consider the following operator L:
L[f(x)] = Z x
0
f(s) ds
(a) Show that L is a linear operator.
(b) Find the eigenfunctions of L, or show that L has no eigenfunc￾tions.Chapter 3
The Schr¨odinger equation
The Schr¨odinger equation, developed by Erwin Schr¨odinger and published
in 1926, forms the basis of modern quantum mechanics. Indeed, it is one of
the most important equations in all of physics, and much of the remainder
of this book will be based on it.
The way in which the Schr¨odinger equation describes the behavior of
particles is fundamentally different from the corresponding description in
classical mechanics. In classical mechanics, a particle has a fixed position in
three-dimensional space, given by the vector r. This position is a function
of time, t, so a complete description of the motion of the particle is given by
its trajectory, r(t); the main problem in classical mechanics is to determine
r(t).
In contrast, in quantum mechanics, a particle no longer has a definite
trajectory r(t). Instead, we start with the idea from Chapter 1 that matter
can be treated as a wave. In particular, we will assume that any particle
can be described by a wave function, Ψ(r, t), which gives the amplitude of
the wave as a function of the three-dimensional position in space, r, and of
the time, t.
This leads to an obvious question: what is the physical meaning of
Ψ(r, t), i.e., what does it tell us about the particle? Although we must
abandon the hope of determining the position of the particle as a function
of time, what we can derive from the wave function is the probability that
the particle will be found in a given region of space at a given time. Fur￾thermore, all of the other observable physical characteristics of this particle
(e.g., its momentum, energy, etc.) are related to Ψ(r, t). The relationship
between observable quantities and Ψ(r, t) will be examined in more detail
in Section 3.2. First, however, we will derive the equation which determines
Ψ(r, t): the Schr¨odinger equation.
4142 Quantum Mechanics: An Accessible Introduction
3.1 Derivation of the Schr¨odinger Equation
Unfortunately, it is no more possible to “derive” the Schr¨odinger equation
from purely mathematical arguments than it is to derive Newton’s law of
gravitation or F = ma. The only basis for developing a physical theory is
that it describes experimental reality. What we can do, however, is make
some reasonable assumptions and show that these lead to the Schr¨odinger
equation. We will then solve the Schr¨odinger equation and discover that it
does, indeed, make numerous correct predictions. In particular, it provides
an accurate description of the hydrogen atom and many other phenomena
at the atomic and subatomic scales.
For simplicity, first consider a wave in one dimension, travelling in the
+x direction. A wave with frequency ν and wavelength λ can be written
in the form
Ψ(x, t) = A cos(2πx/λ − 2πνt) (3.1)
What does Equation (3.1) mean? The shape of the wave can be derived
by fixing t and treating Ψ as a function only of x. Then Equation (3.1)
represents a wave, frozen in time, which oscillates sinusoidally as a func￾tion of x with wavelength λ and amplitude A. Alternately, we can fix the
position x on the wave to be a constant and consider how Ψ varies with t;
in this case, we see that our fixed point on the wave oscillates up and down
sinusoidally with frequency ν and amplitude A (Figure 3.1). To simplify
this wave equation, it is conventional to make the substitutions:
k = 2π/λ
and
ω = 2πν
where k is called the wave number, and ω is the angular frequency. In terms
of k and ω, Equation (3.1) simplifies to
Ψ = A cos(kx − ωt) (3.2)
We note one other property of the wave described by Equation (3.2) (or
Equation (3.1)); it represents a wave travelling to the right with velocity
ω/k. To see this, consider, for example, the maximum xmax in the ampli￾tude of the wave at x = 0, t = 0. At some later time t, this will still be a
maximum of the cosine function as long as kxmax − ωt = 0, or
xmax = (ω/k)t (3.3)The Schr¨odinger equation 43
￾
￾
Fix t, vary x x
Fix x, vary t
Fig. 3.1 The equation Ψ(x, t) = A cos(2πx/λ − 2πνt) represents a wave with amplitude
A and wavelength λ, oscillating in time with frequency ν.
Equation (3.3) shows that the maximum moves in the +x direction, i.e., to
the right, with velocity ω/k. This same argument can be made about any
other point on the wave, which means that the entire wave moves in the
+x direction with velocity
v = ω/k
This velocity is called the phase velocity (Figure 3.2).
So far, we have confined our attention to one dimension, but Equa￾tion (3.2) can be generalized to three dimensions by using a three￾dimensional position vector r in place of the one-dimensional position x.
In this case, we must also take k to be a vector, k, called the wave vecto44 Quantum Mechanics: An Accessible Introduction
Y
Y
t = 0
x
x
t =
1
k
1
xmax v
xmax
Fig. 3.2 The equation Ψ(x, t) = A cos(kx − ωt) represents a wave moving in the +x
direction with phase velocity ω/k.
and Equation (3.2) becomes
Ψ(r, t) = A cos(k·r − ωt)
From our previous argument, this represents a wave travelling in the k
direction. However, this is not the most general possible form for such a
wave. A sine function serves just as well as a cosine function to represent
an oscillating wave, so the most general form for a wave moving in the k
direction is
Ψ(r, t) = A1 cos(k·r − ωt) + A2 sin(k·r − ωt) (3.4)The Schr¨odinger equation 45
where A1 and A2 are constants which determine both the amplitude and
phase of the wave. Although this is a perfectly acceptable way to represent
a general wave, it is somewhat awkward. As an alternative, we can write
Ψ(r, t) = Bei(k·r−ωt)
(3.5)
where B is now a complex number, and in classical mechanics, it is under￾stood that we take the real part of the right-hand side of Equation (3.5).
Equations (3.4) and (3.5) are completely equivalent. To see this expand
Equation (3.5) out using Equation (2.2) and write B = B1 + iB2. Then
Equation (3.5) becomes
Ψ(r, t) = B1 cos(k·r − ωt) − B2 sin(k·r − ωt)
+ iB2 cos(k·r − ωt) + iB1 sin(k·r − ωt) (3.6)
By choosing B1 = A1 and B2 = −A2 and taking the real part of the right￾hand side of Equation (3.6), we get the same result as Equation (3.4). We
will now use Equation (3.5) to represent our wave function.
In order to derive a plausible equation for the wave function, we need
to make a connection between k, ω, and the momentum and energy of
the particle. In Chapter 1 we noted two relations between the properties
of waves and physically-measurable quantities. Specifically, for light, the
energy E and the frequency ν are related by
E = hν
and for matter waves, the momentum p and the wavelength λ are related
by
p = h/λ
We will assume that both of these properties apply to matter waves. The
equation for energy, E = hν, corresponds to
E = (h/2π)(2πν) = ℏω
and the momentum equation, p = h/λ, becomes
p = (h/2π)(2π/λ) = ℏk (3.7)
We can generalize this equation from one dimension to three dimensions. In
three dimensions, k points in the direction of motion of the particle, which
is also the direction of the momentum vector, p. Hence, Equation (3.7)
becomes
p = ℏk46 Quantum Mechanics: An Accessible Introduction
For a non-relativistic particle with mass m and with no potential energy,
the relationship between p and E is given by
E =
p
2
2m
(3.8)
It is now possible to generate expressions for E and p from Equa￾tion (3.5) by taking the appropriate derivatives. Taking the derivative of
Equation (3.5) with respect to time, we get
∂Ψ
∂t = −iωBei(k·r−ωt)
Multiplying both sides by iℏ gives energy on the right-hand side:
iℏ
∂Ψ
∂t = ℏωBei(k·r−ωt)
= EΨ (3.9)
Note that iℏ(∂/∂t) is a linear operator, and Ψ is an eigenfunction of this
operator with eigenvalue E.
Now we need to find a similar operator which gives the momentum p.
Expanding the dot product in Equation (3.5) gives
Ψ(r, t) = Bei(kxx+kyy+kzz−ωt)
so that
∂Ψ
∂x = ikxBei(kxx+kyy+kzz−ωt)
∂Ψ
∂y = ikyBei(kxx+kyy+kzz−ωt)
∂Ψ
∂z = ikzBei(kxx+kyy+kzz−ωt)
Then
∇Ψ = ˆx
∂Ψ
∂x + ˆy
∂Ψ
∂y + ˆz
∂Ψ
∂z
= (ikxxˆ + ikyyˆ + ikzzˆ)Bei(kxx+kyy+kzz−ωt)
= ikΨ
Since we want p = ℏk to multiply Ψ on the right-hand side, we multiply
both sides by −iℏ:
−iℏ∇Ψ = ℏkΨ = pΨThe Schr¨odinger equation 47
In summary, we now have two operators for which Ψ is an eigenfunction;
one gives the energy E as the eigenvalue, and the other gives the momentum
p as the eigenvalue:
iℏ
∂Ψ
∂t = EΨ
−iℏ∇Ψ = pΨ
We now derive an equation which corresponds to Equation (3.8). Applying
the momentum operator −iℏ∇ twice to Ψ produces two factors of p:
(−iℏ∇)·(−iℏ∇)Ψ = p·pΨ
= p
2Ψ
Hence,
−ℏ
2∇2Ψ = p
2Ψ
(Recall that ∇2
is shorthand for ∇·∇ = ∂
2/∂x2 + ∂
2/∂y2 + ∂
2/∂z2
.) Then
−
ℏ
2
2m
∇2Ψ = p
2
2m
Ψ (3.10)
The right-hand sides of Equations (3.9) and (3.10) are manifestly equal,
since p
2/2m = E. Then equating the left-hand sides of these equations
gives us a differential equation satisfied by Ψ:
−
ℏ
2
2m
∇2Ψ = iℏ
∂Ψ
∂t (3.11)
So far, all we have shown is that the wave function given in Equa￾tion (3.5) satisfies Equation (3.11), and further, that it is an eigenfunction
of the operators on the left-hand and right-hand sides of Equation (3.11)
with eigenvalues p
2/2m and E, respectively. It is at this point that we
make an unjustified leap: what happens if we now add a potential energy
V to the system? In a classical system, the total energy is just the sum of
the kinetic and potential energies:
p
2
2m
+ V = E
This suggests that we modify Equation (3.11) to read
−
ℏ
2
2m
∇2Ψ + V Ψ = iℏ
∂Ψ
∂t (3.12)
(Note that unlike the kinetic energy and total energy, which correspond to
operators containing various derivatives, the operator corresponding to the
potential energy is simply multiplication of Ψ by V .)48 Quantum Mechanics: An Accessible Introduction
Equation (3.12) is the Schr¨odinger equation, possibly the most impor￾tant equation in all of 20th-century physics. Note that we have not derived
this equation in a mathematical sense. We have constructed Equa￾tion (3.12) so that for V = 0, the equation will be satisfied by the wave
function Ψ = e
i(k·r−ωt)
. However, this particular wave function will not
satisfy Equation (3.12) if V ̸= 0. We simply postulate that Equation (3.12)
will give the “correct” wave function Ψ for any potential V . We will see that
the predictions of the Schr¨odinger equation do agree with a wide variety of
physical phenomena.
In its most general form, Ψ is a complex function of three spatial coor￾dinates x, y, and z, and of the time t. The potential V , in general, is also a
function of x, y, z, and t. Hence, in the most general case, Equation (3.12)
is really shorthand for
−
ℏ
2
2m

∂
2Ψ(x, y, z, t)
∂x2
+
∂
2Ψ(x, y, z, t)
∂y2
+
∂
2Ψ(x, y, z, t)
∂z2

+ V (x, y, z, t)Ψ(x, y, z, t) = iℏ
∂Ψ(x, y, z, t)
∂t
(3.13)
Most practical applications of the Schr¨odinger equation involve a simplifica￾tion of the most general case, e.g., motion in only one dimension, potentials
which are independent of time, etc. For these cases, the Schr¨odinger equa￾tion assumes a much simpler form than Equation (3.13). For example, for
a particle moving in one dimension, the Schr¨odinger equation becomes
−
ℏ
2
2m
∂
2Ψ(x, t)
∂x2
+ V (x, t)Ψ(x, t) = iℏ
∂Ψ(x, t)
∂t
Example 3.1. A Solution of the One-Dimensional Schr¨odinger
Equation
Consider the one-dimensional infinite square-well potential of width a,
shown in Figure 3.3. The potential V (x) is given by
V (x) = 0, for 0 ≤ x ≤ a
V (x) = ∞, for x < 0 or x > a
Of course, no physical potential can be truly infinite, but this potential
will be a good approximation for any system with sharp potential barriers
such that V ≫ E. The infinite potential barriers force Ψ(x, t) to be zero
outside of the potential well, and give the boundary conditions Ψ(0, t) = 0The Schr¨odinger equation 49
and Ψ(a, t) = 0. (This will be discussed in more detail in Chapter 4.) Note
further that the potential in this case is independent of time.
For 0 ≤ x ≤ a, the potential is zero, so the Schr¨odinger equation can be
written as
−
ℏ
2
2m
∂
2Ψ(x, t)
∂x2
= iℏ
∂Ψ(x, t)
∂t (3.14)
To solve this equation, we assume that the solution has the form
Ψ(x, t) = ψ(x)χ(t) (3.15)
where ψ is a function only of x and is independent of t, while χ is a function
only of t and is independent of x. How do we know that the solution of
Equation (3.14) can be written in the form of Equation (3.15)? In fact, we
don’t. The only way to determine if the solution has this form is to see if
we can find functions ψ(x) and χ(t) for which Ψ(x, t) = ψ(x)χ(t) satisfies
Equation (3.14). However, many partial differential equations in physics
do, in fact, yield solutions of the form given in Equation (3.15). (Of course,
we wouldn’t be introducing this solution if it didn’t work in this case!) This
general method of solution is called separation of variables.
Substituting Equation (3.15) into Equation (3.14) gives
−
ℏ
2
2m
∂
2ψ(x)
∂x2
χ(t) = iℏψ(x)
∂χ(t)
∂t
x
V(x)
x = 0 x = a
Fig. 3.3 The infinite square-well potential.50 Quantum Mechanics: An Accessible Introduction
and dividing both sides by (−ℏ
2/2m)ψ(x)χ(t) yields
1
ψ(x)
∂
2ψ(x)
∂x2
= −
2mi
ℏ
1
χ(t)
∂χ(t)
∂t (3.16)
Note that the left-hand side of Equation (3.16) is a function only of x and
is independent of t, while the right-hand side is a function only of t and is
independent of x. This apparent contradiction can be resolved by noting
that there is only one function that satisfies both of these requirements:
a constant, which is independent of both x and t. Setting both sides of
Equation (3.16) equal to the constant C, we get
d
2ψ(x)
dx2
= Cψ(x) (3.17)
and
−
2mi
ℏ
dχ(t)
dt = Cχ(t) (3.18)
where the partial derivatives have become total derivatives, since each equa￾tion now contains only a single independent variable.
Consider first the equation for ψ(x). The general solution to Equa￾tion (3.17) is either a sum of two exponentials with real arguments (for
C > 0) or a sum of two trigonometric functions with real arguments (for
C < 0). However, the boundary conditions give an additional constraint
on the solution. The infinite barriers produce Ψ(0, t) = 0 and Ψ(a, t) = 0,
which means that ψ(0) = ψ(a) = 0. However, a sum of two exponentials
with real arguments has at most one value of x for which ψ(x) = 0. Hence,
ψ(x) must be a sum of trigonometric functions, namely
ψ(x) = A1 sin √
−Cx + A2 cos √
−Cx (3.19)
where A1 and A2 are constants, and C must be negative, so −C is positive.
The condition that ψ(0) = 0 means that A2 = 0 in Equation (3.19), giving
ψ(x) = A1 sin √
−Cx
while the condition ψ(a) = 0 can be satisfied for
√
−Ca = nπ, n = 1, 2, 3, . . . (3.20)
We will examine the general solution in more detail in Chapter 4; here we
will simply make use of a single solution, n = 1, which gives
C = −π
2
/a2
and
ψ(x) = A1 sin πx
a
The Schr¨odinger equation 51
Now we can solve for χ(t) using Equation (3.18). Taking C = −π
2/a2
in this equation gives
dχ
dt = −
iℏπ
2
2ma2
χ
which has the solution
χ = A3e
−iℏπ
2
t/2ma2
Combining the solutions for ψ(x) and χ(t) into an expression for Ψ(x, t)
gives
Ψ(x, t) = A sin πx
a

e
−iℏπ
2
t/2ma2
, for 0 ≤ x ≤ a
= 0, for x < 0 or x > a
In this solution, A = A1A3 remains an arbitrary constant. However, the
value of A will be determined in the next section, when we examine the
physical interpretation of the wave function.
Note that we have found only a single solution corresponding to n = 1
in Equation (3.20). The general solution, as well as the physical significance
of the values for n, will be examined in the next chapter.
3.2 The Meaning of the Wave Function
In the previous section, we derived the Schr¨odinger equation, which de￾scribes the behavior of the wave function Ψ associated with a particle mov￾ing in a potential V . This leaves an obvious question: what does Ψ tell us
about the physical behavior of the particle?
The interpretation of Ψ was provided by Max Born. Recall that Ψ(r, t)
is complex, so it cannot by itself represent a physically-measurable quan￾tity. Born argued that the square of the absolute value of the wave function,
|Ψ(r, t)|
2 = Ψ∗
(r, t)Ψ(r, t), which is always a real number, gives the proba￾bility per unit volume of finding the particle at the position r at the time
t. Hence Ψ∗Ψ is called the probability density. Since probability is a pure
number, the probability density must have units of 1/volume in three di￾mensions and 1/length in one dimension. Note that this represents the
abandonment of one of the basic ideas of classical mechanics: a particle no
longer has a definite position in space that can be described as a known
function of time. Instead, the wave function is used to calculate the proba￾bility of finding the particle in a given region of space.52 Quantum Mechanics: An Accessible Introduction
As an example, consider the wave function derived in Example 3.1 for
a particle in an infinite square well:
Ψ(x, t) = A sin πx
a

e
−iℏπ
2
t/2ma2
, for 0 ≤ x ≤ a
= 0, for x < 0 or x > a (3.21)
This solution satisfies the Schr¨odinger equation for an arbitrary value
of A. This is a result of the fact that if Ψ is any solution of the Schr¨odinger
equation, then cΨ is also a solution for any complex number c:
−
ℏ
2
2m
∇2Ψ + V Ψ = iℏ
∂Ψ
∂t
−c
ℏ
2
2m
∇2Ψ + cV Ψ = ciℏ
∂Ψ
∂t
−
ℏ
2
2m
∇2
(cΨ) + V (cΨ) = iℏ
∂(cΨ)
∂t
Hence, the value of A cannot be determined from the Schr¨odinger equation
alone. But it can be determined from the definition of the probability
density.
According to the Born prescription, the probability density is
Ψ
∗Ψ = 
A
∗
sin πx
a

e
iℏπ
2
t/2ma2
 A sin πx
a

e
−iℏπ
2
t/2ma2

= |A|
2
sin2
πx
a

(3.22)
for 0 ≤ x ≤ a, and Ψ∗Ψ = 0 for x outside of this range. (Note also that
the time t has dropped out of the expression for the probability density;
for this wave function the probability density is independent of time.) Now
we require that the probability density satisfy an additional requirement,
namely
Z
Ψ
∗Ψ d
3
r = 1 (3.23)
where the integral is taken over all of space. The justification for
Equation (3.23) follows from the definition of the probability density; if
Ψ∗
(r, t)Ψ(r, t) gives the probability per unit volume of finding the particle
at position r, then the integral of this quantity over all of space gives the
probability of finding it somewhere, which must be 1. A wave function
which satisfies Equation (3.23) is said to be normalized.
For the infinite square-well wave function given by Equation (3.21), we
can substitute Ψ∗Ψ from Equation (3.22) into Equation (3.23) to find theThe Schr¨odinger equation 53
x
√2
a
Y
0 a
Fig. 3.4 The normalized wave function given by Equation (3.25) for a particle in an
infinite square-well potential at time t = 0.
value of the constant A:
Z a
0
|A|
2
sin2
πx
a

dx = 1
|A|
2
1
2
a = 1
so that
|A|
2 =
2
a
(3.24)
If we take A to be a positive real number, then Equation (3.24) has a unique
solution: A =
p
2/a, and our normalized wave function is then
Ψ(x, t) = r
2
a
sin πx
a

e
−iℏπ
2
t/2ma2
, for 0 ≤ x ≤ a
= 0, for x < 0 or x > a (3.25)
This wave function is shown in Figure 3.4 at t = 0.
Note, however, that Equation (3.24) has an infinite number of other
solutions. We could just as easily have taken A = −
p
2/a. More generally,
it is easy to show (see Exercise 3.7) that A can be any complex number of
the form A = e
iθp
2/a, where θ is an arbitrary (real) constant. This leads
to an obvious question: which value of A do we choose? The answer is that
it doesn’t matter. We will see that all observable quantities depend only on
|A|
2
, not on A itself. Hence, any value of A which satisfies Equation (3.24)
will give the same predictions for any measurements that we make. In
practice, it is conventional to take (as we have) A to be real and positive.54 Quantum Mechanics: An Accessible Introduction
The Born interpretation tells us that the probability per unit length
that the particle will be found at a point x is given by Ψ∗
(x, t)Ψ(x, t).
Therefore, the probability of finding the particle in some region is simply
the integral of Ψ∗Ψ over that region.
Example 3.2. The Probability of Finding a Particle at a Particular
Location
Consider the particle described by the wave function of Equation (3.25).
What is the probability P(x < ϵ) that the particle lies within a distance ϵ
of the left-hand wall of the square well with ϵ ≪ a?
The desired probability is given by
P(x < ϵ) = Z ϵ
x=0
Ψ
∗Ψ dx
=
Z ϵ
x=0
2
a
sin2 πx
a
dx
=
ϵ
a
−
1
2π
sin
2πϵ
a
(3.26)
In the limit where ϵ ≪ a, the second term in Equation (3.26) can be
expanded as sin(x) ≈ x − x
3/6 + · · · , giving
P(x < ϵ) ≈
2
3
π
2
 ϵ
a
3
Although Ψ∗Ψ can be used to derive the probability of finding the particle at
a particular location, it contains more information than this. We can treat
Ψ∗Ψ as the probability distribution function for the position of the particle.
To see how this works, consider first a much more practical example: the
calculation of a grade point average. If fA is the fraction of a student’s
total grades which are A’s, fB is the fraction which are B’s, and so on, then
the student’s grade point average is simply
grade point average = fA4 + fB3 + fC2 + fD1 + fF0
Similarly, for any discrete distribution p(j), the average value of j (denoted
⟨j⟩) is just
⟨j⟩ =
X
j
P(j)j (3.27)
If the quantity of interest is continuous rather than discrete, then Equa￾tion (3.27) changes from a sum to an integral, giving
⟨x⟩ =
Z
P(x)x dx
where the integral is taken over all allowed values of x.The Schr¨odinger equation 55
Now consider a large number of identical particles all described by the
wave function Ψ, and suppose we measure the position of every one of these
particles. Since Ψ∗Ψ is the distribution function for each of the individual
particle positions, it follows that the average position of the particles, ⟨x⟩,
will be given by
⟨x⟩ =
Z ∞
−∞
Ψ
∗
(x, t)xΨ(x, t) dx (3.28)
(Of course, Equation (3.28) gives the theoretical average position; the actual
measured average will tend toward this value as the number of measure￾ments goes to infinity.) Note that we have written the right-hand side in
a peculiar way, inserting x between Ψ∗ and Ψ. The reason for this will
become apparent shortly.
Example 3.3. The Average Position of a Particle
Consider the wave function for the infinite square well given in Equa￾tion (3.25). The mean value for the position of the particle is
⟨x⟩ =
Z ∞
−∞
Ψ
∗
(x, t)xΨ(x, t) dx
=
Z a
0
2
a
sin2
πx
a

x dx
=
a
2
This result, that ⟨x⟩ = a/2, is exactly what we would expect, since the
wave function is symmetric and is centered at a/2.
What about other observable quantities? Consider, for instance, the
momentum. First consider the special case where Ψ is an eigenfunction of
the momentum operator, so that
−iℏ∇Ψ = pΨ
or, in the one-dimensional case,
−iℏ
∂Ψ
∂x = pΨ
For this special case, we have
Z ∞
−∞
Ψ
∗
(x, t)

−iℏ
∂
∂x
Ψ(x, t) dx =
Z ∞
−∞
Ψ
∗
(x, t)pΨ(x, t) dx
= p (3.29)56 Quantum Mechanics: An Accessible Introduction
assuming that Ψ is normalized. In this case, the integral in Equation (3.29)
gives the momentum p. Now we postulate that even if Ψ is not an eigen￾function of the momentum operator, the average value of the momentum
will be given by
⟨p⟩ =
Z ∞
−∞
Ψ
∗
(x, t)

−iℏ
∂
∂x
Ψ(x, t) dx
This brings us to one of the central ideas in quantum mechanics: every
quantity we can measure, such as position, momentum, energy, angular
momentum, etc., is associated with a corresponding linear operator. Mea￾surable quantities are called, in quantum mechanics, observables, and we
have already noted the correspondence between several observables and
their operators:
OBSERVABLE ↔ OPERATOR
position x ↔ x
momentum p ↔ −iℏ∇
energy E ↔ iℏ
∂
∂t
When a wave function Ψ is an eigenfunction of an operator, then it
represents a state in which the particle has a definite, fixed value for that
observable. For example, if
Ψ = e
−iky−iωt (3.30)
then we have
−iℏ∇Ψ = −iℏyˆ
∂Ψ
∂y
= −ℏkyˆΨ
Thus, the wave function given by Equation (3.30) represents a particle in
a state of definite momentum: it has momentum ℏk in the −y direction.
If the momentum of this particle is measured, the result will be a single,
definite answer: the momentum will be −ℏkyˆ.
In classical physics, of course, all measurements behave this way. A
particle is always assumed, for instance, to have a definite momentum.
While experimental error may limit the precision with which the momentum
of a particle can be measured, it is always taken to be a well-defined, fixed
quantity. This assumption is not true in quantum mechanics. Consider, forThe Schr¨odinger equation 57
example, the square well wave function in Equation (3.25). If we apply the
one-dimensional momentum operator to this wave function, we get
−iℏ
∂
∂xΨ = −iℏ
∂
∂xr
2
a
sin πx
a

e
−iℏπ
2
t/2ma2
= −iℏ
π
a
r
2
a
cos πx
a

e
−iℏπ
2
t/2ma2
which is manifestly not equal to a constant times Ψ. Thus, the square￾well wave function is not an eigenfunction of the momentum operator, and
it represents a particle which is not in a state of definite momentum. Of
course, if the momentum of the particle is measured, a definite value is
always obtained, but there is no way to predict ahead of time what this
value will be. This is one of the places where quantum mechanics differs
radically from classical physics: particles can be in states in which the
momentum, position, or energy of the particle is not well-defined.
However, what is well-defined is the mean value of any observable, called
the expectation value. The expectation value can be calculated for any
observable, using the corresponding operator. If the operator O corresponds
to an observable o, then the expectation value of o is just
⟨o⟩ =
Z
Ψ
∗
(r, t)OΨ(r, t) d
3
r
For example, for a one-dimensional wave function Ψ(x, t), we get
⟨p⟩ =
Z ∞
−∞
Ψ
∗

−iℏ
∂
∂x
Ψ dx
⟨x⟩ =
Z ∞
−∞
Ψ
∗xΨ dx
⟨E⟩ =
Z ∞
−∞
Ψ
∗

iℏ
∂
∂t
Ψ dx
(IMPORTANT: Note that the wave function must be normalized before the
expectation value is computed!)
Example 3.4. Expectation Value of the Momentum
Consider the expectation value of the momentum for a particle with the58 Quantum Mechanics: An Accessible Introduction
wave function given by Equation (3.25):
⟨p⟩ =
Z ∞
−∞
Ψ
∗

−iℏ
∂
∂x
Ψ dx
=
Z a
0
r
2
a
sin πx
a

e
iℏπ
2
t/2ma2

−iℏ
∂
∂x r
2
a
sin πx
a

e
−iℏπ
2
t/2ma2
dx
=
Z a
0
2
a
π
a
(−iℏ) sin πx
a

cos πx
a

dx
= 0
Thus, the expectation value of the momentum is zero. This means that if
p is measured for a set of particles, all described by Equation (3.25), there
is no way to predict in advance the outcome of an individual measurement,
but the mean value of p, calculated by averaging over many measurements,
will tend toward zero. This result for the expectation value makes sense,
since the corresponding classical system is a particle bouncing back and
forth inside the potential well; its momentum averaged over many back￾and-forth trips is zero.
Using the same technique, the expectation value of functions of an ob￾servable can also be calculated. For a particle moving in one dimension, for
instance, we have
⟨x
2
⟩ =
Z ∞
−∞
Ψ
∗x
2Ψ dx
⟨p
2
⟩ =
Z ∞
−∞
Ψ
∗

−iℏ
∂
∂x −iℏ
∂
∂x
Ψ dx
=
Z ∞
−∞
Ψ
∗

−ℏ
2 ∂
2
∂x2

Ψ dx
3.3 The Time-Independent Schr¨odinger Equation:
Qualitative Solutions and the Origin of Quantization
Derivation of the Time-Independent Schr¨odinger Equation
In this section, we will consider a special case of the Schr¨odinger equation,
but this special case will occupy much of the remainder of this book. For
the most general version of the Schr¨odinger equation,
−
ℏ
2
2m
∇2Ψ + V (r, t)Ψ = iℏ
∂Ψ
∂tThe Schr¨odinger equation 59
the various cases of interest are all embodied in the choice of the potential
V (r, t). Now consider a special class of potentials: those for which V is a
function only of position r, and is independent of time t. This is a very
commonly encountered case; for example, the potential that an electron
feels in an atom or in a crystal lattice can be treated this way. For this
case, the Schr¨odinger equation becomes
−
ℏ
2
2m
∇2Ψ + V (r)Ψ = iℏ
∂Ψ
∂t (3.31)
It is possible to make a further simplification by considering only a par￾ticular class of solutions. We will require that the wave function Ψ be an
eigenfunction of the energy operator, iℏ(∂/∂t), so that this wave function
corresponds to a state of definite energy E. This means that
iℏ
∂Ψ(r, t)
∂t = EΨ(r, t) (3.32)
Substituting this expression for the time derivative into Equation (3.31),
we obtain
−
ℏ
2
2m
∇2Ψ(r, t) + V (r)Ψ(r, t) = EΨ(r, t) (3.33)
Equations (3.32) and (3.33) can be solved using separation of variables.
Assume a solution of the form
Ψ(r, t) = ψ(r)χ(t) (3.34)
where ψ is a function only of position, and χ is a function only of time.
Substituting this expression into Equation (3.32) gives
iℏψ(r)
∂χ(t)
∂t = Eψ(r)χ(t)
The factors of ψ(r) cancel, and the resulting equation for χ(t) reduces to
dχ(t)
dt = −
iE
ℏ
χ(t)
which has the solution
χ(t) = e
−iEt/ℏ
(3.35)
Now we substitute the expression for Ψ(r, t) from Equation (3.34) into
Equation (3.33) to yield
−
ℏ
2
2m
∇2ψ(r)χ(t) + V (r)ψ(r)χ(t) = Eψ(r)χ(t)60 Quantum Mechanics: An Accessible Introduction
Here the factor χ(t) cancels to give
−
ℏ
2
2m
∇2ψ(r) + V (r)ψ(r) = Eψ(r) (3.36)
Equation (3.36) is an extremely important version of the Schr¨odinger equa￾tion, called the time-independent Schr¨odinger equation. It can be used
whenever the potential V is independent of time to find wave functions
that are states of definite energy.
Once a solution ψ(r) to the time-independent Schr¨odinger equation is
derived, it can be used to recover the full wave function using the time￾dependent piece of the solution in Equation (3.35):
Ψ(r, t) = ψ(r)e
−iEt/ℏ
Often, however, the quantity of interest will be the time-independent wave
function, ψ(r), because many physical quantities can be derived from ψ(r)
alone, without reference to the full wave function Ψ(r, t). For instance, the
probability density for the particle, Ψ∗
(r, t)Ψ(r, t), is just
Ψ
∗
(r, t)Ψ(r, t) = ψ(r)
∗
e
iEt/ℏψ(r)e
−iEt/ℏ
= ψ
∗
(r)ψ(r)
We can also write expectation values in terms of ψ(r). The expectation
value of any observable o which corresponds to an operator O that does
not depend on time is
⟨o⟩ =
Z
ψ(r)
∗
e
iEt/ℏOψ(r)e
−iEt/ℏ
d
3
r
=
Z
ψ(r)
∗Oψ(r) d
3
r
Clearly, both the probability density and the expectation values are inde￾pendent of time. Of course, these arguments apply only to states of definite
energy, which satisfy the time-independent Schr¨odinger equation. For this
reason, such states are also called stationary states. Of course, the wave
function itself still has a time dependence, given by the factor e
−iEt/ℏ
, but
when the observable o is actually measured, the time dependent factors
cancel out in the calculation of the expectation value: e
iEt/ℏ
e
−iEt/ℏ = 1.
The time-independent Schr¨odinger equation suggests the definition of a
new operator, H, given by
H = −
ℏ
2
2m
∇2 + V (3.37)The Schr¨odinger equation 61
Then the time-independent Schr¨odinger equation can be written in the
compact form
Hψ = Eψ
so that E is the eigenvalue of H. The operator H defined by Equation (3.37)
is called the Hamiltonian operator, or just the Hamiltonian. (The Hamilto￾nian is named after William Hamilton, an Irish mathematician who died in
1865, long before the birth of quantum mechanics. The name originated in
classical mechanics, where H corresponds to the total energy of a particle.)
Qualitative Solutions and the Origin of Quantization
In attempting to solve the time-independent Schr¨odinger equation, the first
point to note (see Problem 3.8) is that if ψ1(r) and ψ2(r) are two different
solutions of the time-independent Schr¨odinger equation with the same value
of E, then ψ1(r) + ψ2(r) is also a solution with energy E. Furthermore, if
ψ(r) is a solution with energy E, then cψ(r) (where c is any complex num￾ber) is also a solution with energy E. Thus, any solution of Equation (3.36)
can always be multiplied by an arbitrary constant to obtain another solu￾tion, so we always have the freedom to normalize the wave function by the
appropriate choice of the multiplicative constant.
In Equation (3.36), the potential V (r) will generally be determined by
whatever system is under consideration. But how do we determine E, the
total energy of the system? This is generally not something that is specified
in advance. However, for many potentials, it is not possible to find solutions
for arbitrary choices of E; rather, solutions exist only for certain discrete
choices for E. This is the origin of energy quantization.
To see how this arises, consider the one-dimensional version of Equa￾tion (3.36):
−
ℏ
2
2m
d
2ψ
dx2
+ V (x)ψ = Eψ
where ψ is a function of x. This equation can be rewritten as
d
2ψ
dx2
=
2m
ℏ
2
[V (x) − E]ψ (3.38)
Assume that we have a particular potential V (x) and E, and we want to
solve for ψ.
Equation (3.38) can be used to determine the sign of d
2ψ/dx2
, which
gives the direction in which the wave function curves: if d
2ψ/dx2 > 0,
then ψ(x) is concave up, while if d
2ψ/dx2 < 0, then ψ(x) is concave down.62 Quantum Mechanics: An Accessible Introduction
c
x
Fig. 3.5 If d
2ψ/dx2 > 0 for ψ > 0, or d
2ψ/dx2 < 0 for ψ < 0, then ψ curves away from
the x-axis.
Then for E < V (x), the factor multiplying ψ on the right-hand side of
Equation (3.38) will be positive, so that d
2ψ/dx2 and ψ will have the same
sign, either both positive or both negative. If ψ > 0 and d
2ψ/dx2 > 0,
then ψ lies above the x-axis and is concave upward, while if ψ < 0 and
d
2ψ/dx2 < 0, then ψ lies below the x-axis and is concave downward. In
either case, ψ(x) will curve away from the horizontal axis (Figure 3.5).
On the other hand, if E > V (x) we can draw the opposite conclusion. In
this case, the factor multiplying ψ on the right-hand side of Equation (3.38)
will be negative, so that d
2ψ/dx2 and ψ will have opposite signs. Then
when ψ lies above the horizontal axis, the function ψ(x) will be concave
downward, while if ψ lies below the horizontal axis, it will be concave
upward. In either case, ψ(x) will curve toward the x-axis (Figure 3.6).
These different possibilities have a clear interpretation in the classical
case. If E < V (x) outside of a finite region of space, then the particle
is bound in that potential, while E > V (x) corresponds to an unbound
particle. Consider a bound particle first with the potential and energy
shown in Figure 3.7.
A classical particle with the indicated energy will oscillate back and forth
in the region between −x1 and x1, i.e., in the region for which E > V (x).
The velocity of this particle is given by conservation of energy: mv2/2 =
E − V (x). This velocity reaches zero at x = −x1 and x = x1, and the
particle moves back in the opposite direction. Note that the particle can
never enter the regions x > x1 or x < −x1, because in these regions it wouldThe Schr¨odinger equation 63
c
x
Fig. 3.6 If d
2ψ/dx2 < 0 for ψ > 0, or d
2ψ/dx2 > 0 for ψ < 0, then ψ curves toward
the x-axis.
x
E
V(x)
–x1
x1
Fig. 3.7 A particle with energy E moves in the potential shown here. Classically, the
particle is bound in the region −x1 < x < x1.
have negative kinetic energy, which is impossible. Hence, this is called the
classically forbidden region.
Now we can sketch a qualitative solution to the time-independent
Schr¨odinger equation using the behavior of ψ illustrated in Figures 3.5 and
3.6. Taking ψ > 0, we note that ψ(x) will be concave down in the region
−x1 < x < x1 and concave up outside this region. One solution, therefore,
will behave as in Figure 3.8. This solution corresponds to the lowest-energy
bound state, so it is called the ground-state wave function.64 Quantum Mechanics: An Accessible Introduction
x
–x1
x1
concave up concave up
concave
down
concave
down
c
Fig. 3.8 A function ψ(x) corresponding to the energy and potential shown in Figure 3.7.
ψ(x) is concave down in the region −x1 < x < x1 and concave up on either side of this
region. This function does not cross the x-axis, and it corresponds to the ground state.
Now we see another stark contrast between the predictions of quan￾tum mechanics and classical mechanics. The function ψ is nonzero in the
classically forbidden region, so there is a nonzero probability to find the
particle in this region. The particle can penetrate into a region that classi￾cal mechanics predicts it does not have enough energy to reach! This effect
has far-reaching consequences, some of which will be discussed in the next
chapter.
Note further that ψ must be very finely tuned in the classically forbidden
region. When E < V (x), so that ψ(x) curves away from the x-axis, the
function has a tendency to “blow up” to positive or negative infinity. This
is bad because then the wave function cannot be normalized to give a
meaningful probability density. Only by choosing the amplitude just right
will ψ(x) decline smoothly to zero, always with positive curvature, as x
goes to infinity. This “dangerous” behavior of the wave function in the
classically forbidden region has an important consequence. Suppose we
change the energy by a tiny amount, from E to E′
. Then, if we choose ψ to
go to zero on the left-hand side, when x → −∞, it will have the “wrong”
slope when it enters the classically forbidden region on the right-hand side.
Depending on the actual solution we choose, the function will either blow
up toward +∞ or cross the x-axis and fall away to −∞ (Figure 3.9).
Does this mean that the time-independent Schr¨odinger equation has
only a single solution for this particular potential? No. If the energy is
increased by a large enough amount, a second acceptable solution for ψ(x)The Schr¨odinger equation 65
x
c
Fig. 3.9 If the energy in Figure 3.7 is changed slightly, there is no longer a well￾behaved solution to the Schr¨odinger equation; the wave function blows up to either +∞
or −∞.
is encountered, which is shown in Figure 3.10. This state is called the first
excited state, since it has the lowest energy of any state beyond the ground
state. (The next state is called the second excited state, and so on.) Note
further that ψ(x) for the first excited state crosses the x-axis exactly one
time, while the ground state function does not cross the x-axis at all. This
corresponds to a general result for bound states: ψ(x) for the ground state
crosses the x-axis zero times, ψ(x) for the first excited state crosses the
x-axis one time, ψ(x) for the second excited state crosses the x-axis two
times, and so on.
Thus, for this potential, the bound-state solutions of the Schr¨odinger
equation occur only at fixed, discrete values of the energy E. This is the
origin of energy quantization: for states which are classically bound, the
time-independent Schr¨odinger equation has solutions only at discrete values
of the energy. So a particle in a bound state is no longer free to have any
energy at all; it can take on only energies which correspond to solutions of
the Schr¨odinger equation.
Now consider what happens for an unbound particle. Using the same
potential, we consider the behavior of the particle when its energy is larger
than the potential everywhere (Figure 3.11). In this case, V (x) − E < 0,
so ψ(x) curves toward the x-axis everywhere. Now ψ can no longer “blow
up,” since it never curves away from the x-axis. Therefore, if E is changed66 Quantum Mechanics: An Accessible Introduction
concave
up
concave
down
concave
up
concave
down
x
c
–x1
x1
Fig. 3.10 A second function ψ(x) corresponding to the potential shown in Figure 3.7,
with a larger energy than displayed in that figure. ψ(x) is concave up for x < −x1 and
0 < x < x1, and concave down for −x1 < x < 0 and x > x1. This function crosses the
x-axis once and corresponds to the first excited state.
x
E
V(x)
Fig. 3.11 A particle with energy E moves in the potential shown here. Since E > V (x)
everywhere, the particle is not bound in this potential.
slightly, the Schr¨odinger equation still yields an acceptable solution for
ψ(x). So while the bound states are quantized, the unbound states are not;
they can have any energy (larger than V (x)) and are not restricted to a
set of discrete energies. Note also that a single potential, such as the one
discussed here, can have both bound and unbound states.The Schr¨odinger equation 67
PROBLEMS
3.1 A particle of mass m is moving in one dimension in a potential
V (x, t). The wave function for the particle is
Ψ(x, t) = Axe−(
√
km/2ℏ)x
2
e
−i
√
k/m(3/2)t
for −∞ < x < +∞, where k and A are constants.
(a) Show that V is independent of t, and determine V (x).
(b) Normalize this wave function.
(c) Using the normalized wave function, calculate ⟨x⟩, ⟨x
2
⟩, ⟨p⟩,
and ⟨p
2
⟩.
3.2 Determine which of the following one-dimensional wave functions
represent states of definite momentum. For each wave function
that does correspond to a state of definite momentum, determine
the momentum.
(a) ψ(x) = e
ikx
(b) ψ(x) = xeikx
(c) ψ(x) = sin(kx) + i cos(kx)
(d) ψ(x) = e
ikx + e
−ikx
3.3 The wave function for a particle is Ψ(x, t) = sin(kx)[i cos(ωt/2) +
sin(ωt/2)], where k and ω are constants.
(a) Is this particle in a state of definite momentum? If so, determine
the momentum.
(b) Is this particle in a state of definite energy? If so, determine
the energy.
3.4 A particle with mass m is moving in one dimension near the speed
of light so that the relation
E = p
2
/2m
for the kinetic energy is no longer valid. Instead, the total energy
is given by
E
2 = p
2
c
2 + m2
c
4
Hence, we can no longer use the Schr¨odinger equation. Suppose
the wave function Ψ(x, t) for the particle is an eigenfunction of the
energy operator and an eigenfunction of the momentum operator,
and also assume that there is no potential energy V . Derive a linear
differential equation for Ψ(x, t).68 Quantum Mechanics: An Accessible Introduction
3.5 A particle with mass m is moving in one dimension in the potential
V (x). The particle is in a state of definite energy E, but it is not
in a state of definite momentum p. Show that ⟨p
2
⟩, ⟨V (x)⟩, and E
are related by
⟨p
2
⟩
2m
+ ⟨V (x)⟩ = E
3.6 Consider the solution to the Schr¨odinger equation for the infinite
square well with n = 2 rather than n = 1 in Equation (3.20).
Derive Ψ(x, t) for this case, and normalize this wave function.
3.7 Suppose that a wave function Ψ(r, t) is normalized. Show that the
wave function e
iθΨ(r, t), where θ is an arbitrary real number, is
also normalized.
3.8 Suppose that ψ1 and ψ2 are two different solutions of the time￾independent Schr¨odinger equation with the same energy E.
(a) Show that ψ1 + ψ2 is also a solution with energy E.
(b) Show that cψ1 is also a solution of the Schr¨odinger equation
with energy E.
3.9 A particle moves in one dimension in the potential shown here. The
energy E is shown on the graph, and the particle is in its ground
state.
x
V(x)
E
(a) Sketch ψ(x) for this particle.
(b) You make a measurement to find the particle. Indicate on your
graph the point or points at which you are most likely to find it.
3.10 A particle moves in one dimension in the potential shown here.
The energy E is shown on the graph, and the particle is in its first
excited state.The Schr¨odinger equation 69
x
V(x)
E
(a) Sketch ψ(x) for this particle.
(b) You make a measurement to find the particle. Indicate on your
graph the point or points at which you are most likely to find it.
3.11 A particle moving in one dimension is described by the function
ψ(x) shown here:
x
A C B
c
(a) You make a measurement to locate the particle. Which one of
the following is true?
(i) You will always find the particle at point B.
(ii) You are most likely to find the particle at points A or C and
least likely to find the particle at point B.
(iii) You are most likely to find the particle at points A, B, or
C.
Explain your answer.
(b) Which one of the following potentials V (x) could give rise to
this ψ(x)?70 Quantum Mechanics: An Accessible Introduction
x
x
x
V(x)
V(x)
V(x)
(i)
(ii)
(iii)Chapter 4
Solutions of the one-dimensional
time-independent Schr¨odinger
equation
In this chapter we will examine some exact solutions of the one-dimensional
time-independent Schr¨odinger equation,
−
ℏ
2
2m
d
2ψ
dx2
+ V (x)ψ = Eψ (4.1)
Of course, the real world is three-dimensional, but Equation (4.1) can be
applied whenever a particle moves only in a single direction. Consider,
for example, an electron travelling through an evacuated tube (Figure 4.1)
with an electrostatic potential Φ(x). Since the electron has charge −e, it
experiences the potential V (x) = −eΦ(x), and this system can be treated
as effectively one-dimensional. Another example is the motion of electrons
in semiconductor heterostructures. These are materials formed by joining
together two or more different semiconductors. At the junction between
the materials, the electron experiences a change in the potential, and it is
possible to construct materials with potentials that mimic some of those
considered in this chapter.
Classically, there are two possible types of states: bound states, in which
the particle is confined to move in a finite region, and unbound states, in
which the particle can escape to infinity. Because the solutions for unbound
states are quite different from those of bound states, we will treat the two
cases separately. For unbound states, we will calculate the probability that
an incident particle will reflect off of or transmit through a particular poten￾tial. For bound states, we will calculate the wave functions and energies.
As noted in the previous chapter, the bound state energy levels will, in
general, be discrete rather than continuous.
7172 Quantum Mechanics: An Accessible Introduction
V(x) = –eF(x)
e
–
x
Fig. 4.1 An electron moving in one dimension in the potential V (x) = −eΦ(x).
4.1 Unbound States: Scattering and Tunneling
In this section we will consider only the case of piecewise constant poten￾tials, i.e., potentials with step-like discontinuities (Figure 4.2). Consider a
range in x over which V (x) is a constant, V0. Then Equation (4.1) becomes
−
ℏ
2
2m
d
2ψ
dx2
+ V0ψ = Eψ
which can be rewritten as
d
2ψ
dx2
+
2m(E − V0)
ℏ
2
ψ = 0 (4.2)
This is the simplest possible version of the time-independent Schr¨odinger
equation. To find a solution, consider the general equation of the form
d
2y
dx2
+ Ay = 0 (4.3)
where A is an arbitrary constant. We try a solution of the form
y = Cemx
where both C and m are constants. Then
d
2y
dx2
= Cm2
e
mxSolutions of the one-dimensional time-independent Schr¨odinger equation 73
x
V(x)
Fig. 4.2 An example of a piecewise constant potential.
Substituting these expressions for d
2y/dx2 and y into Equation (4.3), we
obtain
m2Cemx + ACemx = 0
which is satisfied as long as m is chosen so that m2 + A = 0, while C can
have any value at all. Thus, m = ±
√
−A, and the general solution is
y = C1e
√
−Ax + C2e
−
√
−Ax (4.4)
where C1 and C2 are arbitrary constants. (Note that C1 and C2 need not
be real; they can also be complex numbers.)
This solution will have quite different behavior depending on whether A
is positive or negative. If A is negative, then the quantities under the square
roots will be positive, and the solution given by Equation (4.4) will be the
sum of a positive and a negative exponential. On the other hand, if A is
positive, then √
−A will be imaginary. In this case we take √
−A = i
√
A,
and Equation (4.4) becomes
y = C1e
i
√
Ax + C2e
−i
√
Ax (4.5)
Note that this solution can also be written as a sum of trigonometric func￾tions (see Problem 4.1):
y = D1 cos(√
Ax) + D2 sin(√
Ax) (4.6)74 Quantum Mechanics: An Accessible Introduction
c(x)
x
not OK
not OK
OK!
Fig. 4.3 Both ψ(x) and dψ(x)/dx must be continuous.
The solutions given by Equations (4.5) and (4.6) are completely equivalent,
so the question of which one to use is a matter of convenience; it will usually
be easier to use one form or the other depending on the boundary conditions
of the problem at hand.
For a particle with a given energy E moving in a piecewise constant
potential with step discontinuities such as in Figure 4.2, we will obtain
different solutions in the regions with different values of V0. The constants
appearing in the solutions must then be chosen so that the wave functions
“join up” at each step, i.e., both ψ(x) and dψ(x)/dx must be continuous
(Figure 4.3).
We can now apply this set of solutions to the Schr¨odinger equation in
the form of Equation (4.2). Consider first the simplest case, where V0 = 0,
so we are dealing with a “free particle” and no potential. In this case we
clearly have E − V0 > 0, so we choose a solution of the form given in
Equation (4.5) or (4.6). The former will be more convenient for our current
purposes; we obtain
ψ = C1e
i(
√
2mE/ℏ)x + C2e
−i(
√
2mE/ℏ)xSolutions of the one-dimensional time-independent Schr¨odinger equation 75
The physical interpretation of this solution is clearer if we use it to derive
the time-dependent wave function,
Ψ(x, t) = ψ(x)e
−iEt/ℏ
= C1e
i[(√
2mE/ℏ)x−Et/ℏ] + C2e
i[−(
√
2mE/ℏ)x−Et/ℏ]
(4.7)
Now recall that energy is related to momentum via E = p
2/2m, so that
√
2mE = p. Furthermore, in the previous chapter we derived relations
between momentum and wavenumber (p = ℏk) and between energy and
frequency (E = ℏω). Substituting all of these into Equation (4.7), we get
Ψ(x, t) = C1e
i(kx−ωt) + C2e
i(−kx−ωt)
(4.8)
We have already seen wave functions of this form in Chapter 3; the
function e
i(kx−ωt)
represents a wave moving in the +x direction (i.e., to
the right in a conventional coordinate system) with energy ℏω and mo￾mentum ℏk, while the second term represents a particle moving to the left
with energy ℏω and momentum −ℏk. We know that Equation (4.8) is an
eigenfunction of the energy operator, since it was derived using the time￾independent Schr¨odinger equation. Now consider what happens if we apply
the momentum operator to each term separately:
−iℏ
∂
∂xC1e
i(kx−ωt) = ℏkC1e
i(kx−ωt)
−iℏ
∂
∂xC2e
i(−kx−ωt) = −ℏkC2e
i(−kx−ωt)
As expected, the first term in our wave function, which represents a right￾ward moving particle, is an eigenfunction of the momentum operator with
momentum ℏk. Similarly, the second term is an eigenfunction of the mo￾mentum operator with momentum −ℏk. On the other hand, it is easy
to verify that the total wave function (if C1 ̸= 0 and C2 ̸= 0) is not an
eigenfunction of the momentum operator (see Problem 4.2).
It might seem puzzling that the general form for the wave function
of a free particle moving in one dimension consists of pieces representing
particles simultaneously moving both to the left and to the right. Consider,
however, a particle reflecting off of a boundary. The wave function in this
case simultaneously represents both the rightward-moving incident particle
and the leftward-moving reflected particle. Unlike classical mechanics where
the motion of the particle is specified by its position as a function of time
x(t), and x simply tracks the particle as it first moves to the right and later
moves to the left, the quantum mechanical wave function Ψ simultaneously
encodes the particle moving to the right and reflecting back to the left.76 Quantum Mechanics: An Accessible Introduction
x
Y*Y
Fig. 4.4 Ψ∗Ψ for a wave packet generated by summing over all waves in the interval
k = 0 to k = k0, where each wave is given equal amplitude.
The constants C1 and C2 in Equation (4.8) are free parameters which
can be chosen to match the physical system. Hence, a free particle moving
purely to the right can be expressed in terms of Equation (4.8) by setting
C2 = 0. Similarly, a free particle moving to the left has a wave function
given by Equation (4.8) with C1 = 0.
What do we know about the position of the particle? Consider the wave
function for a purely rightward-moving particle,
Ψ(x, t) = C1e
i(kx−ωt)
(4.9)
Calculating Ψ∗Ψ gives
Ψ∗Ψ = C
∗
1
e
−i(kx−ωt)C1e
i(kx−ωt)
= C
∗
1C1
which is independent of position. This means that the particle is equally
likely to be found anywhere in space! In fact, Equation (4.9) represents an
idealization. In theory, a particle which is in an exact momentum state will
be spread out over an arbitrarily large distance, but in practice, a physical
particle will correspond to a sum of waves like those in Equation (4.9), each
with a slightly different momentum and energy (or, equivalently, a slightly
different k and ω). These waves can be summed to produce a value for Ψ∗Ψ
which is localized in space. Such a sum of waves is called a wave packet,
and it can be normalized. For example, in Figure 4.4, Ψ∗Ψ is shown for a
wave packet generated by summing over all waves in the interval k = 0 to
k = k0, where each wave is given equal amplitude.Solutions of the one-dimensional time-independent Schr¨odinger equation 77
x
V(x)
V = V0
V = 0
x = 0
Fig. 4.5 A step-function potential.
Scattering From Step-Function Potentials
In solving the Schr¨odinger equation for scattering in one dimension, we will
idealize the situation and treat the particles as eigenfunctions of momen￾tum; we will still be able to derive physically-interesting results for this
case. Consider first the “step-function” potential shown in Figure 4.5. The
physical location of the step in the potential is arbitrary, so we will take it
to lie at x = 0. Similarly, as in classical mechanics, we are free to choose
the zero of the potential anywhere, so we will take V = 0 for x < 0, while
V = V0 for x ≥ 0.
We can distinguish two different cases here: either E < V0, or E >
V0. In a classical system, the behavior of the particle is easy to calculate.
Consider first a classical particle moving from left to right with energy
E < V0. The particle will not be able to enter the region x > 0, and it will
simply bounce back to the left with the magnitude of its velocity unchanged.
A classical particle with E > V0 will penetrate into the region x > 0, but
the magnitude of its velocity will decrease as its momentum changes from
p1 =
√
2mE on the left-hand side of the barrier to p2 =
p
2m(E − V0) on
the right-hand side. Quantum mechanics predicts a very different behavior
as we shall now see.78 Quantum Mechanics: An Accessible Introduction
Step-Function Potential With E > V0
Consider first the high-energy case for which a classical particle will simply
travel into the x > 0 region with reduced momentum. For this case, the
Schr¨odinger equation for a constant potential, Equation (4.2), has the form
d
2ψ
dx2
+
2mE
ℏ
2
ψ = 0 (4.10)
for x < 0, and
d
2ψ
dx2
+
2m(E − V0)
ℏ
2
ψ = 0 (4.11)
for x ≥ 0. Since both E and E−V0 are positive, our solution in both regions
can be expressed in the form of either Equation (4.5) or (4.6). Either form
can be used to solve the problem, but the solution will turn out to be easier
to interpret using exponentials (Equation (4.5)) rather than trigonometric
functions. The solution to the Schr¨odinger equation in these two regions is
ψ1(x) = A1e
i(
√
2mE/ℏ)x + B1e
−i(
√
2mE/ℏ)x
, x < 0
ψ2(x) = A2e
i
√
2m(E−V0)/ℏ

x + B2e
−i
√
2m(E−V0)/ℏ

x
, x ≥ 0
where A1, B1, A2, and B2 are constants which need to be determined
from the boundary conditions. To simplify the calculation, we make the
substitutions
k1 =
√
2mE
ℏ
k2 =
p
2m(E − V0)
ℏ
so that ℏk1 and ℏk2 give the magnitude of the momentum of the particle on
the left and right sides of the step, respectively. Then the solution becomes
ψ1(x) = A1e
ik1x + B1e
−ik1x
, x < 0 (4.12)
ψ2(x) = A2e
ik2x + B2e
−ik2x
, x ≥ 0 (4.13)
As noted previously, the constants A1, B1, A2, and B2 must be chosen so
that the wave function and its derivative are continuous at the boundary
between the two solutions:
ψ1(0) = ψ2(0)
and
dψ1
dx (0) = dψ2
dx (0)Solutions of the one-dimensional time-independent Schr¨odinger equation 79
A1
B1
A2
B2
x
V(x)
Fig. 4.6 In Equations (4.14) and (4.15), the “A1” term represents a rightward-moving
particle on the left side of the step, the “B1” term represents a leftward-moving particle
on the left side of the step, the “A2” term represents a rightward-moving particle on the
right side of the step, and the “B2” term represents a leftward-moving particle on the
right side of the step.
However, before applying these boundary conditions, it is useful to un￾derstand the physical significance of the terms in Equations (4.12) and
(4.13). The time-dependent wave functions for the particle, derived from
Equations (4.12) and (4.13), are
Ψ1(x, t) = A1e
i(k1x−Et/ℏ) + B1e
i(−k1x−Et/ℏ)
, x < 0 (4.14)
Ψ2(x, t) = A2e
i(k2x−Et/ℏ) + B2e
i(−k2x−Et/ℏ)
, x ≥ 0 (4.15)
Thus, the “A1” term represents a rightward-moving particle on the left side
of the step, the “B1” term represents a leftward-moving particle on the left
side of the step, the “A2” term represents a rightward-moving particle on
the right side of the step, and the “B2” term represents a leftward-moving
particle on the right side of the step (Figure 4.6). However, not all of
these terms make physical sense. Assuming that the particle is initially in
the region x < 0, travelling to the right, we expect A1 ̸= 0. Classically
the particle will travel across the step and continue travelling to the right,80 Quantum Mechanics: An Accessible Introduction
so we expect A2 ̸= 0. We also want to allow for the possibility that the
particle can scatter backwards off of the step; although this cannot happen
classically, it cannot be ruled out in a quantum system, so we must allow for
B1 ̸= 0. However, one term makes no sense at all: the “B2” term represents
a particle originating at x = +∞ and moving to the left. There is no way
to produce such a particle trajectory from a particle initially moving to the
right on the left-hand side of the step. Therefore, on physical grounds, we
set B2 = 0.
Then our wave functions simplify to
ψ1(x) = A1e
ik1x + B1e
−ik1x
, x < 0
ψ2(x) = A2e
ik2x
, x ≥ 0 (4.16)
Using our two boundary conditions at x = 0, we find the requirement that
ψ1(0) = ψ2(0) gives
A1 + B1 = A2 (4.17)
while the requirement that dψ1/dx = dψ2/dx at x = 0 yields
ik1A1 − ik1B1 = ik2A2 (4.18)
Since k1 and k2 are specified by the values of E and V0, we have three
unknowns, A1, B1, and A2, and only two equations constraining them,
Equations (4.17) and (4.18). Hence, we cannot solve for A1, B1, and A2,
but we can express two of the unknowns in terms of the third. Keeping A2
as our only unknown, we get the solution
A1 =
A2
2

1 +
k2
k1

(4.19)
and
B1 =
A2
2

1 −
k2
k1

(4.20)
so that the wave functions become
ψ1(x) = A2
2

1 +
k2
k1

e
ik1x +
A2
2

1 −
k2
k1

e
−ik1x
, x < 0
ψ2(x) = A2e
ik2x
, x ≥ 0
This is the complete solution, but what does it mean physically? Recall
that for a normalized wave function, the probability of finding a particle
at a given location x is given by ψ(x)
∗ψ(x). Our wave functions are not
so well behaved, since they represent an idealized, single-momentum state.
However, it is still possible to derive useful results from them. In particular,Solutions of the one-dimensional time-independent Schr¨odinger equation 81
we can define the probabilities that the particle will be reflected at the step
(R) and that it will be transmitted across the step (T). In analogy to
results from classical electromagnetism, we take
R =
(reflected amplitude)2
(incident amplitude)2
and
T =
(transmitted amplitude)2
(incident amplitude)2
We require that R + T = 1, since the particle must be either transmitted
or reflected. Since we are dealing with complex quantities, the square of
the incident amplitude is A∗
1A1, and the square of the reflected amplitude
is B∗
1B1, so
R =
B∗
1B1
A∗
1A1
(4.21)
(Note that in general, the terms giving the transmitted and reflected am￾plitudes will also include a factor depending on the velocity of the particle,
but these factors cancel in Equation (4.21), since they are evaluated in the
same region.) The transmission probability is then simply
T = 1 − R
Substituting our amplitudes from Equations (4.19) and (4.20) into Equa￾tion (4.21) gives us the reflection probability
R =
(k1 − k2)
2
(k1 + k2)
2
(4.22)
while
T = 1 − R = 1 −
(k1 − k2)
2
(k1 + k2)
2
This is a truly remarkable result; it tells us that there is a nonzero prob￾ability that the particle will not be transmitted across the step but will
actually reflect backwards! The probability of reflection (Equation (4.22))
can be rewritten in terms of E and V0:
R =
 √
E −
√
E − V0
√
E +
√
E − V0
!2
It is reasonable to ask why such reflection is not observed in classical
systems. For example, suppose we have an electron moving through a
region of space in which the electric potential changes abruptly. If we take82 Quantum Mechanics: An Accessible Introduction
the electron to have an energy equal to twice the potential step, E = 2V0,
we obtain R = 0.17, a nonnegligible reflection probability. The answer lies
in our assumption that the potential is an infinitely sharp step. In any real
physical system, the step-function potential will have a nonzero width in
the x direction. As long as this width is much larger than the de Broglie
wavelength of the scattering particle, the system will lie in the classical
regime, and the calculation we have just performed will be invalid.
Example 4.1. When Is a Step-Function Potential in the Quantum
Regime?
As an example, consider an electron accelerated through a 100 V potential
difference. How narrow would the step-function potential need to be in
order to observe quantum effects?
The energy of the electron in this case is
E = eΦ
= (1.6 × 10−19 C)(100 V)
= 1.6 × 10−17 J
Its de Broglie wavelength is then
λ = h/p
= h/√
2mE
= (6.6 × 10−34 J s)/
p
(2)(9.1 × 10−31 kg)(1.6 × 10−17 J)
= 1.2 × 10−10 m
Thus, the step in the potential would need to rise from 0 to V0 in a length
less than 10−10 m, about an atomic radius. In practice, the step width
would need to be much larger than this in order for the system to lie in the
purely classical regime.
In general, quantum effects in step potentials can only be seen at the
atomic or nuclear level. An important example (α decay) will be discussed
below.
Step-Function Potential With E < V0
Now consider scattering from a step-function potential when the energy
of the incident particle is less than the height of the step. Again, theSolutions of the one-dimensional time-independent Schr¨odinger equation 83
Schr¨odinger equation will be given by Equations (4.10) and (4.11), but now
E − V0 will be negative. Hence, in the region x < 0, the solution to the
Schr¨odinger equation will be identical to what we obtained in the previous
section:
ψ1(x) = A1e
i(
√
2mE/ℏ)x + B1e
−i(
√
2mE/ℏ)x
However, in the region x ≥ 0, we expect a solution of the form given by
Equation (4.4), i.e., a solution which looks like
ψ2(x) = A2e
√
2m(V0−E)/ℏ

x + B2e
−
√
2m(V0−E)/ℏ

x
Note that the quantity under the square root in the exponential is positive
(since V0 −E > 0), so the exponentials are real. As in the previous section,
we define
k1 =
√
2mE
ℏ
k2 =
p
2m(V0 − E)
ℏ
As before, ℏk1 is the magnitude of the momentum of the particle on the
left side of the step, but ℏk2 does not have a similar physical significance.
Now we write the solution as
ψ1(x) = A1e
ik1x + B1e
−ik1x
, x < 0
ψ2(x) = A2e
k2x + B2e
−k2x
, x ≥ 0
As in the previous section, we can make a physical argument to eliminate
one of the unknown constants. Note that if A2 ̸= 0, the wave function ψ2(x)
will “blow up” in the limit where x → ∞. This problem can only be avoided
by taking A2 = 0, yielding
ψ2(x) = B2e
−k2x
, x ≥ 0
The requirement that ψ1 = ψ2 at x = 0 gives
A1 + B1 = B2
while the requirement that dψ1/dx = dψ2/dx at x = 0 gives
ik1A1 − ik1B1 = −k2B2
These two equations can be solved to express A1 and B1 as functions of
B2:
A1 =
B2
2

1 + i
k2
k1

B1 =
B2
2

1 − i
k2
k1
84 Quantum Mechanics: An Accessible Introduction
and the full wave function becomes
ψ1(x) = B2
2

1 + i
k2
k1

e
ik1x +
B2
2

1 − i
k2
k1

e
−ik1x
, x < 0
ψ2(x) = B2e
−k2x
, x ≥ 0
As in the previous section, we can calculate the transmission and reflection
probabilities. The probability of reflection is
R =
B∗
1B1
A∗
1A1
=
(B2/2)2

1 + i
k2
k1
 1 − i
k2
k1

(B2/2)2

1 − i
k2
k1
 1 + i
k2
k1

= 1
and the transmission probability is T = 1 − R = 0. In this case, the
quantum mechanical calculation produces a result in agreement with the
classical result: the particle will always reflect back at the step boundary.
However, there is one strange result here that does not agree with the
classical calculation. In the classical case, the particle stops exactly at the
step and reflects back. However, in our quantum mechanical calculation,
the wave function is nonzero for x > 0. This indicates that the probability
of finding the particle in the classically forbidden region (x > 0) is nonzero.
This penetration into the classically forbidden region is a purely quantum
mechanical effect that has no analog in classical mechanics. It is so small
as to be unobservable at the macroscropic scale, but it can have important
consequences at the atomic and nuclear scales as shown in the next section.
An important limiting case of our solution occurs in the case of an
“infinitely high” potential barrier. Of course, no physical potential can be
infinite, but this simply means that V0 is much larger than any typical
particle energies: E ≪ V0. In this limit, k2 → ∞, and ψ2(x) becomes
negligible for any x > 0. In this limit, therefore, it is a good approximation
to take as a boundary condition, ψ(x) = 0 at x = 0.
Tunneling
In the previous section, we saw that the wave function can penetrate into the
classically forbidden region of a step-function potential. Now we examine
what happens if the step has finite width. Consider the step potential
shown in Figure 4.7. This potential has V = 0 for x < 0 and x ≥ a, andSolutions of the one-dimensional time-independent Schr¨odinger equation 85
x
V = 0
V(x)
V = 0
V = V0
0 a
Fig. 4.7 A potential with a step of finite width.
V = V0 for 0 ≤ x < a. We assume that a particle is incident from the left
with energy E < V0. In classical physics, such a particle will always bounce
off of the barrier and reflect back to the left. However, quantum mechanics
makes a very different prediction: the particle will sometimes be able to
tunnel completely through the barrier and emerge on the other side!
To see why this happens, recall our qualitative solutions to the
Schr¨odinger equation from the previous chapter. We expect the wave func￾tion to oscillate in the regions x < 0 and x > a but to curve away from the
horizontal axis for 0 < x < a. We saw that for an infinitely wide step, the
particle penetrates into the classically forbidden region. If the potential is
reduced to zero after a finite distance, as in Figure 4.7, the wave function
spills out onto the other side, where it oscillates. The magnitude of this
effect can be calculated using the Schr¨odinger equation.
This potential yields three distinct solutions to the Schr¨odinger equa￾tion, corresponding to the three regions x < 0, 0 ≤ x < a, and x ≥ a. As86 Quantum Mechanics: An Accessible Introduction
in the previous section, we get
ψ1(x) = A1e
ik1x + B1e
−ik1x
, x < 0
ψ2(x) = A2e
k2x + B2e
−k2x
, 0 ≤ x < a
with
k1 =
√
2mE
ℏ
k2 =
p
2m(V0 − E)
ℏ
while the solution for x ≥ a is similar to the solution for x < 0, with the
leftward-moving part of the wave function deleted (as in Equation (4.16)):
ψ3(x) = B3e
ik1x
Now we have two pairs of boundary conditions:
ψ1(0) = ψ2(0) (4.23)
dψ1
dx (0) = dψ2
dx (0) (4.24)
and
ψ2(a) = ψ3(a) (4.25)
dψ2
dx (a) = dψ3
dx (a) (4.26)
Equations (4.23)–(4.24) give
A1 + B1 = A2 + B2
ik1A1 − ik1B1 = k2A2 − k2B2
and Equations (4.25)–(4.26) give
A2e
k2a + B2e
−k2a = B3e
ik1a
k2A2e
k2a − k2B2e
−k2a = ik1B3e
ik1a
These equations can be solved to derive four of the unknown coefficients in
terms of the fifth. We are interested primarily in the transmission proba￾bility, given here by
T =
B∗
3B3
A∗
1A1
After some tedious algebra, we obtain
T =
1
1 + [V
2
0
/4E(V0 − E)] sinh2
(k2a)
(4.27)Solutions of the one-dimensional time-independent Schr¨odinger equation 87
r
E
V(r)
Fig. 4.8 The potential experienced by an α particle in a nucleus.
Clearly, T is nonzero even when E < V0, so a particle can tunnel through
the barrier and emerge on the other side! The classical regime corresponds
to the limit k2a ≫ 1, so that T → 0; this is why tunneling is never observed
in classical systems.
Tunneling is seen, however, on the nuclear scale. An important example
is α decay, in which a heavy nucleus such as U238 emits an α particle
(consisting of two protons and two neutrons). The potential seen by the α
particle consists of an attractive nuclear force at short distances plus the
Coulomb repulsion from the remainder of the nucleus at large distances (see
Figure 4.8). The total energy E can be measured for the emitted α particle,
and it is found to be lower than the height of the potential barrier. The
only way for an α particle to escape, therefore, is by quantum-mechanical
tunneling. As a consequence, the typical lifetimes of α-emitting nuclei are
enormous. For example, U238 has a lifetime of τ = 6.5×109 years: half the
age of the universe!
Another application of tunneling is seen in the tunnel diode. This is a
solid-state device in which, over a certain range in applied voltage, electrons
tunnel through a potential barrier. This tunneling current increases with
applied voltage up to a maximum value and then decreases with voltage.
This results in an interesting property for the tunnel diode: over some88 Quantum Mechanics: An Accessible Introduction
x
V(x)
x = 0 x = a
Fig. 4.9 The infinite square-well potential.
range in applied voltage, the current decreases as the voltage increases.
Thus, over this range in voltage, the resistance is negative!
4.2 Bound Systems
We now move from unbound systems to bound systems. We will consider
two important examples of bound systems in one dimension: the infinite
square-well potential and the harmonic oscillator. The infinite square well
has less physical importance than the harmonic oscillator, but it is simpler
to solve and will illustrate concepts that can be applied elsewhere. Both
of these one-dimensional problems will serve as a “warm-up” for the more
physically-relevant (but also more complicated) three-dimensional systems
examined in Chapter 6.
The Infinite Square Well
Consider the one-dimensional infinite square-well potential of width a,
shown in Figure 4.9. This potential has V (x) = 0 for 0 ≤ x ≤ a, and
V (x) = ∞ for x < 0 and x > a. Of course, no physical potential can
be truly infinite, but this potential will be a good approximation for any
system with sharp potential barriers such that V ≫ E.
For our idealized system, it is clear that a particle with any energy E
will be in a bound state. The Schr¨odinger equation for 0 ≤ x ≤ a can beSolutions of the one-dimensional time-independent Schr¨odinger equation 89
written
d
2ψ
dx2
+
2mE
ℏ
2
ψ = 0 (4.28)
Since E > 0, the general solution will have the form of either Equa￾tion (4.5) or Equation (4.6), which are completely equivalent. It will be
more convenient, however, to use the trigonometric form of the solution
(Equation (4.6)), which gives, as the general solution
ψ(x) = C1 cos p
2mE/ℏ
2x

+ C2 sin p
2mE/ℏ
2x

The boundary conditions in the problem imply that ψ(0) = 0 and ψ(a) = 0.
The first of these gives
ψ(0) = C1 cos(0) + C2 sin(0) = C1 = 0
Hence, C1 = 0, and the wave function is simply
ψ(x) = C2 sin p
2mE/ℏ
2x

(4.29)
The second boundary condition, ψ(a) = 0, implies
ψ(a) = C2 sin p
2mE/ℏ
2a

= 0 (4.30)
We cannot take C2 = 0 (or the wave function would vanish everywhere!),
so we must assume that
sin p
2mE/ℏ
2a

= 0
The function sin(x) is zero for x = 0, π, 2π, . . . , nπ. Hence, Equation (4.30)
can only be satisfied if the argument of the sine function is an integer
multiple of π:
p
2mE/ℏ
2a = nπ, n = 1, 2, 3, . . . (4.31)
Note that we exclude the case n = 0, which would produce a wave function
that vanishes everywhere. The only free parameter in Equation (4.31) is
the energy E. This equation tells us that the Schr¨odinger equation has a
solution only for certain discrete values of E which satisfy Equation (4.31).
Solving Equation (4.31) for E, we get
En =
ℏ
2π
2
2ma2
n
2
, n = 1, 2, 3, . . . (4.32)
where we have labeled the energy with a subscript corresponding to the
value of n on the right-hand side.90 Quantum Mechanics: An Accessible Introduction
It is clear that the energy of this system is quantized. The energy E
cannot have an arbitrary value as in classical physics. Instead, only the
set of discrete values given by Equation (4.32) is allowed. Although we
showed qualitatively in the previous chapter that the Schr¨odinger equation
for bound systems leads to energy quantization, this is our first explicit
calculation with the Schr¨odinger equation that demonstrates such quanti￾zation.
Equation (4.32) has an interesting corollary. Since the smallest allowed
value for n is n = 1, the smallest possible energy for the particle is
E1 =
ℏ
2π
2
2ma2
(4.33)
Hence, the particle cannot have zero energy; it must have at least the
minimum energy specified by Equation (4.33). This energy is called the
zero-point energy of the system.
The wave function ψ(x) can now be simplified in Equation (4.29) by
substituting Equation (4.32) for the energy E. This gives
ψn(x) = C2 sin
nπx
a
where ψn(x) is the form of the wave function corresponding to a particle
with energy En. The constant C2 is calculated by normalizing the wave
function:
Z a
0
ψn(x)
∗ψn(x) dx = |C2|
2
Z a
0
sin2 nπx
a
dx
= |C2|
2 a
2
= 1
Taking, for convenience, C2 to be real and positive, we get
C2 =
r
2
a
Note that for this case, the coefficient C2 does not depend on n. This
will not necessarily be the case for solutions with other potentials. The
normalized wave functions and corresponding energies are then
ψn(x) = r
2
a
sin
nπx
a
, 0 ≤ x ≤ a
ψn(x) = 0, x < 0 or x > a
En =
ℏ
2π
2
2ma2
n
2
n = 1, 2, 3, . . .Solutions of the one-dimensional time-independent Schr¨odinger equation 91
0 a
x
c1
(x) c2
(x)
n = 1
0 a
x
n = 2
c3
(x)
0 a
x
n = 3
Fig. 4.10 The infinite square-well wave functions, ψn(x), for n = 1, 2, and 3.
The first few wave functions (for n = 1, 2, 3) are shown in Figure 4.10.
Note the resemblance to standing waves in a pipe. The wave functions
ψn(x) are alternately symmetric (for odd n) and antisymmetric (for even
n) about x = a/2. In fact, it is possible to show (see Problem 4.10) that
for any symmetric potential, the solutions of the Schr¨odinger equation will
be either symmetric or antisymmetric. Note also that ψn crosses the x-axis
n − 1 times.
The probability of finding the particle in a small interval dx at the
location x is just
ψn(x)
∗ψn(x) dx =
2
a
sin2 nπx
a
dx. (4.34)
As n → ∞, we expect to approach the classical regime. For large n, Equa￾tion (4.34) gives a function that resembles a fine tooth comb, giving a nearly
uniform probability of finding the particle anywhere inside the square well.
However, this is exactly what would be expected for the classical case of a
particle bouncing continuously between the two walls of a closed container;
the particle spends an equal amount of time at every point in the container.
A physical system of this sort can be constructed by sandwiching a thin
layer of semiconductor between thicker layers of a different semiconductor
(an example of a semiconductor heterostructure mentioned at the beginning
of this chapter). The electrons are then free to move along the thin layer,
but are confined in a potential well perpendicular to this layer. When
such a structure is extended to three dimensions (so that the electrons are
effectively confined to a single point), it produces a quantum dot.92 Quantum Mechanics: An Accessible Introduction
The Harmonic Oscillator Potential
We now examine a potential with more physical significance: the harmonic
oscillator potential. The one-dimensional harmonic oscillator potential is
V (x) = 1
2
Kx2
(4.35)
This potential is familiar from classical mechanics, where it represents the
potential energy of a mass attached to an ideal spring with spring constant
K. Before solving the quantum harmonic oscillator, we first review the
behavior of the classical harmonic oscillator. For a classical spring, the
force is given by
F(x) = −Kx
so the equation of motion for the mass is
m
d
2x
dt2
= −Kx
One example of a solution to this equation of motion is
x = A cos(ωt)
for the position of the mass, and
v = −Aω sin(ωt)
for the velocity of the mass, where ω =
p
K/m. Thus, the motion of the
mass is sinusoidal. This solution gives a constant value for the total energy:
E =
1
2
mv2 +
1
2
Kx2
=
1
2
mA2ω
2
sin2
(ωt) + 1
2
KA2
cos2
(ωt)
=
1
2
KA2
(4.36)
Before proceeding to solve the Schr¨odinger equation with this potential,
it is reasonable to ask why this potential would be of any interest at all. We
certainly do not expect, for example, to see particles attached to atomic￾scale springs! The answer lies in the fact that this potential is an excellent
approximation to the motion of a particle undergoing small oscillations
about the minimum of any potential. Consider an arbitrary potential V (x),
and choose the origin of the x-axis to lie at the minimum of this potential.
Now consider a particle trapped near the minimum of the potential at x = 0.
The potential can be approximated as a Taylor series near the origin:
V (x) = V (0) + V
′
(0)x +
1
2
V
′′(0)x
2 +
1
6
V
′′′(0)x
3 + · · ·Solutions of the one-dimensional time-independent Schr¨odinger equation 93
The first term in this equation is just a constant and can be ignored,
since we are always free to redefine the zero of a potential. The min￾imum of the potential lies at x = 0, so V
′
(0) = 0, and the second
term is zero. This leaves only terms proportional to x
2
, x
3
, x
4
, and
higher powers of x. But if x is sufficiently small, then x
2 ≫ x
3 ≫
x
4 ≫ · · · , and we need worry only about the x
2
term. Thus, a particle
undergoing small oscillations about the minimum of the potential will ex￾perience the approximate potential
V (x) = 1
2
V
′′(0)x
2
which has the same form as Equation (4.35) with K = V
′′(0). For exam￾ple, the motion of ions in a crystal lattice is often approximated using a
harmonic oscillator potential.
We now proceed to solve the quantum harmonic oscillator. The
Schr¨odinger equation with the one-dimensional harmonic oscillator poten￾tial is
−
ℏ
2
2m
d
2ψ
dx2
+
1
2
Kx2ψ = Eψ (4.37)
In order to simplify the algebra involved in solving this equation, it is
convenient to define a new independent variable s given by
s =
(Km)
1/4
ℏ
1/2
x (4.38)
and a new constant λ proportional to the energy:
λ =
2
ℏ
r
m
K
E (4.39)
Both s and λ are dimensionless; otherwise they have no special significance
beyond simplifying the calculation.
In terms of s and λ, Equation (4.37) simplifies to
d
2ψ
ds2
+ (λ − s
2
)ψ = 0 (4.40)
To derive a solution, consider what happens for s
2 ≫ λ. In this limit,
Equation (4.40) looks like
d
2ψ
ds2
− s
2ψ = 0 (4.41)
Even this simplified version of the equation cannot be solved exactly, but
we can find an approximate solution valid for large s:
ψ = Aes
2/2 + Be−s
2/294 Quantum Mechanics: An Accessible Introduction
For this solution,
d
2ψ
ds2
= A(1 + s
2
)e
s
2/2 − B(1 − s
2
)e
−s
2/2
and for s ≫ 1
d
2ψ
ds2
≈ As2
e
s
2/2 + Bs2
e
−s
2/2 = s
2ψ
satisfying Equation (4.41). However, we also want our solution to be well
behaved in the limit where s → ±∞. This means that A = 0 (otherwise,
the solution “blows up” at ±∞). Thus, we expect the solution to resemble,
in the limit of large s
2
,
ψ(s) ∼ e
−s
2/2
(4.42)
This is clearly not an exact solution of Equation (4.40), but it suggests that
we look for an exact solution of the form
ψ(s) = f(s)e
−s
2/2
(4.43)
Substituting this form for ψ into Equation (4.40) and simplifying, we get a
differential equation for f(s):
d
2f
ds2
− 2s
df
ds + (λ − 1)f = 0 (4.44)
To find a function f(s) which satisfies this equation, we expand f(s)
out in a power series:
f(s) = X∞
n=0
ans
n
(4.45)
where the coefficients an must be chosen to satisfy Equation (4.44). Sub￾stituting this form for f(s) into Equation (4.44) gives
X∞
n=2
n(n − 1)ans
n−2 − 2
X∞
n=0
nans
n + (λ − 1)X∞
n=0
ans
n = 0
Rewriting the first term in this equation in terms of m = n − 2 and com￾bining the last two terms gives
X∞
m=0
(m + 2)(m + 1)am+2s
m + (λ − 2n − 1)X∞
n=0
ans
n = 0
(Note that m is just a summation label, so that it can be changed back to n
in the first term of this equation.) In order for this equation to be satisfied,Solutions of the one-dimensional time-independent Schr¨odinger equation 95
the left-hand side must be identically zero. This can only be achieved if the
factor multiplying every power of s is zero. This requirement gives
(n + 2)(n + 1)an+2 + (λ − 2n − 1)an = 0
which can be used to fix an+2 in terms of an:
an+2 =
2n + 1 − λ
(n + 2)(n + 1)an (4.46)
A relationship of this sort is called a recursion relation. Given a0 and
a1, Equation (4.46) can be iterated to calculate all of the other terms in
the power series. However, an arbitrary choice for a0 and a1 will not, in
general, give an acceptable solution. The reason is the solution should look
like Equation (4.42) when s is large. If the factor f(s) multiplying the
exponential in Equation (4.43) is a finite polynomial, then the exponential
factor will dominate the polynomial at large s, giving the desired asymptotic
behavior for ψ(s) at large s (Equation (4.42)). An infinite polynomial, on
the other hand, can dominate the exponential at large s, leading to an
unacceptable solution.
We therefore require that the power series must terminate at some finite
value of n. This can be achieved by choosing an appropriate value of λ in
Equation (4.46). Recall that λ is simply proportional to the energy E, and
we expect the energy to be quantized, so that the Schr¨odinger equation will
have solutions for only a set of discrete values of E. Thus, fixing the value
of λ in Equation (4.46) is simply equivalent to fixing the value of E to give
a solution for the Schr¨odinger equation. Consider what happens if we set
λ = 2n + 1 (4.47)
for some fixed value of n. As an example, suppose that we choose λ = 13,
so that λ = 2n + 1 for n = 6. Then we fix a value for a0 which determines
a2 through Equation (4.46). Then a2 determines a4, and a4 determines a6,
at which point Equation (4.46) with n = 6 and λ = 13 gives a8 = 0. Then
a10 = 0, a12 = 0, and so on. However, this still leaves the odd values of n:
a1, a3, . . . . There is nothing to force this sequence of terms to terminate at a
finite value of n (since we chose n to be even in Equation (4.47)). Therefore,
to obtain a finite polynomial in Equation (4.45), we must choose a1 = 0,
so that all of the odd-numbered terms are zero. Conversely, if we take n
in Equation (4.47) to be odd, then a0 and all of the other even-numbered
terms must vanish.
This procedure produces a set of solutions ψn(s), corresponding to our
choice of λ in Equation (4.47), and λ, in turn, gives the corresponding96 Quantum Mechanics: An Accessible Introduction
energies En in Equation (4.39). Here is what the first few solutions look
like:
n = 0, ψ0(s) = C0e
−s
2/2
(4.48)
n = 1, ψ1(s) = C1(2s)e
−s
2/2
(4.49)
n = 2, ψ2(s) = C2(4s
2 − 2)e
−s
2/2
(4.50)
n = 3, ψ3(s) = C3(8s
3 − 12s)e
−s
2/2
(4.51)
n = 4, ψ4(s) = C4(16s
4 − 48s
2 + 12)e
−s
2/2
(4.52)
where the constants Cn must be fixed to normalize the wave functions. The
normalization condition gives
Cn =
1
π
1/4
√
2
nn!
These polynomials are called Hermite polynomials; they crop up in other
areas of physics and mathematics. The harmonic oscillator wave functions
for n = 0, 1, 2, 3 are shown in Figure 4.11. As expected (Problem 4.10),
these wave functions are alternately even and odd, since the potential is
symmetric about x = 0.
The energies corresponding to these wave functions can be derived from
Equations (4.39) and (4.47):
2n + 1 = λ =
2
ℏ
r
m
K
E
so
En =

n +
1
2

ℏ
r
K
m
Recall that the frequency of a classical harmonic oscillator is ω =
p
K/m,
so that the energies can be written
En =

n +
1
2

ℏω (4.53)
Once again, we see the phenomenon of a zero-point energy: the lowest￾energy state, n = 0, does not have zero energy. Instead, its energy is
E0 =
1
2
ℏω
Note further that the energy levels for the harmonic oscillator are evenly
spaced; adjacent energy levels differ by ℏω.
The behavior of ψ
∗ψ is shown in Figure 4.12 for the states n = 0, 1, 2, 3.
It is clear that ψ
∗ψ for these wave functions is nonzero in the classicallySolutions of the one-dimensional time-independent Schr¨odinger equation 97
s s
c0
(s)
n = 0 n = 1
c1
(s)
s s
c2
(s)
n = 2 n = 3
c3
(s)
Fig. 4.11 The harmonic oscillator wave functions ψn(s) for the lowest four energy states:
n = 0, 1, 2, 3, where s = [(Km)
1/4/ℏ
1/2
]x.
forbidden region V > E (in fact, it is nonzero for all of the harmonic oscil￾lator wave functions over all space). Once again, we see that the particle
can penetrate into a region which, classically, it should not be able to reach.
These quantum probabilities can be compared with the expected result
in the classical limit. Consider a classical harmonic oscillator with total
energy given by Equation (4.36). The oscillating mass moves between the
limits x− = −
p
2E/K and x+ =
p
2E/K with its largest velocity at the98 Quantum Mechanics: An Accessible Introduction
s s
c0
*c0
n = 0 n = 1
c1
*c1
s s
c2
*c2
n = 2 n = 3
c3
*c3
Fig. 4.12 ψ
∗ψ for the harmonic oscillator, n = 0, 1, 2, 3.
center of the oscillator and the smallest velocity near x− and x+. Thus, the
mass spends more time near x− and x+ and less time near the middle of
the oscillator, so if we take a random snapshot in time, we are most likely
to find the particle near x− and x+, and least likely to find it in the middle.
More quantitatively, if we pick a random time, the probability P of
finding the mass in a small interval dx is proportional to the time dt that
it spends in that interval. But dt = dx/v, and v can be determined fromSolutions of the one-dimensional time-independent Schr¨odinger equation 99
x
P, c*c
Fig. 4.13 The classical probability P of finding the harmonic oscillator mass in a small
interval dx at a position x is shown as a solid curve. The quantum probability density,
ψn(x)
∗ψ(x) for n = 50, is shown as a dashed curve.
Equation (4.36):
v =
p
(2E − Kx2)/m
Thus, we have
P ∝
r m
2E − Kx2
dx
This classical probability, suitably normalized, is shown in Figure 4.13. This
distribution clearly shows no relation to the low-n quantum-mechanical
probabilities in Figure 4.12. However, if we take a large value for n, corre￾sponding to the classical limit, we obtain a result which begins to resemble
the classical probability. In Figure 4.13, we show ψ
∗ψ for n = 50. It is
clear that in this limit, the quantum mechanical probability approaches
the classical result.
One application of the quantum harmonic oscillator is in the physics
of diatomic molecules. The two nuclei in a diatomic molecule can vibrate
about their equilibrium separation, and the potential for these nuclei can
be approximated by a harmonic oscillator potential. It is found that the
vibrational energy levels are well described by Equation (4.53). (See also
Problem 4.13.)
The Heisenberg Uncertainty Principle
Consider the ground state harmonic oscillator wave function derived in
the previous section (Equation (4.48)). Suppose that we make repeated100 Quantum Mechanics: An Accessible Introduction
measurements of the position x. We will get a different answer each time we
measure x, although the mean value of all of our measurements will converge
to ⟨x⟩. Then we can define the “uncertainty” ∆x in our measurement of x
as the standard deviation of our measurements relative to ⟨x⟩:
(∆x)
2 = ⟨x
2
⟩ − ⟨x⟩
2
.
For the ground state harmonic oscillator wave function, ⟨x⟩ = 0, so (∆x)
2
is given by
(∆x)
2 =
Z ∞
−∞
1
π
1/4
e
−s
2/2

ℏ
1/2
(Km)
1/4
s
2 
1
π
1/4
e
−s
2/2

ds
=
1
2
ℏ
(Km)
1/2
where we have used the conversion factor between s and x given in Equa￾tion (4.38). Similarly, we can make repeated measurements of the mo￾mentum, and define the uncertainty in the momentum to be ∆p, where
(∆p)
2 = ⟨p
2
⟩ − ⟨p⟩
2
. As in the case of the position, the mean value of p is
zero, so we have
(∆p)
2 =
Z ∞
−∞
1
π
1/4
e
−s
2/2

−iℏ
(Km)
1/4
ℏ
1/2
2
d
2
ds2

1
π
1/4
e
−s
2/2

ds
=
1
2
ℏ(Km)
1/2
Combining these two expressions gives
(∆x)
2
(∆p)
2 =
ℏ
2
4
.
However, it turns out that the ground state harmonic oscillator wave func￾tion gives the smallest possible value of (∆x)
2
(∆p)
2
(a result that we will
not prove here). Therefore, for any wave function, we have
∆x∆p ≥
ℏ
2
which is called the Heisenberg uncertainty principle. (As an example, see
Problem 4.17).
The Heisenberg uncertainty principle gives a fundamental limit on the
accuracy with which the position and momentum of a particle can be mea￾sured. The more precisely you measure the position of a particle, the less
accurately you will be able to determine the momentum, and vice-versa.
Note that it applies only to measurements made in the same direction. For
example, there is nothing to prevent an arbitrarily precise measurement of
the position along the x axis and of the component of the momentum along
the y axis.Solutions of the one-dimensional time-independent Schr¨odinger equation 101
PROBLEMS
4.1 Show that the differential equation solution given in Equation (4.5),
y = C1e
i
√
Ax + C2e
−i
√
Ax
,
is completely equivalent to the solution in Equation (4.6),
y = D1 cos(√
Ax) + D2 sin(√
Ax),
and express C1 and C2 in terms of D1 and D2. If both D1 and D2
are real and nonzero, is it possible for both C1 and C2 to be real?
4.2 Show that the general expression for the wave function for a free
particle, given by Equation (4.8) as
Ψ(x, t) = C1e
i(kx−ωt) + C2e
i(−kx−ωt)
,
is not an eigenfunction of momentum unless C1 = 0 or C2 = 0.
4.3 A particle with mass m and energy E is moving in one dimension
from right to left. It is incident on the step potential V (x) = 0 for
x < 0 and V (x) = V0 for x ≥ 0, where V0 > 0, as shown on the
diagram. The energy of the particle is E > V0.
V = 0 x
x = 0
V = V0
V(x)
E
(a) Solve the Schr¨odinger equation to derive ψ(x) for x < 0 and
x ≥ 0. Express the solution in terms of a single unknown constant.
(b) Calculate the value of the reflection coefficient R for the parti￾cle.
4.4 A particle with mass m and energy E is moving in one dimension
from left to right. It is incident on the step potential V (x) = 0
for x < 0 and V (x) = V0 for x ≥ 0, where V0 > 0, as shown on102 Quantum Mechanics: An Accessible Introduction
the diagram. The energy of the particle is exactly equal to V0, i.e.,
E = V0.
V = 0 x
x = 0
V = V0
V(x)
E
(a) Solve the Schr¨odinger equation to derive ψ(x) for x < 0 and
x ≥ 0. Express the solution in terms of a single unknown constant.
(b) Calculate the value of the reflection coefficient R for the parti￾cle.
4.5 Consider reflection from a step potential of height V0 with E > V0,
but now with an infinitely high wall added at a distance a from the
step (see diagram):
V = 0 x
x = 0 x = a
V = V0
V(x)
E
(a) Solve the Schr¨odinger equation to find ψ(x) for x < 0 and 0 ≤
x ≤ a. Your solution should contain only one unknown constant.
(b) Show that the reflection coefficient at x = 0 is R = 1. This is
different from the value of R previously derived without the infinite
wall. What is the physical reason that R = 1 in this case?
(c) Which part of the wave function represents a leftward-moving
particle at x ≤ 0? Show that this part of the wave function is anSolutions of the one-dimensional time-independent Schr¨odinger equation 103
eigenfunction of the momentum operator, and calculate the eigen￾value. Is the total wave function for x ≤ 0 an eigenfunction of the
momentum operator?
4.6 An electron is accelerated through a potential difference of 3.0 eV
and is incident on a finite potential barrier of height 5.0 eV and
thickness 5.0 × 10−10 m. What is the probability that the electron
will tunnel through the barrier?
4.7 Consider an infinite square-well potential of width a, but with the
coordinate system shifted so that the infinite potential barriers lie
at x = −a/2 and x = a/2 (see diagram):
x
V(x)
x = 
a
2
x = –
a
2
(a) Solve the Schr¨odinger equation for this case to calculate the
normalized wave functions ψn(x) and the corresponding energies
En.
(b) Explain why you get the same energies as for the square well
between x = 0 and x = a, but a different set of wave functions.
4.8 A baseball of mass 0.14 kg is confined between two thick walls
a distance 0.5 m apart. Calculate the zero-point energy of the
baseball.
4.9 A particle is trapped inside an infinite one-dimensional square well
of width a in the first excited state (n = 2).
(a) You make a measurement to locate the particle. At what po￾sitions are you most likely to find the particle? At what positions
are you least likely to find it?
(b) Calculate ⟨p
2
⟩ for this particle.104 Quantum Mechanics: An Accessible Introduction
4.10 A particle is bound in a one-dimensional potential V (x), where
V (x) is symmetric, i.e., V (x) = V (−x).
(a) Suppose that ψ(x) is a solution of the Schr¨odinger equation
with energy E. Make the change of variables y = −x, and show
that ψ(y) is also a solution of the Schr¨odinger equation with energy
E.
(b) Since the solutions of the Schr¨odinger equation for a fixed value
of E are unique (up to multiplication by a constant), the result
from part (a) implies that ψ(x) = cψ(−x), where c is an unknown
constant. Use this result to show that ψ(x) must be either even
[ψ(−x) = ψ(x)] or odd [ψ(−x) = −ψ(x)].
(c) For a particle bound in a one-dimensional symmetric potential,
so that V (−x) = V (x), show that all of the following are true:
(i) ψ
∗ψ is a symmetric function,
(ii) ⟨x⟩ = 0,
(iii) ⟨p⟩ = 0.
4.11 Consider the semi-infinite square well given by V (x) = −V0 < 0
for 0 ≤ x ≤ a and V (x) = 0 for x > a. There is an infinite barrier
at x = 0 (hence the name “semi-infinite”). A particle with mass m
is in a bound state in this potential with energy E ≤ 0.
(a) Solve the Schr¨odinger equation to derive ψ(x) for x ≥ 0. Use the
appropriate boundary conditions and normalize the wave function
so that the final answer does not contain any arbitrary constants.
(b) Show that the allowed energy levels E must satisfy the equation
tanp
2m(E + V0)
ℏ
a

+
r
−(E + V0)
E
= 0
(c) The equation in part (b) cannot be solved analytically to give
the allowed energy levels, but simple solutions exist in certain spe￾cial cases. Determine the conditions on V0 and a so that a bound
state exists with E = 0.
4.12 A particle of mass m moves in a harmonic oscillator potential. The
particle is in the first excited state.
(a) Calculate ⟨x⟩ for this particle.
(b) Calculate ⟨p⟩ for this particle.
(c) Calculate ⟨p
2
⟩ for this particle.
(d) At what positions are you most likely to find the particle? At
what positions are you least likely to find it?Solutions of the one-dimensional time-independent Schr¨odinger equation 105
4.13 The oscillation frequencies of a diatomic molecule are typically
1012 Hz–1014 Hz. Derive an order of magnitude estimate for the
harmonic oscillator constant K for such molecules.
4.14 A particle of mass m is bound in a one-dimensional power law
potential V (x) = Kxβ
, where β is an even positive integer. Show
that the allowed energy levels are proportional to m−β/(2+β)
.
4.15 A particle is moving in a simple harmonic oscillator potential
V (x) = 1
2Kx2
for x ≥ 0, but with an infinite potential barrier
at x = 0 (the paddle ball potential). Calculate the allowed wave
functions and corresponding energies. Do not worry about normal￾izing the wave functions.
4.16 A particle moves in one dimension in the potential V (x) =
V0 ln(x/x0) for x > 0, where x0 and V0 are constants with units
of length and energy, respectively. There is an infinite potential
barrier at x = 0. The particle drops from the first excited state
with energy E1 into the ground state with energy E0, by emitting a
photon with energy E1–E0. Show that the frequency of the photon
emitted by this particle is independent of the mass of the particle.
4.17 Calculate ∆x∆p for the ground state wave function in an infinite
square well and show that it satisfies the Heisenberg uncertainty
principle.This page intentionally left blankChapter 5
Math interlude B: Linear algebra
We have already seen that linear operators occupy a central place in quan￾tum mechanics. In particular, in Chapter 3 we noted that for any observable
quantity o, we can find a linear operator O with the following properties:
1. If a particle is in a state with a definite value of o, then the wave
function ψ for the particle is an eigenfunction of O with eigenvalue
o:
Oψ = oψ (5.1)
Note that O is an operator and o is a number, but O and o must
have the same physical units (joules, meters, etc.). If Equation (5.1)
is satisfied, then if a measurement of the observable is made, the
result is guaranteed to be o.
2. If the particle is not in a state with a definite value of o, then ψ
will not be an eigenfunction of O, and Equation (5.1) will not be
satisfied. If a measurement of the observable is made, there is no
way to predict the result. However, the expectation value of o is
still a well-defined quantity given by
⟨o⟩ =
Z
ψ
∗Oψ d3
r
The properties of linear operators are part of a more general branch of
mathematics called linear algebra, and it is this subject which we examine
in more detail here.
5.1 Properties of Linear Operators
Recall that in order for an operator O to be a linear operator, must have
two properties:
107108 Quantum Mechanics: An Accessible Introduction
O[cf(x)] = cOf(x)
and
O[f(x) + g(x)] = Of(x) + Og(x)
for all functions f(x) and g(x), and all complex numbers c.
We can go further and define addition or subtraction of linear operators.
If P and Q are two linear operators, then their sum, R = P + Q, is defined
by
Rf(x) = (P + Q)f(x) = P f(x) + Qf(x)
A similar result holds for subtraction: if R = P − Q, then
Rf(x) = P f(x) − Qf(x)
In fact, we have already implicitly used this definition when we introduced
the Hamiltonian operator H. The Hamiltonian operator is defined as the
sum of two operators:
H = −
ℏ
2
2m
∇2 + V
so that
Hψ = −
ℏ
2
2m
∇2ψ + V ψ
We can also define the product of two linear operators. If P and Q are
linear operators, then R = P Q is defined by
Rψ = (P Q)ψ
= P(Qψ) (5.2)
where Equation (5.2) means that we first apply the operator Q to ψ, and
then we apply the operator P to the result. The operator P Q is also called
the composition of P and Q.
Example 5.1. Multiplication of Two Operators
Let X be the one-dimensional position operator, Xψ = xψ, and let D be
the derivative operator: Dψ = dψ/dx. Calculate DX.
Applying DX to an arbitrary function ψ(x) gives
DXψ =
d
dx(xψ)
= ψ + x
dψ
dx
= (1 + XD)ψ
so that
DX = 1 + XD (5.3)Math interlude B: Linear algebra 109
Example 5.1 demonstrates that the multiplication of operators differs
from the multiplication of ordinary numbers in one important respect: it
is not commutative! Clearly, Equation (5.3) implies that DX ̸= XD.
In fact, the question of whether or not operators commute is of central
importance in quantum mechanics. Hence, it is customary to define a
special quantity called the commutator. For any two operators A and B,
the commutator is denoted by the symbol [A, B], and it is defined as
[A, B] = AB − BA
When two operators do commute with each other, their commutator is,
obviously, zero.
Example 5.2. The Commutator of H and P
As an example, we calculate the commutator of the one-dimensional Hamil￾tonian operator H and the one-dimensional momentum operator P.
Applying [H, P] to an arbitrary wave function, ψ(x), gives
[H, P]ψ = HP ψ − P Hψ
=

−
ℏ
2
2m
∂
2
∂x2
+ V (x)
−iℏ
dψ
dx 
−

−iℏ
d
dx−
ℏ
2
2m
∂
2ψ
∂x2
+ V (x)ψ

= i
ℏ
3
2m
∂
3ψ
∂x3
− iℏV (x)
∂ψ
∂x − i
ℏ
3
2m
∂
3ψ
∂x3
+ iℏψ
∂V
∂x + iℏV (x)
∂ψ
∂x
= iℏ
∂V
∂x ψ
Hence,
[H, P] = iℏ
∂V
∂x
Some important general properties of commutators are (for any opera￾tors A, B, and C)
[A, B] = −[B, A] (5.4)
[A, A] = 0 (5.5)
[A + B, C] = [A, C] + [B, C] (5.6)
[A, BC] = [A, B]C + B[A, C] (5.7)
(See Problem 5.1.)110 Quantum Mechanics: An Accessible Introduction
The importance of commutators for quantum mechanics arises in the
following way. Suppose that I have a particle for which I want to measure
two different observables, a and b. (For instance, I might want to measure
the position and momentum of the particle.) Is it possible for the particle
to be in a state of definite a and definite b at the same time? The answer
is “yes” but only if the corresponding operators A and B commute.
To see why this is the case, recall that in order for the particle to be in
a state of definite a, it must be an eigenfunction of A with eigenvalue a:
Aψ = aψ (5.8)
Now we make an additional assumption: there are no other wave functions
ψ (other than multiples of ψ) that are eigenfunctions of A with the same
eigenvalue a. (If two different eigenfunctions have the same eigenvalue, and
one eigenfunction is not a multiple of the other, then the eigenfunctions are
said to be degenerate. The argument presented here can be extended to
the case of degenerate states, but it is somewhat more complicated.) Now
suppose that A and B do commute so that [A, B] = 0. Operating on both
sides of Equation (5.8) with the operator B gives
BAψ = Baψ = aBψ
But A commutes with B, so we can rewrite the left-hand side of this equa￾tion to get
A(Bψ) = a(Bψ)
So we have shown that Bψ is an eigenfunction of A with eigenvalue a.
However, we assumed that the eigenfunctions of A were all nondegenerate,
so that any eigenfunction of A with eigenvalue a must simply be a multiple
of ψ. Thus, Bψ must be a multiple of ψ, e.g., bψ, and
Bψ = bψ
So ψ is simultaneously an eigenfunction of both A and B. Physically, this
means that the particle is in a state of definite a and b, and both quantities
can be measured simultaneously.
Example 5.3. Simultaneous Eigenfunctions
For which potentials V (x) is it possible to find solutions of the one￾dimensional time-independent Schr¨odinger equation which are also states
of definite momentum?Math interlude B: Linear algebra 111
We calculated [H, P] in Example 5.2, finding
[H, P] = iℏ
∂V
∂x
Solutions of the one-dimensional time-independent Schr¨odinger equation
are eigenfunctions of H; in order for them also to be eigenfunctions of P,
we must have [H, P] = 0 which implies V = constant (and the constant
can be set to zero). Hence, free particles are the only solutions of the
time-independent Schr¨odinger equation that can be in states of definite
momentum; it is precisely these states which we examined in the previous
chapter.
Another very famous commutator is provided by the momentum and
position operators. Consider the one-dimensional case, [P, X]:
[P, X]ψ =

−iℏ
∂
∂x
xψ − x

−iℏ
∂ψ
∂x 
= −iℏψ
which implies
[P, X] = −iℏ
Thus, a particle can never be in a state which is simultaneously a state
of definite momentum and a state of definite position. Of course, if we
could measure both the position and momentum exactly, it would violate
the Heisenberg uncertainly principle discussed in the previous chapter.
These results regarding commutators provide a useful blueprint for mea￾suring quantities of interest. We will usually want our system to satisfy the
time-independent Schr¨odinger equation, which implies that the wave func￾tion is an eigenfunction of H and represents a state of definite energy E.
We will then want to find a set of operators A, B, C, . . . , which all commute
with H and also with each other:
[H, A] = 0
[H, B] = 0
[H, C] = 0
.
.
.
[A, B] = 0
[A, C] = 0
[B, C] = 0
.
.
.112 Quantum Mechanics: An Accessible Introduction
The fact that all of these operators commute with each other means that
we can find a wavefunction ψ for which
Hψ = Eψ
Aψ = aψ
Bψ = bψ
and so on. The set of eigenvalues E, a, b, etc. can be used to specify
ψ and are called good quantum numbers. When a measurement of the
corresponding observables is made, the results will be E, a, b, . . . .
5.2 Vector Spaces
In this section we introduce the concept of an abstract “vector space.”
First, consider a familiar three-dimensional vector. It can be represented
in one of two equivalent ways: either as a quantity with a given magnitude
and a direction in three dimensions, or as a set of components, (x, y, z).
Similarly, a two-dimensional vector can be represented as a quantity with
a given magnitude and direction in the x-y plane, or as a two-component
quantity, (x, y). It is the component representation which we will general￾ize. One can specify a vector in n dimensions as a set of n components:
(r1, r2, . . . , rn). Obviously, an n-dimensional vector cannot be represented
in ordinary three-dimensional space as a quantity with a magnitude and
direction, but any of the normal vector operations can be performed on it
by using its components. For instance, the sum and dot product of two
three-dimensional vectors r = (r1, r2, r3) and s = (s1, s2, s3) are just
r + s = (r1 + s1, r2 + s2, r3 + s3)
and
r·s = r1s1 + r2s2 + r3s3
In the same way, for two n-dimensional vectors, r = (r1, r2, . . . , rn) and
s = (s1, s2, . . . , sn), the sum and dot product are
r + s = (r1 + s1, r2 + s2, . . . , rn + sn)
and
r·s = r1s1 + r2s2 + · · · + rnsn
A vector space is simply a collection of objects (called vectors) which
act, in a general way, like familiar three-dimensional vectors. For instance,
the sum of two vectors r and s, must also be a vector:
r + s = t (5.9)Math interlude B: Linear algebra 113
while the product of a number c and a vector r must also be a vector:
cr = u (5.10)
Note that for our ordinary three-dimensional vectors, c can only be a real
number, but for some vector spaces c is assumed to be a complex number.
Thus, there are two different kinds of vector spaces: real vector spaces (for
which c in Equation (5.10) is restricted to be a real number) and complex
vector spaces (for which c can be complex). In quantum mechanics, we will
deal exclusively with complex vector spaces.
The properties given in Equations (5.9) and (5.10) may seem almost
trivial, but they allow the notion of a vector to be generalized to a wide
variety of other systems. For example, consider the set of real numbers.
Clearly, they obey Equations (5.9) and (5.10) (as long as we restrict c to
be a real number). Hence, the set of all real numbers is a vector space with
each real number acting as a vector. This result becomes obvious when we
realize that the real numbers are just equivalent to one-component vectors,
(r1); the set of real numbers forms a one-dimensional vector space.
A less obvious result is that the set of functions f(x) can also be treated
as a vector space. Clearly, the sum of two functions f(x) and g(x) is also
a function:
f(x) + g(x) = h(x)
and we can multiply a function by a real or complex number to get
another function. In fact, the set of functions behaves like an infinite￾dimensional vector space! To see this, consider first the three-dimensional
vector r = (1, 4, 9). We can display this vector in a rather strange way,
plotting ri as a function of i (see Figure 5.1). Similarly, an n-dimensional
vector (r1, r2, . . . , rn) can be displayed in a plot of ri as a function of i.
An example for n = 7 is shown in Figure 5.2. Consider what happens to
Figure 5.2 as we take the limit n → ∞. The points become denser, merging
into a continuous curve: a function! (See Figure 5.3.) This is a plausibility
argument rather than a rigorous proof, but it can be shown rigorously that
a suitably defined set of functions is, in fact, an infinite-dimensional vector
space.
Inner Products
As we have seen, one of the standard operations on a set of three￾dimensional vectors is the dot product: r·s = r1s1 + r2s2 + r3s3. It is114 Quantum Mechanics: An Accessible Introduction
0
1 2 3
i
2
4
6
8
10
ri
Fig. 5.1 A plot of ri as a function of i for the three-dimensional vector r = (1, 4, 9).
2 4 6 8
i
40
20
60
0
ri
Fig. 5.2 A plot of ri as a function of i for a 7-dimensional vector r = (r1, r2, . . . , r7).
trivial to generalize this to other finite-dimensional vectors, but what hap￾pens when we have an infinite-dimensional vector space, such as a set of
functions?
In this case we need to define a more abstract concept called an inner
product. Note that the dot product is a function which takes two vectors,
r and s, and produces a real number. Now suppose we have two vectors,
ψ and ϕ, in an abstract vector space. In analogy with the dot product,
we take the inner product to be a function which takes ψ and ϕ as inputs
and produces a real or complex number as the output. (As already noted,Math interlude B: Linear algebra 115
i
0
20 40 60 80 100
2000
4000
6000
8000
104
ri
Fig. 5.3 A function is the limiting case of an n-dimensional vector when n → ∞.
quantum mechanics makes use of complex vector spaces, so our inner prod￾ucts will produce complex numbers.) The inner product of ψ and ϕ will be
denoted (ψ|ϕ), such that
(ψ|ϕ) = c
where c is a complex number. Note that, in the world of mathematics,
there is no standard notation for the inner product. In addition to the
notation introduced here, (ψ, ϕ), ⟨ψ, ϕ⟩, and ⟨ψ|ϕ⟩ are also used. Later,
we will encounter yet another notation for inner products, called the Dirac
notation, which diverges in some respects from the standard mathematical
notation for inner products, but which is ultimately equivalent to it.
If ψ, ϕ, and θ are vectors in an arbitrary complex vector space, and c is116 Quantum Mechanics: An Accessible Introduction
a complex number, then inner products have the following properties:
(ψ + ϕ|θ) = (ψ|θ) + (ϕ|θ) (5.11)
(ψ|cϕ) = c(ψ|ϕ) (5.12)
(ψ|ϕ) = (ϕ|ψ)
∗
(5.13)
(ψ|ψ) ≥ 0 (5.14)
where, as usual, the * denotes complex conjugation. Note that Equa￾tions (5.12) and (5.13) together imply that
(cψ|ϕ) = c
∗
(ψ|ϕ) (5.15)
In physics, the standard convention is given by Equations (5.12) and (5.15);
mathematicians, on the other hand, use the reverse convention: (cψ|ϕ) =
c(ψ|ϕ) and (ψ|cϕ) = c
∗
(ψ|ϕ). Needless to say, we will use the physics
convention throughout.
For ordinary real three-dimensional vectors, the dot product satisfies
Equations (5.11)–(5.14) and is therefore an inner product (see Problem 5.3).
However, we are most interested in the vector space of functions, so we need
to define an inner product for this case. We argued at the beginning of this
section that a function resembles an n-dimensional vector in the limit where
n goes to infinity. We can use this analogy to derive a reasonable inner
product for functions. For two n-dimensional vectors, r = (r1, r2, . . . , rn)
and s = (s1, s2, . . . , sn), the n-dimensional inner product is r·s = r1s1 +
r2s2 + · · · + rnsn. Now consider two real-valued functions, f(x) and g(x).
The quantity analogous to the n-dimensional inner product is f(x1)g(x1)+
f(x2)g(x2) + · · · + f(xn)g(xn), in the limit where n → ∞. Taking the
continuum limit, the inner product should be R
f(x)g(x) dx. For complex￾valued functions, in order to satisfy Equations (5.13) and (5.14), the inner
product becomes R
f(x)
∗
g(x) dx.
More rigorously, consider the set of complex-valued functions in three
dimensions. For any two such functions, f(r) and g(r), the inner product
will be defined as
(f|g) = Z
f(r)
∗
g(r) d
3
r (5.16)
where the integral is taken over all of three-dimensional space. For the
frequently encountered case of functions in one dimension, this reduces to
(f|g) = Z ∞
x=−∞
f(x)
∗
g(x) dx (5.17)
Although we used a rough analogy to finite-dimensional vectors to moti￾vate these expressions, these definitions do not depend on this argument.Math interlude B: Linear algebra 117
All that is necessary for our expressions in Equations (5.16) and (5.17) to
represent valid inner products is that they satisfy Equations (5.11)–(5.14).
This is indeed the case (see Problem 5.3).
Example 5.4. An Inner Product
Consider two functions, ψ(x) = e
−x
2/2 and ϕ(x) = xe−x
2/2
. What is (ψ|ϕ)?
We have
(ψ|ϕ) = Z ∞
x=−∞
ψ(x)
∗ϕ(x) dx
=
Z ∞
x=−∞
(e
−x
2/2
)
∗xe−x
2/2
dx
=
Z ∞
x=−∞
xe−x
2
dx
but note that xe−x
2
is an odd function [i.e., a function for which f(−x) =
−f(x)], so the integral from −∞ to 0 cancels the integral from 0 to ∞.
Hence (ψ|ϕ) = 0.
Some of the results from Chapter 3 can now be cast in a much more
compact form, using inner product notation. For instance, the requirement
that the wave function ψ be normalized can now be written as
(ψ|ψ) = 1
In analogy with three-dimensional vectors, normalization means that the
“length” of an infinite-dimensional vector is 1.
Similarly, the expectation value of an operator O can now be expressed
in the compact form:
⟨o⟩ = (ψ|Oψ)
Adjoint and Hermitian Operators
The inner product derived in the previous section can be used to pair up
every operator with a second operator called its adjoint operator. If A is
an operator, then the adjoint operator of A is written as A†
, and it satisfies
the equation
(ϕ|Aψ) = (A
†ϕ|ψ) (5.18)
for all ϕ and ψ.118 Quantum Mechanics: An Accessible Introduction
Example 5.5. The Adjoint of the Derivative Operator
Consider the one-dimensional derivative operator D; what is its adjoint?
We can write, for arbitrary ϕ and ψ
(ϕ|Dψ) = Z ∞
x=−∞
ϕ(x)
∗
dψ
dx dx
Integration by parts gives
(ϕ|Dψ) = [ϕ(x)
∗ψ(x)]∞
−∞ −
Z ∞
x=−∞
dϕ
dx
∗
ψ(x) dx (5.19)
If ϕ and ψ represent wave functions for physical particles, we can assume
that ϕ → 0 and ψ → 0 as x → ±∞, so the first term in Equation (5.19)
vanishes, and the second term simplifies to
(ϕ|Dψ) = Z ∞
x=−∞
(−Dϕ)
∗ψ
= (−Dϕ|ψ)
Hence, from the definition of the adjoint operator, D† = −D.
From the definition of the adjoint operator (Equation (5.18)), the fol￾lowing general properties can be derived:
(cP)
† = c
∗P
†
(5.20)
(P + Q)
† = P
† + Q
†
(P Q)
† = Q
†P
†
(5.21)
(P
†
)
† = P
where c is a complex number, and P and Q are arbitrary operators. The
only nonintuitive result here is the reversal in the order of the operators P
and Q in Equation (5.21); this arises because of the way that operators are
“peeled away” to form the adjoint:
(ϕ|P[Qψ]) = (P
†ϕ|Qψ)
= (Q
†
[P
†ϕ]|ψ)
so (P Q)
† = Q†P
†
.
Note that for the operator corresponding to multiplication by the com￾plex number c, Equation (5.20) implies that
c
† = c
∗Math interlude B: Linear algebra 119
It is possible for an operator to be equal to its own adjoint, i.e., O† = O.
Such operators are called self-adjoint or Hermitian, and they occupy a
special place in quantum mechanics.
Example 5.6. The Position Operator Is Hermitian
As an example, we now show that the one-dimensional position operator
X is Hermitian.
We can write, for arbitrary ϕ and ψ,
(ϕ|Xψ) = Z ∞
x=−∞
ϕ(x)
∗xψ(x) dx
=
Z ∞
x=−∞
[xϕ(x)]∗ψ(x) dx
= (Xϕ|ψ)
so X† = X, and X is Hermitian.
The reason that Hermitian operators are important in quantum me￾chanics is that both the expectation values and the eigenvalues of Hermitian
operators are real. Since observable quantities are always real, we require
that the operators corresponding to observables be Hermitian.
Consider first the expectation value of a Hermitian operator Q: ⟨q⟩ =
(ψ|Qψ). In order for ⟨q⟩ to be real, it must equal its own complex conjugate.
From Equation (5.13), we have
⟨q⟩
∗ = (Qψ|ψ)
From the definition of the adjoint operator, this is equivalent to
⟨q⟩
∗ = (ψ|Q
†ψ)
and, since Q is Hermitian, we get
⟨q⟩
∗ = (ψ|Qψ) = ⟨q⟩
Hence, ⟨q⟩ is real.
Now suppose that ψ is an eigenfunction of a Hermitian operator Q with
eigenvalue q. Since Q is Hermitian,
(ψ|Qψ) = (Qψ|ψ)
which implies
(ψ|qψ) = (qψ|ψ)
q(ψ|ψ) = q
∗
(ψ|ψ)
q = q
∗120 Quantum Mechanics: An Accessible Introduction
so q must be real. Hence, Hermitian operators have both real expecta￾tion values and real eigenvalues. We have already shown that the position
operator is Hermitian; Problem 5.7 will show that several other operators
corresponding to observables are also Hermitian.
Basis Sets
Among the collection of all three-dimensional vectors, there are three vec￾tors that occupy a special place: the unit vectors in the x, y, and z di￾rections, denoted ˆx, ˆy, and ˆz. This collection of three vectors ˆx, ˆy, and ˆz
has several important properties. Any three-dimensional vector r can be
expressed as a linear combination of ˆx, ˆy, and ˆz, i.e., as the sum of the
product of each of these three vectors with a different real number:
r = c1xˆ + c2yˆ + c3zˆ (5.22)
This result indicates that we have “enough” vectors to do the job of decom￾posing every three-dimensional vector. However, we also don’t have “too
many” vectors in the sense that no one vector in our set of three can be
expressed in terms of the other two. One can never write, for example,
zˆ = c1xˆ + c2yˆ (5.23)
If ˆz could be expressed in this way, then ˆz would be irrelevant; Equa￾tion (5.23) could just be substituted into Equation (5.22) and ˆz could be
eliminated from Equation (5.22). In an abstract vector space, a subset of
vectors with these two properties (every vector can be represented as a
linear combination of the vectors in the subset, and no one vector in the
subset can be expressed as a linear combination of the rest) is called a basis.
In general, an n-dimensional vector space will have n distinct basis vectors.
The basis set ˆx, ˆy, and ˆz has two other desirable properties. First of
all, each vector has unit length, and second, each vector is perpendicular
to the other two: ˆx·yˆ = ˆx·zˆ = ˆy·zˆ = 0. A basis with these two additional
properties is called an orthonormal basis.
In general, we can find a basis set for any vector space, but the basis
will not be unique. In three dimensions, for example, there are an infinite
number of orthonormal bases, obtained by rotating the ˆx, ˆy, ˆz basis. For
instance, another perfectly acceptable orthonormal basis is (1/
√
2)(ˆx + ˆy),
(1/
√
2)(−xˆ + ˆy), ˆz.
Even infinite-dimensional vector spaces have basis sets. As an example,
consider the set of functions f(x) which are periodic with period 2π. Thus,
for these functions, f(x + 2π) = f(x). (The inner product for this vectorMath interlude B: Linear algebra 121
space will be defined by integration from 0 to 2π rather than −∞ to ∞.)
Since this is an infinite-dimensional vector space, its basis set will contain
an infinite set of functions.
Then a familiar example of a basis for this vector space is the set of
trigonometric functions:
1
√
π
sin x,
1
√
π
sin(2x), . . . ,
1
√
π
sin(nx), . . .
1
√
π
cos x,
1
√
π
cos(2x), . . . ,
1
√
π
cos(nx), . . .
Any periodic function can be written as a sum of these functions:
f(x) = X∞
n=0
An √
π
sin(nx) + X∞
n=0
Bn √
π
cos(nx) (5.24)
called a Fourier series. Further, this set of trigonometric functions forms
an orthonormal basis, since

1
√
π
sin mx




1
√
π
sin nx
=

1
√
π
cos mx




1
√
π
cos nx
= 0, m ̸= n
= 1, m = n
and

1
√
π
sin mx




1
√
π
cos nx
= 0
for all m and n.
Although any periodic function can be written as the sum of trigono￾metric basis functions, as in Equation (5.24), we need a procedure for de￾termining the constants An and Bn which multiply these trigonometric
functions. Again, an analogy to three-dimensional vectors is instructive.
Consider an arbitrary three-dimensional vector r, expanded out as
r = c1xˆ + c2yˆ + c3zˆ (5.25)
and suppose that we need to determine c1, c2, and c3. Since our basis is
orthonormal, we can take the dot product of r with ˆx to obtain
r·xˆ = c1(ˆx·xˆ) + c2(ˆy·xˆ) + c3(ˆz·xˆ)
= c1(1) + c2(0) + c3(0)
= c1
So c1 = r·xˆ. Similarly, c2 = r·yˆ and c3 = r·zˆ. This result shows that c1, c2,
and c3 are the magnitudes of the projection of r onto the x, y, and z axes,
respectively. Therefore, an alternate way of writing Equation (5.25) is
r = (r·xˆ)ˆx + (r·yˆ)ˆy + (r·zˆ)ˆz (5.26)122 Quantum Mechanics: An Accessible Introduction
Now suppose we take an arbitrary periodic function f(x) and wish to
expand it out in the form of Equation (5.24). In analogy to Equation (5.26),
we write
f(x) = 
f|
1
√
π
sin x

1
√
π
sin x +

f|
1
√
π
sin 2x

1
√
π
sin 2x + · · ·
+

f|
1
√
π
sin nx
1
√
π
sin nx + · · · +

f|
1
√
π
cos x

1
√
π
cos x
+

f|
1
√
π
cos 2x

1
√
π
cos 2x + · · · +

f|
1
√
π
cos nx
1
√
π
cos nx + · · ·
Thus, the Fourier coefficients An and Bn in Equation (5.24) are the inner
products of f(x) with the appropriate basis functions, e.g.,
An =

f|
1
√
π
sin nx
=
1
√
π
Z 2π
x=0
f(x) sin nx dx
and
Bn =

f|
1
√
π
cos nx
=
1
√
π
Z 2π
x=0
f(x) cos nx dx
Of course, the trigonometric functions are not the only possible basis
set, and this is where the connection to quantum mechanics becomes rel￾evant. Recall that for an arbitrary potential V (x), we can find a set of
solutions ψn(x) for the Schr¨odinger equation. This set of solutions will it￾self form a basis set, so that an arbitrary function can be expressed as a
linear combination of these solutions:
f(x) = X
n
cnψn(x)
The usefulness of this sort of expansion will become apparent later.
PROBLEMS
5.1 Verify the commutator properties given in Equations (5.4)–(5.7),
i.e., for any operators A, B, and C, show that
[A, B] = −[B, A]
[A, A] = 0
[A + B, C] = [A, C] + [B, C]
[A, BC] = [A, B]C + B[A, C]Math interlude B: Linear algebra 123
5.2 Consider a particle moving in three dimensions. Is it possible for
the particle to be in a state of definite px and y, i.e., can both its
y-coordinate and its momentum in the x direction be known at the
same time?
5.3 (a) Verify that the ordinary dot product for three-dimensional vec￾tors satisfies all of the properties of an inner product, given by
Equations (5.11)–(5.14).
(b) Verify that the inner product for complex-valued, three￾dimensional functions defined in Equation (5.16) satisfies Equa￾tions (5.11)–(5.14).
5.4 (a) The operators A, B, and C are all Hermitian with [A, B] = C.
Show that C = 0.
(b) The operators A and B are both Hermitian with [A, B] = iℏ.
Determine whether or not AB is a Hermitian operator.
5.5 The one-dimensional parity operator Π is defined by Πψ(x) =
ψ(−x). In other words, Π changes x into −x everywhere in the
function.
(a) Is Π a Hermitian operator?
(b) For what potentials V (x) is it possible to find a set of wavefunc￾tions which are eigenfunctions of the parity operator and solutions
of the one-dimensional time-independent Schr¨odinger equation?
5.6 (a) Let Q be an operator which is not a function of time, and let
H be the Hamiltonian operator. Show that
iℏ
∂
∂t⟨q⟩ = ⟨[Q, H]⟩
Here ⟨q⟩ is the expectation value of Q for an arbitrary time￾dependent wave function Ψ, which is not necessarily an eigenfunc￾tion of H, and ⟨[Q, H]⟩ is the expectation value of the commutator
of Q and H for the same wave function. This result is known as
Ehrenfest’s theorem.
(b) Use this result to show that
∂
∂t⟨p⟩ =

−
∂V
∂x 
What is the classical analog of this equation?124 Quantum Mechanics: An Accessible Introduction
5.7 (a) Show that the one-dimensional momentum operator is Hermi￾tian.
(b) Use this result to show that the one-dimensional Hamiltonian
operator H with potential V (x) is Hermitian. What (reasonable)
assumption must be made about V (x) to derive this result?
5.8 Suppose that the operator T is defined by T = αQ†Q, where α is
a real number, and Q is an operator (not necessarily Hermitian).
Show that T is Hermitian.
5.9 Determine all potentials V (x) for which it is possible to find a set of
solutions of the time-independent Schr¨odinger equation which are
also eigenfunctions of the position operator X, or else show that
no such potentials exist.
5.10 Suppose that two operators P and Q satisfy the commutation re￾lation
[P, Q] = Q
Suppose that ψ is an eigenfunction of the operator P with eigen￾value p. Show that Qψ is also an eigenfunction of P, and find its
eigenvalue.
5.11 The operator F is defined by F ψ(x) = ψ(x+a)+ψ(x−a), where a
is a nonzero constant. Determine whether or not F is a Hermitian
operator.Chapter 6
Solutions of the three-dimensional
time-independent Schr¨odinger
equation
In Chapter 4 we examined solutions of the one-dimensional time￾independent Schr¨odinger equation,
−
ℏ
2
2m
d
2ψ
dx2
+ V (x)ψ = Eψ
Of course, the real world is three-dimensional, so in this chapter we will
solve the full three-dimensional, time-independent Schr¨odinger equation.
Along the way, we will need to understand the behavior of angular momen￾tum in quantum mechanics. The crowning achievement of the solution of
the three-dimensional Schr¨odinger equation (and of this chapter) will be a
description of the hydrogen atom.
The three-dimensional Schr¨odinger equation is:
−
ℏ
2
2m
∇2Ψ(r, t) + V (r)Ψ(r, t) = iℏ
∂Ψ(r, t)
∂t
We will assume throughout this chapter that the wave function represents a
state of definite energy E, so that the Schr¨odinger equation can be written
in the time-independent form:
−
ℏ
2
2m
∇2ψ(r) + V (r)ψ(r) = Eψ(r) (6.1)
In order to solve Equation (6.1), we need to choose a particular coordinate
system, e.g., rectangular, cylindrical, or spherical. Of course, the physical
solution does not depend on the coordinate system we choose; instead, the
correct choice of coordinates can simplify the form of the solution by taking
advantage of the symmetries in the problem. For example, a central force,
defined as a force which points radially inward or outward, corresponds to
a potential that is a function only of radial distance r. (An example is
the potential experienced by an electron in a hydrogen atom.) For such a
125126 Quantum Mechanics: An Accessible Introduction
a
b
c
z
y
x
Fig. 6.1 A particle of mass m is confined to a rectangular box with sides of length a,
b, and c.
potential, the spherical coordinate system is most appropriate. However,
as a warm-up, we will first examine a problem which can be solved in a
simple way in rectangular coordinates.
6.1 Solution in Rectangular Coordinates
Consider a particle of mass m, confined to move in a rectangular box with
sides of length a, b, and c (Figure 6.1). We choose a rectangular coordinate
system with ˆx along the side of length a, ˆy along the side of length b, and
zˆ along the side of length c, and one corner of the box at the origin. Then
the potential is simply
V (r) = 0, 0 < x < a
0 < y < b
0 < z < c
with infinite potential barriers at x = 0, x = a, y = 0, y = b, and z = 0,
z = c. This is the three-dimensional analog of the infinite one-dimensional
square-well potential discussed in Chapter 4.
Inside the box, where V = 0, Equation (6.1) becomes
−
ℏ
2
2m
∇2ψ(r) = Eψ(r)
which can be written as
∂
2ψ
∂x2
+
∂
2ψ
∂y2
+
∂
2ψ
∂z2
= −
2mE
ℏ
2
ψ (6.2)
As in Chapter 3, we use separation of variables. (The solution here is
slightly more complicated than the separation of variables solutions inSolutions of the three-dimensional time-independent Schr¨odinger equation 127
Chapter 3, since we now have three independent variables.) We take a
trial solution of the form
ψ(x, y, z) = ψ1(x)ψ2(y)ψ3(z) (6.3)
In this equation, ψ1(x) is an unknown function of x and is independent of
y and z. Similarly, ψ2(y) is an unknown function of y which is independent
of x and z, and so on. Our job is then to find the functions ψ1, ψ2, and ψ3.
Substituting Equation (6.3) into Equation (6.2) gives
∂
2ψ1(x)
∂x2
ψ2(y)ψ3(z) + ψ1(x)
∂
2ψ2(y)
∂y2
ψ3(z) + ψ1(x)ψ2(y)
∂
2ψ3(z)
∂z2
= −
2mE
ℏ
2
ψ1(x)ψ2(y)ψ3(z)
and dividing both sides by ψ1(x)ψ2(y)ψ3(z) yields
1
ψ1(x)
∂
2ψ1(x)
∂x2
+
1
ψ2(y)
∂
2ψ2(y)
∂y2
+
1
ψ3(z)
∂
2ψ3(z)
∂z2
= −
2mE
ℏ
2
(6.4)
Now consider what happens if we move the second and third terms on the
left-hand side over to the right-hand side:
1
ψ1(x)
∂
2ψ1(x)
∂x2
= −
2mE
ℏ
2
−
1
ψ2(y)
∂
2ψ2(y)
∂y2
−
1
ψ3(z)
∂
2ψ3(z)
∂z2
(6.5)
The left-hand side of this equation is a function only of x and is independent
of y and z. On the other hand, the right-hand side is a function only of
y and z and is independent of x. There is only one function that satisfies
both of these requirements: a constant, which is independent of x, y, and
z. Hence, we can set both the left-hand side and the right-hand side of
Equation (6.5) equal to some (still to be determined) constant, which we
will call Cx:
1
ψ1(x)
d
2ψ1(x)
dx2
= Cx (6.6)
But now note that we can again begin with Equation (6.4) and, instead of
leaving the first term on the left-hand side, we can leave the second or third
terms. Leaving the second term on the left-hand side, a similar argument
gives
1
ψ2(y)
d
2ψ2(y)
dy2
= Cy (6.7)
where Cy is another undetermined constant, while leaving the third term
on the left-hand side produces
1
ψ3(z)
d
2ψ3(z)
dz2
= Cz (6.8)128 Quantum Mechanics: An Accessible Introduction
Thus, we have transformed a single partial differential equation (Equa￾tion (6.4)) into three ordinary differential equations. Note that Cx, Cy,
and Cz are not completely independent. Adding Equations (6.6), (6.7),
and (6.8), and comparing with Equation (6.4), we get
Cx + Cy + Cz = −
2mE
ℏ
2
It is possible to put Equations (6.6)–(6.8) into a form that we have already
seen. Define the new constants Ex, Ey, and Ez to be given by Cx =
−2mEx/ℏ
2
, Cy = −2mEy/ℏ
2
, and Cz = −2mEz/ℏ
2
. Note that Ex, Ey,
and Ez have no physical significance, but their sum does; it is the total
energy:
Ex + Ey + Ez = E
If we rewrite Equations (6.6)–(6.8) in terms of Ex, Ey, and Ez, instead of
Cx, Cy, and Cz, we get the three equations
d
2ψ1(x)
d
2x
+
2mEx
ℏ
2
ψ1(x) = 0 (6.9)
d
2ψ2(y)
d
2y
+
2mEy
ℏ
2
ψ2(y) = 0 (6.10)
d
2ψ3(z)
d
2z
+
2mEz
ℏ
2
ψ3(z) = 0 (6.11)
supplemented by the boundary condition that the wave function must van￾ish on the sides of the box, which gives ψ1(x) = 0 at x = 0 and x = a,
ψ2(y) = 0 at y = 0 and y = b, and ψ3(z) = 0 at z = 0 and z = c. But
we have seen equations of this form before. Equations (6.9), (6.10), and
(6.11) all have the form of the Schr¨odinger equation for a one-dimensional
infinite square well (Equation (4.28)) with the same boundary conditions
as the infinite one-dimensional square well. Hence, the solutions to these
equations are the same as the solutions previously derived in Chapter 4,
namely,
ψ1(x) ∝ sin nxπx
a

with corresponding energy
En =
ℏ
2π
2
2ma2
n
2
x
and similarly for ψ2(y) and ψ3(z). Using Equation (6.3) to reassemble the
wave function, we get
ψ(x, y, z) = A sin nxπx
a

sin nyπy
b

sin nzπz
c
Solutions of the three-dimensional time-independent Schr¨odinger equation 129
where nx, ny, and nz can each take on positive integer values, and A is the
normalization constant. (This normalization constant is A =
p
8/V , where
V is the volume of the box; see Problem 6.1.) The energy corresponding to
a given nx, ny, and nz is
E = Ex + Ey + Ez
=

ℏ
2π
2
2m
 
n
2
x
a
2
+
n
2
y
b
2
+
n
2
z
c
2
!
Consider what happens for the special case of a cube of side a. For this
case, the wave function with quantum numbers nx, ny, and nz is
ψ(x, y, z) = A sin nxπx
a

sin nyπy
a

sin nzπz
a

with corresponding energy levels
E =

ℏ
2π
2
2ma2

(n
2
x + n
2
y + n
2
z
)
Now we see an interesting new phenomenon. Consider the two states nx =
1, ny = 1, nz = 2 and nx = 1, ny = 2, and nz = 1. These correspond to two
different wave functions, but they have the same energy. This illustrates the
phenomenon of degeneracy. Two different states are said to be degenerate
if they have the same energy but different wave functions. (As noted in the
previous chapter, degeneracy in linear algebra occurs when two different
eigenvectors have the same eigenvalue. In this case the two different wave
functions are both eigenfunctions of the Hamiltonian H, and they have the
same eigenvalue E.) Note that our two wave functions in this case are
related by an interchange of the x- and y-axes, which leaves the potential
unchanged. Degeneracies often arise from this sort of symmetry.
6.2 Angular Momentum
Before moving on to examine quantum mechanical systems with spherical
symmetry, it is necessary to derive a quantum mechanical treatment of
angular momentum. Recall that for a classical particle with momentum p
at position r relative to the origin, the angular momentum is a vector given
by the cross product of r and p (Figure 6.2):
L = r×p
We now need to derive a quantum mechanical operator corresponding to
L. Note that we already have an operator R corresponding to the position130 Quantum Mechanics: An Accessible Introduction
p
L
r
x
y
z
Fig. 6.2 In classical mechanics, the angular momentum L for a particle with momentum
p at the position r relative to the origin is L = r×p.
r, namely multiplication by r, and we have an operator P corresponding
to the momentum p, namely −iℏ∇. (We will use the lowercase symbols r
and p to refer to the physical position and momentum, and the uppercase
symbols R and P to refer to the corresponding operators.) Hence, the
operator corresponding to angular momentum should simply be
L = R×P (6.12)
In practice, however, it is easier to break L down into its components, and
to calculate the operators corresponding to the x, y, and z components of
angular momentum, namely, Lx, Ly, and Lz. Then Equation (6.12) gives
Lx = Y Pz − ZPy
Ly = ZPx − XPz
Lz = XPy − Y Px
All three of these operators are Hermitian.
Example 6.1. Show that the Operator Lz is Hermitian
The adjoint of Lz is
L
†
z = (XPy)
† − (Y Px)
†
The rules for taking adjoints of sums and products of operators (Chapter 5)
give
L
†
z = P
†
y X† − P
†
xY
†Solutions of the three-dimensional time-independent Schr¨odinger equation 131
But the momentum and position operators are Hermitian, so that
L
†
z = PyX − PxY
Now recall that Py commutes with X, and Px commutes with Y , so that
L
†
z = XPy − Y Px = Lz
so Lz is Hermitian. The argument is similar for the other components of L
(Problem 6.5).
Now consider how well we can measure the angular momentum of a
particle. Suppose that we have a particle for which we would like to measure
the angular momentum exactly. For this to be possible, the particle must be
in an eigenstate of each component of L, i.e., Lx, Ly, and Lz. However, this
is possible only if Lx, Ly, and Lz all commute with each other. Consider,
for example, whether or not Lx and Ly commute with each other. We have
[Lx, Ly] = [Y Pz − ZPy, ZPx − XPz] (6.13)
To simplify this expression, we need to know all commutators of the
form [Pz, X], [Py, Z], and so on. In the previous chapter, we derived the
commutator for the one-dimensional momentum and position operators,
which corresponds to
[X, Px] = iℏ
and similarly for the y and z components. But what happens if the position
and momentum in this equation correspond to different components, e.g.,
does Py commute with X? In general, all of the position and momentum
operators commute with each other as long they correspond to different
components. For instance,
[X, Py]ψ = x(−iℏ)
∂ψ
∂y − (−iℏ)
∂
∂y (xψ) = 0
A shorthand for this result that encapsulates all of these commutation
relations is
[Rα, Pβ] = iℏδαβ
where x, y, and z correspond to α = 1, 2, 3 and β = 1, 2, 3, and δαβ is called
the Kronecker delta; it has the value
δαβ = 1, α = β
= 0, α ̸= β132 Quantum Mechanics: An Accessible Introduction
Furthermore, the different components of position and momentum all com￾mute with each other, i.e.,
[X, Y ] = [X, Z] = [Y, Z] = 0
and
[Px, Py] = [Px, Pz] = [Py, Pz] = 0
(see Problem 6.6).
The simplification of Equation (6.13) also requires the use of the iden￾tities (from Chapter 5),
[A + B, C] = [A, C] + [B, C]
and
[AB, C] = A[B, C] + [A, C]B
These identities allow Equation (6.13) to be reduced to
[Lx, Ly] = [Y Pz, ZPx] − [ZPy, ZPx] − [Y Pz, XPz] + [ZPy, XPz]
for which the second and third terms are zero (since they contain only
factors which commute with each other), while the first and fourth terms
reduce to
[Lx, Ly] = Y PzZPx − ZPxY Pz + ZPyXPz − XPzZPy
= Y Px[Pz, Z] − XPy[Pz, Z]
= −iℏ(Y Px − XPy)
= iℏLz
Similarly,
[Ly, Lz] = iℏLx
and
[Lz, Lx] = iℏLy
Thus, none of the three components of L commutes with any of the others.
This means that we cannot measure the full angular momentum exactly;
instead, we can measure only a single component of the angular momentum!
We will normally take this component to be Lz, i.e., we will look for states
which are eigenfunctions of Lz. This choice is, however, arbitrary. It is a
convenient choice because, in spherical coordinates, the angular variable θ
is normally measured relative to the z-axis. But this does not mean thatSolutions of the three-dimensional time-independent Schr¨odinger equation 133
there is anything special about Lz; we could just as easily have chosen to
measure Lx or Ly instead.
Can we measure anything else about the angular momentum other than
the value of a single component? In fact, we can also measure the square
of the magnitude of the angular momentum. The corresponding operator
is L
2 = L
2
x + L
2
y + L
2
z
, and this operator commutes with Lz:
[L
2
, Lz] = [L
2
x + L
2
y + L
2
z
, Lz]
= [L
2
x
, Lz] + [L
2
y
, Lz] + [L
2
z
, Lz]
The last term is zero, and the other terms give
[L
2
, Lz] = Lx[Lx, Lz] + [Lx, Lz]Lx + Ly[Ly, Lz] + [Ly, Lz]Ly
= −iℏLxLy − iℏLyLx + iℏLyLx + iℏLxLy
= 0
This means that a particle can be in an eigenstate of L
2 and Lz simulta￾neously, i.e., we can measure the total magnitude squared of the angular
momentum and its component in the z direction.
But what result will we get if we actually do measure these two quan￾tities? The answer is given by the eigenvalues of L
2 and Lz. One might
think that these eigenvalues are fairly arbitrary and would depend on the
particular wave function (as is, for example, the case for the eigenvalues of
H, which correspond to energy). However, this is not the case. If ψ is an
eigenfunction of both L
2 and Lz, then the eigenvalues of these operators
are actually restricted to a small class of possible values, which we will now
calculate.
Before beginning this calculation, we need to point out that there are
actually two kinds of angular momentum that are observed at the atomic
level. The first is the familiar orbital angular momentum, which is equiva￾lent, classically, to the orbit of a particle. An example of this is the angular
momentum of the electron as it orbits the nucleus of an atom. However,
particles, such as the electron and proton, also have an internal angular
momentum called spin angular momentum. Naively, one can imagine these
particles behaving like rotating balls. However, spin differs so much from
our intuitive ideas of rotational motion that this analogy is quite crude. We
will be mostly concerned with orbital angular momentum in this chapter
and will deal with spin angular momentum in Chapter 8. However, the
discussion which follows in this section will be kept as general as possible.
When dealing with general angular momentum (as opposed to orbital or
spin angular momentum), we will use the symbol J. Then L will always134 Quantum Mechanics: An Accessible Introduction
refer to orbital angular momentum, and spin angular momentum will be
denoted by the operator S.
Assume, then, that the angular momentum operator J obeys the com￾mutation relations we derived above, namely,
[Jx, Jy] = iℏJz (6.14)
[Jz, Jx] = iℏJy
[Jy, Jz] = iℏJx
Furthermore, J
2
commutes with each of the individual operators, Jx, Jy,
and Jz. We will now assume that ψ is an eigenfunction of J
2 and Jz, and
we will calculate the possible eigenvalues of these two operators.
To perform this calculation, we will make use of a special set of oper￾ators called ladder operators. This will allow us to find the allowed eigen￾values of J
2 and Jz without even calculating what the wave function looks
like (although we will, in fact, find explicit forms for the orbital angular
momentum eigenfunctions in the next section). The ladder operators are
designated J+ and J−, and they are defined by
J+ = Jx + iJy
J− = Jx − iJy
These operators, J+ and J−, are also called the raising and lowering op￾erators, respectively. Note that J+ and J− are not Hermition operators,
e.g., J
†
+ = J
†
x −iJ†
y = J−. Hence, these two operators do not correspond to
observable quantities. Rather, they can be used to turn one eigenfunction
of J
2 and Jz into another eigenfunction with a different set of eigenvalues.
Suppose, for instance, that ψ is an eigenfunction of J
2 and Jz with
eigenvalues α, β, so that
J
2ψ = αψ
Jzψ = βψ
and suppose that J+ operates on this eigenfunction to give some new wave
function ϕ:
J+ψ = ϕ
It is now possible to find J
2ϕ and Jzϕ. Note that J
2
commutes with Jx
and Jy individually, so it also commutes with J+. Therefore,
J
2ϕ = J
2
(J+ψ) = J+(J
2ψ) = αJ+ψ = αϕSolutions of the three-dimensional time-independent Schr¨odinger equation 135
so ϕ is also an eigenfunction of J
2 with the same eigenvalue as ψ. On the
other hand, J+ does not commute with Jz. Instead, we have
[Jz, J+] = [Jz, Jx + iJy]
= [Jz, Jx] + i[Jz, Jy]
= iℏJy + ℏJx
= ℏJ+
This means that
Jzϕ = Jz(J+ψ)
= J+Jzψ + ℏJ+ψ
= βJ+ψ + ℏJ+ψ
= (β + ℏ)ϕ
To summarize, J+ transforms the wave function ψ with eigenvalues α and
β (for operators J
2 and Jz) into a new wave function with eigenvalues α
and β + ℏ. So the eigenvalue of J
2
is unchanged, but the eigenvalue of Jz
is increased by ℏ. If we apply J+ to our new function ϕ, we will get yet
another eigenfunction of J
2 and Jz with the same eigenvalue of J
2 but a new
eigenvalue for Jz, namely β + 2ℏ. We can continue this process, increasing
the eigenvalue of Jz at each step; hence the name ladder operator. (As one
might have guessed, J− has the opposite effect: it keeps the eigenvalue of
J
2 fixed, but lowers the eigenvalue of Jz by ℏ.)
It would appear that we could continue this process indefinitely, ob￾taining an infinite number of different eigenfunctions for Jz. However, this
is not the case; it turns out that there is an upper limit on the possible
eigenvalues of Jz. To see this, assume once more that ψ is a normalized
eigenfunction of both J
2 and Jz with eigenvalues α and β, respectively.
Since J
2 = J
2
x + J
2
y + J
2
z
, we can write
(ψ, J2ψ) − (ψ, J2
z ψ) = (ψ, J2
xψ) + (ψ, J2
yψ)
Now the left-hand side is α(ψ, ψ)−β
2
(ψ, ψ) = α−β
2
, while the right-hand
side is (since Jx and Jy are both Hermitian) just (Jxψ, Jxψ) + (Jyψ, Jyψ).
This latter quantity is nonnegative from Equation (5.14). Hence, we have
α − β
2 ≥ 0
so
β
2 ≤ α136 Quantum Mechanics: An Accessible Introduction
Note that there is a classical analogy to this result: the z component of
a vector cannot be larger than the vector itself! Therefore, classically,
J
2
z ≤ J
2
.
How do we reconcile this upper bound on β with the fact that we can
repeatedly apply J+ to ψ and increase the value of β each time? This is
possible only if there is an eigenfunction of J
2 and Jz, which we will call
ψmax, for which
J+ψmax = 0
Thus, as we apply J+ repeatedly, we get larger and larger values for β, but
the process terminates when we reach ψmax. A similar argument shows
that there must be an eigenfunction ψmin for which
J−ψmin = 0
We can use these two eigenfunctions to derive the possible eigenvalues of J
2
and Jz. From the definitions of J+ and J−, it is tedious but straightforward
to show that
J
2 = J−J+ + J
2
z + ℏJz (6.15)
J
2 = J+J− + J
2
z − ℏJz (6.16)
Using Equation (6.15), we see that
J
2ψmax = J−J+ψmax + J
2
z ψmax + ℏJzψmax
αψmax = 0 + β
2
maxψ + ℏβmaxψ
where βmax is the eigenvalue of Jz for the eigenstate ψmax. Thus,
α = β
2
max + ℏβmax (6.17)
Similarly, applying J
2
to the state ψmin, and using Equation (6.16), we get
α = b
2
min − ℏbmin (6.18)
Subtracting Equation (6.18) from (6.17) gives
b
2
max − b
2
min + ℏ(bmax + bmin) = 0
which has the solution
bmin = −bmax (6.19)
But recall that we can apply J+ repeatedly to ψ and with each appli￾cation, increase the eigenvalue of Jz by ℏ. Hence, all of the eigenvalues of
Jz must differ from each other by an integer multiple of ℏ, so
bmax = bmin + nℏ (6.20)Solutions of the three-dimensional time-independent Schr¨odinger equation 137
where n is an integer. Combining Equations (6.19) and (6.20) gives
bmax − (−bmax) = nℏ
so that
bmax = n
ℏ
2
(6.21)
Define a new number j given by j = n/2, so that j is an integer or a
half-integer:
j = 0,
1
2
, 1,
3
2
, 2, . . . (6.22)
Then from Equations (6.17) and (6.21), we have
α = j
2
ℏ
2 + jℏ
2 = ℏ
2
j(j + 1)
with the possible values of j given by Equation (6.22).
We also know that β must go in integer steps of ℏ from −jℏ to +jℏ, so
β = −jℏ, −jℏ + ℏ, . . . ,(j − 1)ℏ, jℏ
A convenient way to write this is
β = mjℏ, mj = −j, −j + 1, . . . , j
To summarize, then, if ψ is an eigenfunction of both J
2 and Jz, then
its possible eigenvalues for J
2 are ℏ
2
j(j + 1), i.e.,
J
2ψ = ℏ
2
j(j + 1)ψ (6.23)
where j is an integer or a half-integer,
j = 0,
1
2
, 1,
3
2
, . . . (6.24)
and the eigenvalues of Jz depend on the value of j, namely,
Jzψ = mjℏψ (6.25)
where
mj = −j, −j + 1, . . . , j − 1, j (6.26)
Here is another example of quantization: the total squared angular mo￾mentum and the z component cannot have arbitrary values. Instead, they
are restricted to the discrete values given in Equations (6.23)–(6.26). In
fact, the quantization of angular momentum differs from energy quantiza￾tion in an important respect: although a given potential will have a lowest￾energy state, there is no absolute lower bound on the energy that can exist138 Quantum Mechanics: An Accessible Introduction
in nature; the potential can always be altered to produce a lower-energy
ground state. With angular momentum, on the other hand, there is an
absolute lowest angular momentum state. For example, the z component
of angular momentum, if it is nonzero, cannot be smaller than ℏ/2; this
represents the smallest “unit” of angular momentum found in nature.
Example 6.2. Solving the One-dimensional Simple Harmonic
Oscillator Using Ladder Operators
The simple harmonic oscillator in one dimension can also be solved by the
method of ladder operators. This solution is simpler and more elegant than
the one in Chapter 4.
For a particle of mass m in a one-dimensional simple harmonic oscillator
potential V (x) = 1
2Kx2
, the Hamiltonian operator is
H = −
ℏ
2
2m
d
2
dx2
+
1
2
Kx2
Define the ladder operators a− and a+ to be given by
a+ =
r
K
2
x −
ℏ
√
2m
d
dx
and
a− =
r
K
2
x +
ℏ
√
2m
d
dx
We can now show that
[H, a+] = ℏωa+
and
[H, a−] = −ℏωa−
where ω =
p
K/m. For a+, we have
[H, a+] = "
−
ℏ
2
2m
d
2
dx2
+
1
2
Kx2
,
r
K
2
x −
ℏ
√
2m
d
dx#
=
"
−
ℏ
2
2m
d
2
dx2
,
r
K
2
x
#
+
"
1
2
Kx2
,
r
K
2
x
#
+

−
ℏ
2
2m
d
2
dx2
, −
ℏ
√
2m
d
dx
+

1
2
Kx2
, −
ℏ
√
2m
d
dx
The second and third terms are zero, and the remaining two terms simplify
to
[H, a+] = −
ℏ
2
2m
r
K
2

d
2
dx2
, x
−
K
2
ℏ
√
2m

x
2
,
d
dxSolutions of the three-dimensional time-independent Schr¨odinger equation 139
Using the commutator identities, this expands out to
[H, a+] = −
ℏ
2
2m
r
K
2

d
dx 
d
dx, x
+

d
dx, x
d
dx
−
K
2
ℏ
√
2m

x

x,
d
dx
+

x,
d
dx
x

Now note that

x,
d
dx
= −1
(This is trivially derived from [X, Px] = iℏ.) Then we get
[H, a+] = −
ℏ
2
2m
r
K
2
d
dx(+2) −
K
2
ℏ
√
2m
x(−2)
= ℏ
r
K
m
 r
K
2
x −
ℏ
√
2m
d
dx!
= ℏωa+
Similarly, for a−, we get
[H, a−] = "
−
ℏ
2
2m
d
2
dx2
+
1
2
Kx2
,
r
K
2
x +
ℏ
√
2m
d
dx#
=
"
−
ℏ
2
2m
d
2
dx2
,
r
K
2
x
#
+
"
1
2
Kx2
,
r
K
2
x
#
+

−
ℏ
2
2m
d
2
dx2
,
ℏ
√
2m
d
dx
+

1
2
Kx2
,
ℏ
√
2m
d
dx
= −
ℏ
2
2m
r
K
2

d
2
dx2
, x
+
K
2
ℏ
√
2m

x
2
,
d
dx
= −
ℏ
2
2m
r
K
2

d
dx 
d
dx, x
+

d
dx, x
d
dx
+
K
2
ℏ
√
2m

x

x,
d
dx
+

x,
d
dx
x

= −
ℏ
2
2m
r
K
2
d
dx(+2) + K
2
ℏ
√
2m
x(−2)
= −ℏ
r
K
m
 r
K
2
x +
ℏ
√
2m
d
dx!
= ℏωa−140 Quantum Mechanics: An Accessible Introduction
We can now show that if ψ(x) is a solution of the time-independent
Schr¨odinger equation for the harmonic oscillator with energy E, then
a+ψ(x) is also a solution of the time-independent Schr¨odinger equation
for the harmonic oscillator with energy E + ℏω, and a−ψ(x) is a solution
with energy E − ℏω.
Applying [H, a+] = ℏωa+ to ψ gives
Ha+ψ − a+Hψ = ℏωa+ψ
But ψ is a solution to the time-independent Schr¨odinger equation with
energy E, so Hψ = Eψ. Substituting this into the equation above gives
Ha+ψ − a+Eψ = ℏωa+ψ
which can be written as
H(a+ψ) = (E + ℏω)(a+ψ)
so a+ψ is a solution of the Schr¨odinger equation with energy E + ℏω. Sim￾ilarly, applying [H, a−] = −ℏωa+ to ψ gives
Ha−ψ − a−Hψ = −ℏωa−ψ
and Hψ = Eψ, so
Ha−ψ − a−Eψ = −ℏωa−ψ
so
H(a−ψ) = (E − ℏω)a−ψ
so a−ψ is a solution of the Schr¨odinger equation with energy E − ℏω.
Further, we have
a+a− =
 r
K
2
x −
ℏ
√
2m
d
dx! r
K
2
x +
ℏ
√
2m
d
dx!
= −
ℏ
2
2m
d
2
dx2
+
K
2
x
2 +
ℏ
√
2m
r
K
2

x
d
dx −
d
dxx

= H +
ℏ
√
2m
r
K
2
(−1)
= H − ℏω/2
There is no upper bound on the possible values for E, but there is a
lower bound; the energy cannot be negative. This means that if ψ0(x) is
the ground state wave function, then a−ψ0(x) = 0. Suppose that ψ0 is the
ground state wave function. Then
a+a−ψ0 = (H − ℏω/2)ψ0Solutions of the three-dimensional time-independent Schr¨odinger equation 141
But a−ψ0 = 0, so (H − ℏω/2)ψ0 = 0, so
Hψ0 = (ℏω/2)ψ0
But this is just the Schr¨odinger equation with energy E = ℏω/2, which is
therefore the energy of the ground state wave function.
The expression a−ψ0 = 0 produces the differential equation:
 r
K
2
x +
ℏ
√
2m
d
dx!
ψ0 = 0
which can be written as
dψ0
ψ0
= −
r
K
2
√
2m
ℏ
x
with solution
ln ψ0 = −
1
2
r
K
2
√
2m
ℏ
x
2 + C
or
ψ0 = Ae−(1/2)(√
Km/ℏ)x
2
where A is the normalization constant. This is the desired ground-state
wave function. Then the excited state wave functions derived in Chapter 4
are given by applying a+ repeatedly to this wave function.
6.3 The Schr¨odinger Equation in Spherical Coordinates
In quantum mechanics, the case of spherical symmetry is often encoun￾tered. The most obvious example of this is the potential experienced by
the electron in a hydrogen atom, given by
V (r) = −
1
4πϵ0
e
2
r
In this case the potential depends only on the radial distance r; such po￾tentials are called central potentials. For central potentials, the spherical
coordinate system is the most convenient.
The spherical coordinate system is described by the coordinates r, θ,
and ϕ, where r is the distance from the origin, θ is the angle relative to the142 Quantum Mechanics: An Accessible Introduction
u
f
r
z
z
y
x
Fig. 6.3 The spherical coordinate system expresses all positions as a function of r, θ,
and ϕ.
z-axis, and ϕ gives the azimuthal angle relative to the x-axis (Figure 6.3).
Spherical coordinates are related to the familiar rectangular coordinates by
x = r sin θ cos ϕ (6.27)
y = r sin θ sin ϕ (6.28)
z = r cos θ (6.29)
Using these relations, any operator in rectangular coordinates can be ex￾pressed in terms of spherical coordinates, and vice versa.
Example 6.3. Expressing the Operator ∂/∂ϕ in Rectangular
Coordinates
To transform from spherical coordinates to rectangular coordinates, we use
∂
∂ϕ =
∂x
∂ϕ
∂
∂x +
∂y
∂ϕ
∂
∂y +
∂z
∂ϕ
∂
∂z
Substituting Equations (6.27)–(6.29) for the derivatives gives
∂
∂ϕ = −r sin θ sin ϕ
∂
∂x + r sin θ cos ϕ
∂
∂y + 0
= −y
∂
∂x + x
∂
∂y
Now we can express the angular momentum operators in spherical co￾ordinates. The result of Example 6.3 can be used to find Lz:
−iℏ
∂
∂ϕ = −Y Px + XPySolutions of the three-dimensional time-independent Schr¨odinger equation 143
which gives the desired expression for Lz:
Lz = −iℏ
∂
∂ϕ (6.30)
Note the resemblance to the one-dimensional linear momentum operator,
Px = −iℏ(∂/∂x). In both cases the operator is based on the derivative
in the direction of the classical motion. Using similar methods (but much
more algebra!) the operator L
2
can also be derived in spherical coordinates:
L
2 = −ℏ
2

1
sin θ
∂
∂θ 
sin θ
∂
∂θ 
+
1
sin2
θ
∂
∂ϕ2

(6.31)
These operators can be used to calculate explicitly the eigenfunctions and
eigenvalues of L
2 and Lz.
Consider first the eigenvalues of Lz. From the previous section, we know
that such eigenvalues must be of the form mℏ with m given by an integer or
half-integer. However, this represents the set of all possible eigenvalues for
a general angular momentum operator; we are dealing with a special case
(orbital angular momentum) characterized by a specific angular momentum
operator, so it is possible that some of these eigenvalues are excluded.
Assume that ψ(r, θ, ϕ) is an eigenfunction of Lz with eigenvalue mlℏ:
Lzψ = mlℏψ
where the l subscript on m indicates that we are dealing with orbital angular
momentum. Once again, we use separation of variables and assume that
the solution is of the form
ψ(r, θ, ϕ) = R(r)F(θ)G(ϕ)
Using this form for ψ, along with the expression for Lz from Equa￾tion (6.30), our eigenvalue equation becomes
−iℏR(r)F(θ)
dG
dϕ = mlℏR(r)F(θ)G(ϕ)
−iℏ
dG
dϕ = mlℏG
which has the solution
G(ϕ) = e
imlϕ
so that
ψ(r, θ, ϕ) = R(r)F(θ)e
imlϕ
(6.32)
Equation (6.32) gives the general ϕ-dependence for any wave function that
is an eigenfunction of Lz.144 Quantum Mechanics: An Accessible Introduction
Now note that we must impose an additional condition on ψ. In spher￾ical coordinates, increasing ϕ by 2π just amounts to a 360 degree rotation,
so it brings any system back to the same position in physical space. Hence,
it must be true that
ψ(r, θ, ϕ + 2π) = ψ(r, θ, ϕ)
so Equation (6.32) gives
e
iml(ϕ+2π) = e
imlϕ
which implies
e
2πiml = 1
This equation is satisfied if and only if ml
is a positive or negative integer:
ml = 0, ±1, ±2, ±3, . . .
This is obviously more restrictive than the general condition on angular
momentum quantum numbers, for which m could be an integer or a half￾integer. Since ml ranges from −l to +l in integer steps, the only way to
insure that ml
is an integer is for l to be an integer as well:
l = 0, 1, 2, . . .
This, then, is a distinguishing property of orbital angular momentum: while
the eigenvalues of L
2 are ℏ
2
l(l + 1) and the eigenvalues of Lz are ℏml
, just
as in the case of general angular momentum, l must be an integer, which
forces ml to be a positive or negative integer:
ml = −l, −l + 1, . . . , −1, 0, 1, . . . , l
Half-integer values for l and ml are excluded.
Now consider the Schr¨odinger equation in spherical coordinates for some
arbitrary potential V (r, θ, ϕ). The Hamiltonian still has the familiar form
H = −
ℏ
2
2m
∇2 + V (r, θ, ϕ)
but now ∇2 must be expressed in terms of the spherical coordinates r, θ,
and ϕ. This transformation is tedious but straightforward; it yields
H = −
ℏ
2
2m

1
r
2 sin θ
∂
∂θ sin θ
∂
∂θ +
1
r
2
∂
∂r r
2 ∂
∂r +
1
r
2 sin2
θ
∂
2
∂ϕ2

+ V (r, θ, ϕ)
But now compare the first and third terms in this expression with the
expression for L
2
in spherical coordinates (Equation (6.31)). It is clear
that H can be rewritten in the form
H = −
ℏ
2
2m
1
r
2
∂
∂r r
2 ∂
∂r +
L
2
2mr2
+ V (r, θ, ϕ) (6.33)Solutions of the three-dimensional time-independent Schr¨odinger equation 145
F
Fig. 6.4 The potential V (r) corresponds to a classical central force. The direction of
the force is always radial (toward or away from the origin), and it produces no torque.
Note the similarity between this expression and the classical expression for
the energy of a body moving in a central potential V (r):
E =
1
2
m

dr
dt 2
+
l
2
2mr2
+ V (r)
In the classical central force problem, the term l
2/2mr2
leads to a fictitious
“centrifugal force”, producing a minimum in the effective potential for some
choices of V (r).
Now we would like to find solutions of the Schr¨odinger equation which
are also eigenfunctions of L
2 and Lz, i.e., they are states of definite total
angular momentum and of the z component of angular momentum. In
order for this to be possible, the Hamiltonian in Equation (6.33) must
commute with L
2 and Lz. Since L
2 and Lz are functions only of θ, ϕ,
and the derivatives with respect to θ and ϕ, they commute with the first
term in Equation (6.33), which is a function only of r and derivatives with
respect to r. Further, L
2 and Lz commute with the second term, since they
commute with both L
2 and 1/r2
. Thus, the question of whether or not L
2
and Lz commute with H boils down to whether or not they commute with
V (r, θ, ϕ). A very simple way to insure that L
2 and Lz do, in fact, commute
with V is to take V to be a function only of r and to be independent of θ
and ϕ, since, as we have noted, L and Lz are functions only of θ, ϕ, and
the derivatives with respect to θ and ϕ. Classically, a potential of the form
V (r) corresponds to a central force, i.e., one that is directed radially inward
or radially outward (Figure 6.4). Such a force produces no torque, so that
angular momentum is conserved. We will assume for the remainder of this
chapter that we are dealing with a potential of the form V = V (r). This
will be the case, for example, for an electron in a hydrogen atom.146 Quantum Mechanics: An Accessible Introduction
The full Schr¨odinger equation, Hψ = Eψ, then becomes
−
ℏ
2
2m
1
r
2
∂
∂r r
2 ∂ψ
∂r +
L
2
2mr2
ψ + V (r)ψ = Eψ
Now assume that ψ is a eigenfunction of L
2 with eigenvalue ℏ
2
l(l + 1), so
that this equation becomes
−
ℏ
2
2mr
∂
∂r2
(rψ) + ℏ
2
l(l + 1)
2mr2
ψ + V (r)ψ = Eψ (6.34)
where we have also used the fact that
1
r
∂
∂r2
(rψ) = 2
r
∂ψ
∂r +
∂
2ψ
∂r2
=
1
r
2
∂
∂r r
2 ∂ψ
∂r
To solve this equation, we once again use separation of variables, assuming
a solution of the form
ψ(r, θ, ϕ) = R(r)Y (θ, ϕ)
Substituting this solution into Equation (6.34) gives
−
ℏ
2
2mr
∂
∂r2
(rR(r))Y (θ, ϕ) + ℏ
2
l(l + 1)
2mr2
R(r)Y (θ, ϕ) + V (r)R(r)Y (θ, ϕ)
= ER(r)Y (θ, ϕ)
The function Y (θ, ϕ) can be divided out, yielding an equation for R(r):
−
ℏ
2
2mr
∂
∂r2
(rR(r)) + ℏ
2
l(l + 1)
2mr2
R(r) + V (r)R(r) = ER(r) (6.35)
Equation (6.35) is called the radial Schr¨odinger equation. It gives the en￾ergy and the radial part of the wave function R(r) for an arbitrary central
potential V (r). Of course, both the energy and R(r) will depend on the
particular form of V (r). Note also that the solutions for R(r) and E will,
in general, depend on l, but they are completely independent of ml
, since
ml does not appear in Equation (6.35). The physical reason for this is
that for a fixed l, a change in the eigenvalue of Lz can be produced simply
by rotating the coordinate axes, and the energy of the system should not
depend on the choice of the coordinate system.
It appears that the function Y (θ, ϕ) has vanished from the problem
completely. In fact, the functional form for Y (θ, ϕ) can be derived from the
eigenvalue equations,
L
2ψ = ℏ
2
l(l + 1)ψ
Lzψ = ℏmlψSolutions of the three-dimensional time-independent Schr¨odinger equation 147
Substituting the explicit forms for L
2 and Lz from Equations (6.31) and
(6.30) gives
−ℏ
2

1
sin θ
∂
∂θ 
sin θ
∂
∂θ 
+
1
sin2
θ
∂
∂ϕ2

R(r)Y (θ, ϕ) = ℏ
2
l(l + 1)R(r)Y (θ, ϕ)
−iℏ
∂
∂ϕR(r)Y (θ, ϕ) = ℏmlR(r)Y (θ, ϕ)
Dividing out the factor R(r) gives two equations for Y (θ, ϕ):
−ℏ
2

1
sin θ
∂
∂θ 
sin θ
∂
∂θ 
+
1
sin2
θ
∂
∂ϕ2

Y (θ, ϕ) = ℏ
2
l(l + 1)Y (θ, ϕ) (6.36)
−iℏ
∂
∂ϕY (θ, ϕ) = ℏmlY (θ, ϕ) (6.37)
An important point here is that Y (θ, ϕ) is determined entirely by the
eigenvalues l and ml and is completely independent of V (r). Therefore, it
is customary to write these functions as Y
m
l
(θ, ϕ). (For clarity, we write
Y
m
l
rather than Y
ml
l
; it is understood that the m appearing in Y
m
l
al￾ways refers to orbital angular momentum.) These functions, which we will
now calculate, provide a universal description of the angular part of the
wave function for all central potentials. Once again we assume separation
of variables, so that Y
m
l
(θ, ϕ) = F(θ)G(ϕ), and substitute this form for
Y
m
l
into Equations (6.36) and (6.37). Note that we have already solved
Equation (6.37) above with the result that
G(ϕ) = e
imlϕ
Now we need to determine the θ-dependence of Y
m
l
(θ, ϕ). Recall that the
largest possible value of ml for a given l is ml = l. Thus, if an expression for
Y
l
l
(θ, ϕ) is known, it is possible to derive all of the other values of Y
m
l
(θ, ϕ)
by repeated application of the lowering operator L−. In terms of spherical
coordinates, the raising and lowering operators are given by
L+ = ℏe
iϕ 
∂
∂θ + i cot θ
∂
∂ϕ
(6.38)
L− = ℏe
−iϕ 
−
∂
∂θ + i cot θ
∂
∂ϕ
(6.39)
In order to derive Y
l
l
(θ, ϕ), recall that the raising operator applied to the
highest-ml state gives 0:
L+Y
l
l
(θ, ϕ) = 0148 Quantum Mechanics: An Accessible Introduction
Table 6.1 The first few normalized spherical har￾monics, Y m
l
(θ, ϕ).
l ml Y m
l
(θ, ϕ)
0 0 Y m
l =

1
4π
1/2
1 −1 Y m
l =

3
8π
1/2
sin θe−iϕ
1 0 Y m
l =

3
4π
1/2
cos θ
1 +1 Y m
l = −

3
8π
1/2
sin θeiϕ
2 −2 Y m
l =

15
32π
1/2
sin2
θe−2iϕ
2 −1 Y m
l =

15
8π
1/2
sin θ cos θe−iϕ
2 0 Y m
l =

5
16π
1/2
(3 cos2
θ − 1)
2 +1 Y m
l = −

15
8π
1/2
sin θ cos θeiϕ
2 +2 Y m
l =

15
32π
1/2
sin2
θe2iϕ
In terms of L+ in spherical coordinates (Equation (6.38)), this equation
becomes
ℏe
iϕ 
∂Y l
l
∂θ + i cot θ
∂Y l
l
∂ϕ 
= 0
which has the solution
Y
l
l
(θ, ϕ) = (sin θ)
l
e
ilϕ
Now, by repeatedly applying the operator L− from Equation (6.39), one
can obtain all of the other functions Y
m
l
(θ, ϕ).
These Y
m
l
functions arise in a variety of different areas of physics; it
is difficult to overemphasize their importance. They are called spherical
harmonics, or more colloquially, “Y”-“l”-“m”’s. A list of the functions
Y
m
l
(θ, ϕ) for the first few values of l is given in Table 6.1.Solutions of the three-dimensional time-independent Schr¨odinger equation 149
The constants appearing in the Y
m
l
functions in Table 6.1 are chosen so
as to normalize these functions, i.e.,
Z π
θ=0
Z 2π
ϕ=0
|Y
m
l
(θ, ϕ)|
2
sin θ dθ dϕ = 1
This still leaves an arbitrary complex phase factor; the convention is to
choose this phase so that Y
−m
l
(θ, 0) = (−1)mY
m
l
(θ, 0). This accounts for
the minus signs appearing in some of the Y
m
l
functions in Table 6.1.
As derived earlier, all of the spherical harmonics in Table 6.1 are of the
form Y
m
l
(θ, ϕ) = f(θ)e
imϕ. This implies that Y
0
l
is a function only of θ and
is independent of ϕ. These m = 0 functions, Y
0
l
(θ), are also encountered
in the theory of electromagnetic fields, where they arise as the solution of
Laplace’s equation, which gives the electric potential in a vacuum. In this
context they are written in terms of Legendre polynomials Pl(cos θ), where
Pl(cos θ) ∝ Y
0
l
(θ). Note further that the l = 0, m = 0 spherical harmonic
is spherically symmetric, i.e., completely independent of both θ and ϕ, and
it is the only spherical harmonic with this property.
The spherical harmonics are difficult to visualize, since they are com￾plex functions of spherical angular coordinates. However, note that |Y
m
l
|
2
,
which gives the angular dependence of the probability density, is real and
is independent of ϕ (since |e
imϕ|
2 = 1). In Figure 6.5, we show |Y
m
l
|
2 as a
function of θ for l = 0, 1, 2. These are polar graphs in which θ is the angle
relative to the z-axis, and |Y
m
l
|
2
is plotted as the radial distance from the
origin.
We have now achieved a remarkably general result for central potentials.
For any wave function that represents an eigenstate of L
2 and Lz in a central
potential V (r), with angular momentum quantum numbers l and ml
, the
angular part of the wave function will be given by the appropriate Y
m
l
(θ, ϕ),
completely independent of both V (r) and the energy E. The potential does
determine E and the radial part of the wave function R(r), so these will
depend on the particular choice of V (r).
6.4 The Hydrogen Atom
We are now in a position to determine the wave functions and energy levels
of the electron in the hydrogen atom, one of the most important results in all
of quantum mechanics. Before inserting the Coulomb potential experienced
by the electron, we first simplify the general form for the radial Schr¨odinger
equation (Equation (6.35)). Multiplying both sides of Equation (6.35) by150 Quantum Mechanics: An Accessible Introduction
u
Yl
m

2
l = 0, m = 0
l = 2, m = 0
l = 2, m = ±1
l = 2, m = ±2
l = 1, m = ±1
l = 1, m = 0
z
Fig. 6.5 Polar graphs showing |Y m
l
|
2 as a function of θ for the indicated values of l
and m.
r gives
−
ℏ
2
2m
∂
∂r2
(rR(r)) + ℏ
2
l(l + 1)
2mr2
rR(r) + V (r)rR(r) = ErR(r) (6.40)Solutions of the three-dimensional time-independent Schr¨odinger equation 151
This form of the equation suggests the substitution u(r) = rR(r), simpli￾fying the equation to the form
−
ℏ
2
2m
∂
∂r2
u(r) + ℏ
2
l(l + 1)
2mr2
u(r) + V (r)u(r) = Eu(r)
Note again that both the wave function and the energies should depend on
the particular value of l, since it appears in this equation. Two boundary
conditions can be imposed on the wave function; as usual, as r → ∞,
we require u → 0. However, an additional boundary condition must be
imposed at the origin; since ψ ∝ u/r, we must have u → 0 as r → 0 in
order to keep ψ finite.
Now consider the actual hydrogen atom. It consists of an electron with
mass
me = 9.109 × 10−31 kg
orbiting a proton with mass
mp = 1.672 × 10−27 kg
In a classical system of this sort, it would be inaccurate to take the electron
to orbit a fixed proton; rather, the electron and proton orbit their common
center of mass. Consider, more generally, a classical system consisting of
a particle with mass m1 at position r1, and a particle with mass m2 at
position r2, so the vector separation between the particles is
r = r1 − r2 (6.41)
Assume that the potential energy V is a function only of the distance
between the particles r, where r = |r|. The energy of this system is
E =
1
2
m1

dr1
dt 2
+
1
2
m2

dr2
dt 2
+ V (r) (6.42)
We are free to choose any origin for the coordinate system, so we take it to
lie at the center of mass of the particles, which gives
m1r1 + m2r2 = 0
This equation and Equation (6.41) allow us to express r1 and r2 as functions
of r:
r1 =
m2
m1 + m2
r
r2 = −
m1
m1 + m2
r152 Quantum Mechanics: An Accessible Introduction
Substituting these expressions for r1 and r2 in Equation (6.42) gives an
expression for E as a function only of the separation between the particles:
E =
1
2
µ

dr
dt 2
+ V (r)
where µ is given by
µ =
m1m2
m1 + m2
The quantity µ is called the reduced mass.
The quantum analog to this result is achieved by replacing m in the
Hamiltonian with µ, so that
H = −
ℏ
2
2µ
∇2 + V
where, for the hydrogen atom, µ is given by
µ =
memp
me + mp
(6.43)
Note that me ≪ mp, so that µ for the hydrogen atom will be very close to
me. Plugging the actual numbers into Equation (6.43) gives
µ = 0.9995me (6.44)
Hence, using µ instead of me produces only a small correction in the case
of the hydrogen atom. However, we will include this correction in our
calculations.
The Coulomb potential experienced by the electron in the electric field
of the proton is
V (r) = −
1
4πϵ0
e
2
r
so the radial Schr¨odinger equation becomes
−
ℏ
2
2µ
∂
2u
∂r2
+
ℏ
2
l(l + 1)
2µr2
u −
1
4πϵ0
e
2
r
u = Eu (6.45)
We will now solve this equation. Note that the potential is always negative,
approaching zero as r → ∞. Therefore, a bound state (which are the
states we are interested in) must have E < 0 (Figure 6.6). To simplify the
notation, we take ε = −E, and rewrite Equation (6.45) as
d
2u
dr2
+
2µe2
4πϵ0ℏ
2
u
r
−
l(l + 1)u
r
2
=
2µ
ℏ
2
εu (6.46)Solutions of the three-dimensional time-independent Schr¨odinger equation 153
V(r)
E
r
Energy
Fig. 6.6 The potential experienced by the electron in a hydrogen atom satisfies V (r) <
0. Hence, any bound state must have E < 0.
where ε > 0. To solve this equation, first consider its asymptotic behavior
in the limit as r → ∞. In this limit the second and third terms on the
left-hand side go to zero, and we are left with
d
2u
dr2
=
2µ
ℏ
2
εu
which has the solution
u = e
−(
√
2µε/ℏ)r
(6.47)
Of course, this is not the exact solution to the full Equation (6.46), but it
suggests that we investigate solutions of the form
u(r) = v(r)e
−(
√
2µε/ℏ)r
(6.48)
where v(r) is now the unknown function to be determined. Substituting
this trial solution into Equation (6.46) gives an equation for v(r):
d
2v
dr2
−
2
√
2µε
ℏ
dv
dr +
2µe2
4πϵ0ℏ
2
v
r
−
l(l + 1)v
r
2
= 0 (6.49)
To solve for v(r), we now try a series solution of the form
v(r) = X∞
p=1
Apr
p
(6.50)
(Note that the constant term, A0, must be zero because of our previously￾derived boundary condition that u(0) = 0.) Substituting this power-series
expansion into Equation (6.49) gives an equation in powers of r on the
left-hand side, and in order for this to be equal to zero, the coefficient154 Quantum Mechanics: An Accessible Introduction
multiplying each power of r must vanish. Enforcing this condition gives
the following relation between the Ap coefficients:
[p(p + 1) − l(l + 1)]Ap+1 =

2p
√
2µε
ℏ
−
2µe2
ℏ
24πϵ0

Ap (6.51)
Because l is the angular momentum quantum number, it has some fixed
integer value for any particular solution. Note that for p = l, the left-hand
side of the equation vanishes, so that Ap on the right-hand side must be
zero. But taking Ap = 0 on the left-hand side of Equation (6.51) gives
Ap−1 = 0 on the right-hand side. This argument can be repeated to give
Ap−2 = 0, Ap−3 = 0, and so on all of the way down. Thus, the only nonzero
coefficients have p > l, namely, Al+1, Al+2, . . . . There is, however, one
additional constraint on the polynomial series in Equation (6.50). In order
for u(r) to have the correct asymptotic behavior shown in Equation (6.47),
we do not want the v(r) factor in Equation (6.48) to give the dominant
behavior at large r. This can be achieved by requiring the polynomial to
have a finite number of terms. (A finite polynomial is always dominated by
an exponential at large r; this need not be true for a polynomial with an
infinite number of terms.) In order for the polynomial to terminate after a
finite number of terms, the right-hand side of Equation (6.51) must vanish
for some value of p, which we will call n. Note that n must be greater than
l, since only terms with p ≥ l + 1 are nonzero. In order for the term on the
right-hand side to vanish at p = n, we must have
2n
√
2µε
ℏ
−
2µe2
ℏ
24πϵ0
= 0
Solving for E = −ε gives
E = −
µe4
(4πϵ0)
22ℏ
2
1
n2
= −13.6 eV 1
n2
(6.52)
This is exactly the same result derived earlier for the Bohr model of the
atom (Chapter 1)! This equation also gives the physical meaning of the pa￾rameter n introduced above: it determines the energy levels of the hydrogen
atom. Furthermore, we have derived a constraint on l: since n > l,
l ≤ n − 1
Now, however, we can move beyond the Bohr model to derive the wave
functions as well. The radial wave function is
R(r) = u(r)
r
=
v(r)
r
e
−(
√
2mε/ℏ)rSolutions of the three-dimensional time-independent Schr¨odinger equation 155
where v(r) is a polynomial in powers of r ranging from r
l+1 up to r
n. Since
R depends on n and l, we write it as Rnl(r). Solving for the power-series
coefficients using Equation (6.51) gives explicit expressions for Rnl(r). To
simplify these expressions, we introduce a physical quantity a0 with units
of length, given by
a0 =
4πϵ0ℏ
2
µe2
= 5.3 × 10−11 m
This length a0 is called the Bohr radius. Then the first few normalized
radial wave functions are
R10 =

1
a0
3/2
2e
−r/a0
R20 =

1
2a0
3/2
2

1 −
1
2
r
a0

e
−r/2a0
R21 =

1
2a0
3/2
1
√
3

r
a0

e
−r/2a0
Each radial wave function can be combined with the corresponding Y
m
l
to
obtain the full wave function. Since Rnl(r) is a function of n and l, and
Y
m
l
(θ, ϕ) is a function of l and ml
, the full wave function will be determined
by three quantum numbers: n, l, and ml
:
ψnlml
(r, θ, ϕ) = Rnl(r)Y
m
l
(θ, ϕ)
Each of these quantum numbers has a physical significance: n, called the
principal quantum number, determines the energy of the electron, l deter￾mines the total squared angular momentum, and ml gives the z component
of the angular momentum. We have also derived the allowed values for all
of these quantum numbers:
n = 1, 2, 3, . . .
l ≤ n − 1
ml = −l, −l + 1, . . . , 0, . . . , l − 1, l
The normalized wave functions for n = 1, 2, 3 are given in Table 6.2.
Note that the energy En is entirely determined by n and is independent
of l, despite the fact that the radial Schr¨odinger equation (Equation (6.35)),
which determines the energy levels, contains l. This is an “accidental”
degeneracy, in the sense that it occurs only for the Coulomb potential
(V (r) ∝ 1/r). For the case of a general radial potential, E will depend
on l.156 Quantum Mechanics: An Accessible Introduction
Table 6.2 The normalized hydrogen wave functions for n = 1, 2, 3.
n l ml ψnlml
(r, θ, ϕ)
1 0 0 ψ100 =
1
√
π

1
a0
3/2
e
−r/a0
2 0 0 ψ200 =
1
4
√
2π

1
a0
3/2 
2 −
r
a0

e
−r/2a0
2 1 0 ψ210 =
1
4
√
2π

1
a0
3/2 
r
a0

e
−r/2a0 cos θ
2 1 ±1 ψ21±1 =
1
8
√
π

1
a0
3/2 
r
a0

e
−r/2a0 sin θe±iϕ
3 0 0 ψ300 =
1
81√
3π

1
a0
3/2 
27 − 18
r
a0
+ 2
r
2
a
2
0

e
−r/3a0
3 1 0 ψ310 =
√
2
81√
π

1
a0
3/2 
6 −
r
a0
  r
a0

e
−r/3a0 cos θ
3 1 ±1 ψ31±1 =
1
81√
π

1
a0
3/2 
6 −
r
a0
  r
a0

e
−r/3a0 sin θe±iϕ
3 2 0 ψ320 =
1
81√
6π

1
a0
3/2 
r
2
a
2
0

e
−r/3a0 (3 cos2
θ − 1)
3 2 ±1 ψ32±1 =
1
81√
π

1
a0
3/2 
r
2
a
2
0

e
−r/3a0 sin θ cos θe±iϕ
3 2 ±2 ψ32±2 =
1
162√
π

1
a0
3/2 
r
2
a
2
0

e
−r/3a0 sin2
θe±2iϕ
The total number of states with a given energy En is straightforward to
compute. A given value of n corresponds to n − 1 possible states for l, and
each l state has 2l + 1 possible values for ml
. Thus, the total degeneracy
for energy En is 1 + 3 + 5 + · · · + 2n − 1 = n
2
. We will see in Chapter 8
that each electron also has two possible spin states corresponding to two
possible values of the z component of the spin angular momentum, so the
true degeneracy for a given n is actually 2n
2
.
Although this model for the hydrogen atom agrees with the Bohr model
as far as the predictions of the energy levels are concerned, it presents a
very different physical picture of the behavior of the electrons. In the Bohr
model, electrons lie in distinct “orbits” around the proton, with the length
of each orbit fixed by the need for it to comprise an integer number ofSolutions of the three-dimensional time-independent Schr¨odinger equation 157
2 4 6 8 10 12 14
0.1
0.2
0.3
0.4
0.5
0.6
n = 1
l = 0
n = 2
l = 1
n = 2
l = 0
r/a0
Pnl(r)
Fig. 6.7 The radial probability density, Pnl(r), as a function of r for the n = 1 and
n = 2 states of the hydrogen atom.
de Broglie wavelengths. In the picture we have just derived (which is the
best current picture of the atom), the behavior of the electrons is defined
entirely by the wave functions. The idea of an electron “orbiting” the
central proton is essentially abandoned. The electron does not follow a
well-defined trajectory; instead, one can only talk about the probability of
finding the electron inside a given volume V , which is given by
P =
Z
V
|ψnlml
(r, θ, ϕ)|
2
r
2
dr sin θ dθ dϕ
We can also define radial probability densities, Pnl(r), by integrating the
full probability density over θ and ϕ but retaining the r-dependence:
Pnl(r) dr =
Z π
θ=0
Z 2π
ϕ=0
|ψnlml
(r, θ, ϕ)|
2
r
2
dr sin θ dθ dϕ
Then Pnl(r) dr gives the probability of finding the electron in a small inter￾val dr at a radius r from the proton. A graph of Pnl(r) as a function of r
is given in Figure 6.7. Clearly, the larger n states, corresponding to larger
energies, have larger mean radii for the electron. Although it is meaningless
to talk about a single fixed “radius” of the atom in this picture, the proba￾bility of finding the electron at a given r is largest where Pnl(r) is peaked.158 Quantum Mechanics: An Accessible Introduction
It is also common to use ⟨r⟩ as a reasonable definition of the atomic radius
for any given n, l state.
For instance, for the ground state of hydrogen, ⟨r⟩ is given by
⟨r⟩ =
Z ∞
r=0
Z π
θ=0
Z 2π
ϕ=0
r
2
dr sin θ dθ dϕ|ψ100|
2
r
with the ground state wave function
ψ100 =
1
√
π

1
a0
3/2
e
−r/a0
This wave function is independent of θ and ϕ, so
Z π
θ=0
Z 2π
ϕ=0
sin θ dθ dϕ = 4π
and
⟨r⟩ =
Z ∞
r=0
4πr2
dr 1
π

1
a0
3
e
−2r/a0 r
=
4
a
3
0
Z ∞
r=0
e
−2r/a0 r
3
dr
=
4
a
3
0
6
(2/a0)
4
=
3
2
a0
Thus, ⟨r⟩ = 3a0/2 = 8 × 10−11 m. For this reason, the “radius of the
hydrogen atom” is often taken to be about 10−10 m.
This picture of the hydrogen atom has explanatory power far beyond
what is possible with the Bohr model. In particular, a more detailed anal￾ysis of the hydrogen spectrum reveals that the energy levels are not exactly
given by Equation (6.52), but are slightly perturbed from the predicted
values. It is possible to explain these perturbations within the context of
the model we have just derived; this will be done in Chapter 9.
PROBLEMS
6.1 A particle with mass m is confined inside of a rectangular box
given by 0 ≤ x ≤ a, 0 ≤ y ≤ b, and 0 ≤ z ≤ c. The solution to the
Schr¨odinger equation is
ψ(x, y, z) = A sin nxπx
a

sin nyπy
b

sin nzπz
c
Solutions of the three-dimensional time-independent Schr¨odinger equation 159
where A is a constant. The energy levels are given by
E = (ℏ
2π
2/2m)(n
2
x/a2 + n
2
y/b2 + n
2
z/c2
).
(a) Normalize the wave functions. You should obtain A =
p
8/V ,
where V = abc is the volume of the box.
(b) Suppose the particle is in the ground state. Calculate the prob￾ability of finding the particle in the lower fourth of the box, i.e., in
the region z ≤ c/4.
6.2 A particle with mass m is confined inside a cubic box with edges
of length a. Show that there are six different wave functions that
have E = 14(ℏ
2π
2/2ma2
). (This is called sixfold degeneracy.)
6.3 (a) A particle with mass m is confined inside a rectangular box
with sides of length a, a, and 2a. What is the energy of the first
excited state? Is this state degenerate? If so, determine how many
different wave functions have this energy.
(b) Now assume the rectangular box has sides of length a, 2a, and
2a. What is the energy of the first excited state? Is this state
degenerate? If so, determine how many different wave functions
have this energy.
6.4 (a) A particle with mass m and energy E is inside a square tube
with infinite potential barriers at x = 0, x = a, y = 0, and y = a.
The tube is infinitely long in the z direction. Inside the tube,
V = 0. The particle is moving in the +z direction. Solve the
Schr¨odinger equation to derive the allowed wave functions for this
particle. Do not try to normalize the wave functions, but make
sure they correspond to motion in the +z direction.
(b) Energy should not be quantized in this case because the particle
is not in a bound state. Use the answer from part (a) to show that
this is indeed the case.
6.5 Show that Lx and Ly are Hermitian.
6.6 Verify that [X, Y ] = 0 and [Px, Py] = 0.
6.7 Calculate these commutators:
[Lz, Px], [Lz, X]
[Lz, Py], [Lz, Y ]
[Lz, Pz], [Lz, Z]160 Quantum Mechanics: An Accessible Introduction
6.8 Show that ℏ has units of angular momentum.
6.9 The operator Q obeys the commutation relation [Q, H] = E0Q,
where E0 is a constant with units of energy. Show that if ψ(x)
is a solution of the time-independent Schr¨odinger equation with
energy E, then Qψ(x) is also a solution of the time-independent
Schr¨odinger equation, and determine the energy corresponding to
Qψ(x).
6.10 A particle is confined in a cubic box with edge of length a, with
V = 0 inside the box. The particle is in its ground state; determine
whether or not the particle is in an eigenstate of Lz.
6.11 Consider a three-dimensional system with wave function ψ. If ψ is
in the l = 0 state, we already know that Lzψ = 0. Show that Lxψ =
0 and Lyψ = 0 as well. (Note this is the only exception to the rule
that a wave function cannot be simultaneously an eigenfunction of
Lx, Ly, and Lz.)
6.12 A particle is in an eigenstate of L
2 and Lz, with quantum numbers
l and ml
. By symmetry, we must have ⟨L
2
x
⟩ = ⟨L
2
y
⟩. Show that
ℏ
2
l/2 ≤ ⟨L
2
x
⟩ ≤ ℏ
2
l(l + 1)/2.
6.13 The “radius of the hydrogen atom” is often taken to be on the
order of about 10−10 m. If a measurement is made to determine
the location of the electron for hydrogen in its ground state, what
is the probability of finding the electron within 10−10 m of the
nucleus?
6.14 (a) The electron in a hydrogen atom is in the l = 1 state having
the lowest possible energy and the highest possible value for ml
.
What are the n, l, and ml quantum numbers?
(b) A particle is moving in an unknown central potential. The
wave function of the particle is spherically symmetric. What are
the values of l and ml?
6.15 The deuteron is a nucleus of “heavy hydrogen” consisting of one
proton and one neutron. As a simple model for this nucleus, con￾sider a single particle of mass m moving in a fixed spherically￾symmetric potential V (r), defined by V (r) = −V0 for r < r0 andSolutions of the three-dimensional time-independent Schr¨odinger equation 161
V (r) = 0 for r > r0. This is called a spherical square-well potential.
Assume that the particle is in a bound state with l = 0.
(a) Find the general solutions R(r) to the radial Schr¨odinger equa￾tion for r < r0 and r > r0. Use the fact that the wave function must
be finite at 0 and ∞ to simplify the solution as much as possible.
(You do not have to normalize the solutions.)
(b) The deuteron is only just bound; i.e., E is nearly equal to 0.
Take m to be the proton mass, m = 1.67 × 10−27 kg, and take
r0 to be a typical nuclear radius, r0 = 1 × 10−15 m. Find the
value of V0 (the depth of the potential well) in MeV (1 MeV =
1.6 × 10−13 J). (Hint: The continuity conditions at r0 must be
used. The radial wave function R(r) and its derivative R′
(r) must
both be continuous at r0; this is equivalent to requiring that u(r)
and u
′
(r) must both be continuous at r0, where u(r) = rR(r). The
resulting equations cannot be solved exactly but can be used to
derive the value for V0.)
6.16 Determine all potentials V (r, θ, ϕ) for which it is possible to find
solutions of the time-independent Schr¨odinger equation which are
also eigenfunctions of the operator Lz.
6.17 A particle with mass m is confined inside of a spherical cavity
of radius r0. The potential is spherically symmetric and can be
written in the form: V (r) = 0 for r < r0, and V (r) = ∞ for r = r0;
in other words, there is an infinite potential barrier at r = r0. The
particle is in the l = 0 state.
(a) Solve the radial Schr¨odinger equation and use the appropriate
boundary conditions to find the ground state radial wave function
R(r) and the ground state energy. (You do not have to normalize
the solution).
(b) What is the pressure exerted by the particle (in the l = 0
ground state) on the surface of the sphere?
6.18 A particle of mass m is in a three-dimensional, spherically￾symmetric harmonic oscillator potential given by V (r) = (1/2)Kr2
.
The particle is in the l = 0 state. Find the ground-state radial wave
function R(r) and the ground-state energy. (You do not have to
normalize the solution).162 Quantum Mechanics: An Accessible Introduction
6.19 Deuterium is an isotope of hydrogen with a nucleus consisting of
one proton and one neutron. Let λ(D)2→1 be the wavelength of
the photon emitted when the electron in a deuterium atom drops
from the n = 2 state to the n = 1 state, and let λ(H)2→1 be
the corresponding wavelength for ordinary hydrogen. Calculate
λ(D)2→1 − λ(H)2→1.Chapter 7
Math interlude C: Matrices, Dirac
notation, and the Dirac delta function
In Chapter 5, we examined some of the general properties of vector spaces.
We have, so far, treated functions as general vectors in an abstract vec￾tor space, with the inner product represented as an integral over pairs of
the functions, and linear operators transforming one function into another.
Here we examine two other ways of treating vector spaces. In the next
section, we examine finite-dimensional vectors, for which linear operators
are represented by matrices. In the following section, we introduce Dirac
notation, which is simply a general means to represent arbitrary vectors in
an abstract vector space. Finally, we discuss briefly an unrelated topic, but
one which comes up frequently in quantum mechanics as well as in other
areas of physics: the Dirac delta function.
7.1 The Matrix Formulation of Linear Operators
As we have seen in Chapter 5, the set of wave functions ψ(x) can be treated
as an infinite-dimensional vector space with the appropriate definitions for
linear operators and inner products. However, we will often be interested
in finite-dimensional vector spaces. These vector spaces occur, for instance,
in the study of angular momentum. For example, suppose that a particle
has total angular momentum j = 1/2, so that the possible mj states are
−1/2 and +1/2. We can represent these two states as column vectors; for
instance, 
1
0

can represent the mj = +1/2 state, and 
0
1

can represent
the mj = −1/2 state. In general, we will use column vectors of the form


x1
x2
x3

 to represent general finite-dimensional vectors; the dimension of the
vector space is then just the number of entries in the column.
163164 Quantum Mechanics: An Accessible Introduction
( )
C
x
A
=
B
( )( )
Fig. 7.1 If C = AB, then to obtain a given element in matrix C, scan across the
corresponding row of matrix A and the corresponding column of matrix B, multiply
each pair of numbers and add the result.
How is a linear operator represented using this formulation? If we are
dealing with an n-dimensional vector space, so that the vectors are column
vectors with n entries, then a general linear operator is an n × n matrix,
and the act of operating on the vector is simply given by multiplying the
matrix by the column vector.
Recall how matrix multiplication works. Suppose that A is an l × m
matrix, and B is an m × n matrix. Then the elements of the product,
C = AB, are given by
Cjk =
Xm
i=1
AjiBik (7.1)
where Aji, for example, is the element in the jth row and the ith column
of A. Thus, multiplication of an l × m matrix by an m × n matrix yields
an l × n matrix, and such multiplication is possible only if the number of
columns in A is equal to the number of rows in B.
More graphically, we can think of a single element in matrix C being
generated by scanning across the corresponding row of matrix A and the
corresponding column of matrix B, multiplying each pair of numbers and
adding the result (Figure 7.1).
Example 7.1. Matrix Multiplication Is not Commutative
Consider the two matrices A =

1 2
3 4
and B =

5 6
7 8
. The rules for
matrix multiplication give
AB =

1 2
3 4 5 6
7 8
=

19 22
43 50
while
BA =

5 6
7 8 1 2
3 4
=

23 34
31 46
Clearly AB ̸= BA in this case.Math interlude C: Matrices, Dirac notation, and the Dirac delta function 165
A column vector with n entries can be treated as an n×1 matrix. Hence,
multiplying an n×n matrix by an n×1 column vector yields another n×1
column vector. Thus, for a vector space consisting of n-dimensional column
vectors, the operators are n × n matrices:


A11 A12 A13
A21 A22 A23
A31 A32 A33




x1
x2
x3

 =


y1
y2
y3


The multiplication of two operators represented by the matrices A and B
corresponds to multiplication of the two matrices. Since matrix multiplica￾tion is not commutative (Example 7.1), it will general not be true that any
two operators will commute, as we have already noted for many quantum
mechanical operators.
We can also find the eigenvalues and eigenvectors of an operator rep￾resented as a matrix. Suppose we have a matrix A multiplying a column
vector x, and assume that one of the eigenvalues is c. Then the eigenvalue
equation is
Ax = cx (7.2)
Because we are dealing with matrices, this can be written as
Ax = cIx (7.3)
where I is the identity matrix with 1’s along the main diagonal and 0’s
everywhere else. The identity matrix has the property that Ix = x for any
column vector x. For example, in three dimensions,


1 0 0
0 1 0
0 0 1




x1
x2
x3

 =


x1
x2
x3


Then Equation (7.3) can be rewritten as
(A − cI)x = 0 (7.4)
In three dimensions, for example, Equation (7.4) corresponds to


A11 − c A12 A13
A21 A22 − c A23
A31 A32 A33 − c




x1
x2
x3

 =


0
0
0

166 Quantum Mechanics: An Accessible Introduction
A matrix equation of this form always has a trivial solution of the form


x1
x2
x3

 =


0
0
0


i.e., a vector for which all of the entries are zero. This is not a very inter￾esting solution. In order for Equation (7.4) to have a nonzero solution, the
determinant of A − cI must be zero. For example, in three dimensions, the
condition for a nonzero solution is






A11 − c A12 A13
A21 A22 − c A23
A31 A32 A33 − c






= 0
An n × n determinant of this kind, in which each term on the main
diagonal is of the form Aii − c, corresponds to a polynomial of degree
n in the variable c. Thus, there will always be n complex values of c for
which the determinant is zero, corresponding to n complex eigenvalues (not
necessarily all distinct). The first step is to find these eigenvalues; they can
then each be inserted, in turn, into Equation (7.2) to find the corresponding
eigenvectors. Note from Equation (7.2) that an eigenvector multiplied by
an arbitrary constant will remain an eigenvector with the same eigenvalue,
a result that is already familiar from our earlier work with eigenvectors.
Example 7.2. The Eigenvalues and Eigenvectors of the Matrix
A =

0 1
1 0
Assume an eigenvalue c. Then the determinant equation is




−c 1
1 −c




= 0
Expanding out the determinant gives
c
2 − 1 = 0
so
c = ±1
Thus, the eigenvalues are c = −1 and c = 1. These can now be inserted
into the eigenvalue equation. First, for c = 1,

0 1
1 0 x1
x2

= 1 
x1
x2
Math interlude C: Matrices, Dirac notation, and the Dirac delta function 167
which yields the two equations:
x2 = x1
x1 = x2
Note that these two equations are not independent. This will always be
the case, since there must always be one extra degree of freedom, which
allows multiplication of the final solution by an arbitrary constant. If a
set of completely independent equations has been obtained (so that every
component of the vector x can be calculated exactly), then the eigenvalues
have been calculated incorrectly. Now we fix x1 to any value, and x2 will
be determined. So, for example, we can choose x1 = 1, which gives x2 = 1,
yielding the eigenvector 
1
1

, with eigenvalue c = 1.
Now consider c = −1. For this case, we get

0 1
1 0 x1
x2

= −1

x1
x2

so
x2 = −x1
x1 = −x2
Again, these are not independent equations. We can take, for example,
x1 = 1, which gives x2 = −1, yielding the eigenvector 
1
−1

. However, we
could just as easily have taken x1 = −1, giving x2 = 1 and producing the
eigenvector 
−1
1

. It would appear that we have found two different eigen￾vectors. However, this is not the case: 
1
−1

and 
−1
1

are two different
representations of the same vector; they differ by an overall multiplicative
factor of −1.
The inner product of two vectors x and y is given by
(x|y) = ￾
x
∗
1 x
∗
2
· · · x
∗
n



y1
y2
.
.
.
yn


= x
∗
1
y1 + x
∗
2
y2 + · · · + x
∗
n
yn (7.5)
This is identical to the familiar dot product of two vectors, except that all of
the elements of the first vector are complex-conjugated (which will matte168 Quantum Mechanics: An Accessible Introduction
only when they are not real numbers). This definition of the inner product
can be used to normalize any n-dimensional column vector. In order that
x be normalized, we require (x|x) = 1, which corresponds to
￾
x
∗
1 x
∗
2
· · · x
∗
n



x1
x2
.
.
.
xn


= |x1|
2 + |x2|
2 + · · · + |xn|
2 = 1 (7.6)
To normalize x, we multiply x by a constant c so that Equation (7.6) is
satisfied.
Example 7.3. Normalizing the Vector


1
3
2i


We multiply this vector by the constant c, and then require that Equa￾tion (7.6) be satisfied:
c
∗
￾
1 3 −2i

c


1
3
2i

 = 1
Multiplying out the matrices gives
|c|
2
(1 + 9 + 4) = 1
for which we choose the positive real solution, c = 1/
√
14. As in our
previous derivation of normalization constants, there is an arbitrary phase
factor, i.e., c can be multiplied by e
iϕ, where ϕ is any real number, and the
vector will still be normalized. However, it is usually easiest to take c to be
real and positive, which we will do here. Hence, the normalized vector is
x =
1
√
14


1
3
2i


If we insert an operator into the inner product, we end up with the
product of three matrices:
(x|Ay) = ￾
x
∗
1 x
∗
2
· · · x
∗
n



A11 A12 · · ·
A21
.
.
. Ann




y1
y2
.
.
.
yn

Math interlude C: Matrices, Dirac notation, and the Dirac delta function 169
Using these definitions, it is possible to determine the adjoint of a matrix
operator. Recall that the adjoint A† of the operator A has the property
that
(x|Ay) = (A
†x|y) (7.7)
for all x and y. Using Equation (7.5) to write Equation (7.7) in matrix
form, and expanding the matrix products out in terms of their components
as in Equation (7.1), gives
Xn
i,j=1
x
∗
i Aijyj =
Xn
i,j=1
(A
†
ijxj )
∗
yi
Note that matrix elements are just numbers, so they do commute, and we
can rewrite the right-hand side of the equation:
Xn
i,j=1
x
∗
i Aijyj =
Xn
i,j=1
x
∗
jA
†∗
ij yi
=
Xn
j,i=1
x
∗
i A
†∗
ji yj (7.8)
where, in the last line, we have simply interchanged the summation labels
i and j. Equation (7.8) implies that
A
†
ij = A
∗
ji
so that the adjoint of a matrix operator corresponds to the conjugate trans￾pose of the matrix, i.e., the interchange of rows and columns and the
complex-conjugating of all of the entries.
Example 7.4. Determining the Adjoint of a Matrix
Consider the matrix operator
L =

1 i
−3 e
iθ
where θ is a real number. What is the matrix corresponding to the adjoint
operator L
†
?
First transpose the matrix to get 
1 −3
i eiθ
. Then take the complex￾conjugate of all of the entries to obtain the adjoint operator L
†
. This gives
us:
L
† =

1 −3
−i e−iθ170 Quantum Mechanics: An Accessible Introduction
The matrix corresponding to a Hermitian operator must be self-adjoint.
Thus, such a matrix must be equal to its conjugate transpose. For a real
matrix, this means that the matrix is symmetric, e.g., 
1 2
2 7
. But Her￾mitian complex matrices need not be symmetric. For example, the matrix

0 −i
i 0

corresponds to a Hermitian operator.
7.2 Dirac Notation
In Chapter 5 we introduced the properties of an abstract vector space,
as well as operators and inner products acting on that space. We then
made use of a special case in which the elements of the vector space were
functions, and the inner product was simply an integral:
(f|g) = Z
f(x)
∗
g(x) dx
However, as noted in the previous section, another perfectly acceptable
example of a vector space is the set of column vectors for which the inner
product is, instead,
(x|y) = ￾
x
∗
1 x
∗
2
· · · x
∗
n



y1
y2
.
.
.
yn


Often, however, we will want to deal with general vector spaces and general
inner products, without reference to whether we are talking about functions,
column vectors, or some other special class of vectors. In fact, we have
already developed the abstract notation to deal with general vector spaces,
operators, and inner products in Chapter 5. This notation is commonly
used in the world of mathematics. In quantum mechanics, however, most
physicists use a slightly different notation called Dirac notation, which we
now discuss.
In Dirac notation, a general vector is written like this: |ψ⟩. These
vectors satisfy all of the properties of a vector space, as defined in Chapter 5,
e.g., the sum of two vectors is a vector:
|ψ1⟩ + |ψ2⟩ = |ψ3⟩
and the product of a vector and a complex number is a vector:
c|ϕ1⟩ = |ϕ2Math interlude C: Matrices, Dirac notation, and the Dirac delta function 171
To represent the inner product of two vectors, |ψ⟩ and |ϕ⟩, we simply write
⟨ϕ|ψ⟩. Now suppose that the vectors |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ represent an or￾thonormal basis set for our vector space, i.e.,
⟨ψi
|ψj ⟩ = δij
We saw in Chapter 5 that an arbitrary three-dimensional vector r could be
expressed as a sum of orthonormal basis set vectors as
r = (r·xˆ)ˆx + (r·yˆ)ˆy + (r·zˆ)ˆz
The generalization of this to arbitrary vectors in Dirac notation is
|ϕ⟩ = |ψ1⟩⟨ψ1|ϕ⟩ + |ψ2⟩⟨ψ2|ϕ⟩ + · · · + |ψn⟩⟨ψn|ϕ⟩ (7.9)
Note that in this equation, the constants multiplying the basis vectors are
the inner products ⟨ψ1|ϕ⟩, ⟨ψ2|ϕ⟩, . . . ,⟨ψn|ϕ⟩; we have written these con￾stants to the right of the basis vectors themselves, |ψ1⟩, |ψ2⟩, . . . , |ψn⟩. This
is completely equivalent to the notation developed in Chapter 5, where we
used (ϕ|ψ) to represent an inner product. We have not introduced any
new mathematics so far; we have only rewritten the ideas developed in
Chapter 5 in this new notation.
Now we introduce a new property of vector spaces. Suppose we have an
inner product of two Dirac vectors, given by
⟨ϕ|ψ⟩
The right-hand part of this inner product is just the vector |ψ⟩. But suppose
we detach the left-hand side, and write it as the quantity ⟨ϕ|. Does this
have any meaning at all? We can combine ⟨ϕ| with any vector |ψ⟩ to get the
complex number ⟨ϕ|ψ⟩. Thus, the quantity ⟨ϕ| is a function which maps
the vector space into the set of complex numbers. It is clumsier to express
this concept in terms of the inner product notation developed in Chapter 5;
in that notation we would need to write ⟨ϕ| as (ϕ| ), where any vector
could be inserted in the blank space to produce a complex number. It turns
out that this set of all mappings of the vector space into the set of complex
numbers has all of the properties of a vector space itself, so it is given a
special name: the dual space. Given a set of vectors |ψ1⟩, |ψ2⟩, . . . , |ψn⟩,
the dual space consists of ⟨ψ1|, ⟨ψ2|, . . . ,⟨ψn|, with all of the properties
of a vector space, namely, the sum of two elements of the dual space is a
member of the dual space:
⟨ψ1| + ⟨ψ2| = ⟨ψ3|172 Quantum Mechanics: An Accessible Introduction
as is the product of a complex number with a member of the dual space:
c⟨ϕ1| = ⟨ϕ2|
The inner product in Dirac notation ⟨ϕ|ψ⟩ is sometimes called a bracket, so
that ⟨ψ1|, ⟨ψ2|, . . . ,⟨ψn| are called bra vectors, and |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ are
called ket vectors.
With this new idea of dual vectors, Equation (7.9) can be written in a
particularly elegant fashion:
X
n
|ψn⟩⟨ψn| = 1
In Dirac notation, linear operators behave in the standard way, e.g., if
P is a linear operator, we have
P(c|ψ⟩) = cP|ψ⟩
and
P(|ψ1⟩ + |ψ2⟩) = P|ψ1⟩ + P|ψ2⟩
Inner products with an operator inserted are written as ⟨ϕ|P|ψ⟩; this is
equivalent to (ϕ|P ψ) in the notation of Chapter 5. Finally, the dual of the
vector P|ψ⟩ is simply ⟨ψ|P
†
.
It is important to remember that vectors and operators in Dirac no￾tation are completely general; they will sometimes be used to represent
finite-dimensional vector spaces, for which the operators can be repre￾sented as matrices and the vectors as column vectors, but they can also
represent infinite-dimensional vector spaces as well. For example, the time￾independent Schr¨odinger equation is simply
H|ψ⟩ = E|ψ⟩
Sometimes this will represent the familiar Schr¨odinger equation with deriva￾tives of wave functions, but sometimes it will represent matrix quantities,
such as in the next chapter.
7.3 The Dirac Delta Function
In this section we will introduce a function that comes up frequently in
physics and has some rather remarkable properties: the Dirac delta func￾tion. The delta function, δ(x), has the following properties:Math interlude C: Matrices, Dirac notation, and the Dirac delta function 173
x = 0
x
d(x)
Fig. 7.2 The delta function is zero everywhere except at x = 0, where it is infinitely
peaked.
δ(x) = 0, for x ̸= 0 (7.10)
Z ∞
−∞
δ(x) dx = 1 (7.11)
Z ∞
−∞
δ(x)f(x) dx = f(0) (7.12)
Although the range of these integrals has been taken from −∞ to ∞, these
equations are valid as long as the range of integration includes the point
x = 0.
A function which can satisfy these equations must be very strange in￾deed. It is zero everywhere except at x = 0, but in order for it to integrate
to 1 (Equation (7.11)), it must be infinitely sharply peaked at the origin
(Figure 7.2). In fact, from a mathematician’s point of view, the delta func￾tion is not really a function at all, but it can be defined in a rigorous way
as the limit of a set of functions of constant (unit) area, but with an in￾creasingly narrower width (Figure 7.3). The property for which the delta
1
1
x
1
2
2
x
1
4
4
x
Fig. 7.3 The delta function can be treated as the limit of a set of functions with unit
area but decreasing width.174 Quantum Mechanics: An Accessible Introduction
function is primarily used is given by Equation (7.12): the integral of the
product of a delta function with any other function f(x) “picks out” the
value of f(x) at the origin. If we wish to pick out the value of f(x) at some
other value of x, a change of variables gives
Z ∞
−∞
δ(x − a)f(x) = f(a) (7.13)
The Kronecker delta, which we have already encountered, is a discrete ver￾sion of the delta function; the expression corresponding to Equation (7.13)
for the Kronecker delta is
X∞
i=1
δinci = cn
We can also define a three-dimensional delta function, δ
3
(r), given by
δ
3
(r) = δ(x)δ(y)δ(z)
Then the equation corresponding to Equation (7.13) in three dimensions is
Z
δ
3
(r − r0)f(r) d
3
r = f(r0)
where the range of integration must include the point r0. Thus, the integral
over the three-dimensional delta function picks out the value of the function
at a single point in three-dimensional space.
The delta function is useful in representing the kinds of idealized point
distributions that are frequently encountered in physics. For example, con￾sider the charge density, ρ(r), produced by a point charge e at the position
r0. This charge density can be written in terms of a delta function:
ρ(r) = eδ3
(r − r0)
This charge density is infinite at the point r0 and zero everywhere else, but
the total charge Q is well-defined:
Q =
Z
ρ(r) d
3
r =
Z
eδ3
(r − r0) d
3
r = eMath interlude C: Matrices, Dirac notation, and the Dirac delta function 175
PROBLEMS
7.1 The operator Q is given by the matrix:
Q =

1 i
−i −1

(a) Determine the matrix corresponding to Q†
.
(b) Is Q Hermitian?
(c) Find the eigenvalues of Q.
(d) For each eigenvalue in part (c), determine the corresponding
eigenvector.
7.2 The operator A is given by the matrix:
A =


1 0 1
0 0 0
1 0 1


(a) Is A Hermitian?
(b) Find the eigenvalues and corresponding eigenvectors.
(c) What is unusual about the eigenvectors corresponding to the
eigenvalue c = 0?
7.3 Suppose that an n×n matrix A is diagonal so that Aij = 0 for i ̸= j,
but the diagonal elements A11, A22, . . . need not be zero. Assume
A11 ̸= A22 ̸= ...Ann. Find the eigenvalues and eigenvectors of this
matrix.
7.4 The trace of a matrix A, written tr(A), is defined to be the sum of
its diagonal elements:
tr(A) = Xn
i=1
Aii
(a) Show that for any two square matrices, tr(AB) = tr(BA).
(b) Show that for any matrix A, the trace is equal to the sum of
its eigenvalues (where multiple eigenvalues must be included in the
sum multiple times).
7.5 Normalize these vectors: 
1
−1

,


1
i
−1

,


−1
2
−3
4

.176 Quantum Mechanics: An Accessible Introduction
7.6 A particle is in the state |ϕ⟩, and let |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ be an
orthonormal basis for the vector space which contains |ϕ⟩. Q is a
Hermitian operator. Show that
⟨Q
2
⟩ =
Xn
j=1
|⟨ϕ|Q|ψj ⟩|2
7.7 Suppose that |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ is an orthonormal basis set, and
all of the basis vectors are eigenvectors of the operator Q with
Q|ψj ⟩ = qj |ψj ⟩ for all j. A particle is in the state |ϕ⟩. Show that
for this particle, the expectation value of Q is
⟨Q⟩ =
Xn
j=1
qj |⟨ϕ|ψj ⟩|2
7.8 If the operator U has the property that U
†U = I (where I is the
identity operator), then U is called a unitary operator. Show that
if |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ are a set of orthonormal vectors, then U|ψ1⟩,
U|ψ2⟩, . . . , U|ψn⟩ are also a set of orthonormal vectors.
7.9 Suppose that U is a unitary operator, as defined in Exercise 7.8,
and U is represented by a matrix. Show that the columns of U
form a set of orthonormal column vectors.
7.10 A particle is in the state |ϕ⟩. Let |ψ1⟩, |ψ2⟩, . . . , |ψn⟩ be an or￾thonormal basis for the vector space which contains |ϕ⟩, and as￾sume that all of these basis vectors are eigenvectors of H with
H|ψj ⟩ = Ej |ψj ⟩ for all j. Suppose that the operator Q satisfies
⟨Q⟩ =
X
m
Em|⟨ϕ|Z|ψm⟩|2
where Z is just the usual position operator in the z direction. De￾rive an expression for Q as a function of H and Z, but not con￾taining Em.
7.11 The delta function is sometimes represented as
δ(x) = 1
2π
Z ∞
−∞
e
ikx dk
Show that this definition satisfies the properties of the delta func￾tion given in Equations (7.10)–(7.12).Math interlude C: Matrices, Dirac notation, and the Dirac delta function 177
7.12 Show that
δ(ax) = δ(x)
|a|
7.13 Show that
Z ∞
−∞
f(x)δ(g(x)) dx =
f(x0)
|dg/dx|x=x0
where x0 is determined by g(x0) = 0.This page intentionally left blankChapter 8
Spin angular momentum
In Chapter 6 we noted that there are two types of angular momentum most
relevant in quantum mechanics: orbital angular momentum, produced at
the classical level by the physical motion of a particle, and spin angular
momentum, which represents a type of angular momentum internal to the
particle. Here we will examine the latter in more detail. Although it is
tempting to think of “spin” as being produced by the actual internal rota￾tion of a particle, this is misleading. It is more accurate to treat spin as an
intrinsic property of the particle, like charge or mass.
8.1 Spin Operators
All of the formalism derived for angular momentum operators in Chapter 6
carries over to spin operators. In particular, the operators Sx, Sy, and Sz
give the components of spin angular momentum in the x, y, and z directions,
respectively, while S
2 = S
2
x + S
2
y + S
2
z
is the operator corresponding to the
square of the total angular momentum. Further, these operators satisfy the
standard angular momentum commutation relations derived in Chapter 6:
[Sx, Sy] = iℏSz (8.1)
[Sz, Sx] = iℏSy (8.2)
[Sy, Sz] = iℏSx (8.3)
As in the case of orbital angular momentum, it is impossible to measure
all three components of spin simultaneously, but it is possible to measure
a single component of S and the total squared angular momentum S
2
. As
before, we will normally make the somewhat arbitrary decision to measure
the z component of angular momentum. Then a particle which is in an
179180 Quantum Mechanics: An Accessible Introduction
eigenstate of the operators S
2 and Sz has a wave function |ψ⟩ satisfying
S
2
|ψ⟩ = ℏ
2
s(s + 1)|ψ⟩ (8.4)
Sz|ψ⟩ = ℏms|ψ⟩
However, there are also significant differences between spin angular
momentum and orbital angular momentum. First, recall that the eigen￾functions of orbital angular momentum could be written as spatial wave
functions, namely the spherical harmonics Y
m
l
(θ, ϕ). There are no spatial
wave functions corresponding to eigenstates of spin, since spin is a purely
internal property of a particle. Second, the total spin eigenvalue s has a
fixed value for any given particle, and, unlike orbital angular momentum,
it cannot be increased or decreased for a single particle. For example, the
electron in a hydrogen atom can attain arbitrarily large values for l (for ar￾bitrarily large values of n). However, its spin is always s = 1/2. This is one
reason that viewing spin as the physical rotation of a particle is misleading;
an elementary particle cannot be “spun up” to obtain larger values of spin.
Finally, we saw in Chapter 6 that the orbital angular momentum quantum
number was restricted to integer values. This is not true for spin; the spin
quantum number can take on the full range of both integer and half-integer
values: s = 0, 1/2, 1, 3/2, . . . .
All elementary particles in nature have an intrinsic spin, given by the
s quantum number of Equation (8.4). In fact, spin is such a fundamen￾tal property that particles are classified according to their spin: particles
with integer spin (s = 0, 1, 2, . . .) are called bosons, while particles with
half-integer spin (s = 1/2, 3/2, . . .) are called fermions. The properties of
fermions and bosons in multi-particle collections are fundamentally differ￾ent, as we will see in Chapter 13. All of the particles making up the ordinary
matter in the universe, i.e., protons, neutrons, and electrons, have s = 1/2
and are therefore fermions. Bosons include the photon (s = 1), the pion
(s = 0), and the graviton (s = 2), which is hypothesized to transmit the
gravitational force.
8.2 Evidence for Spin
What is the reason for believing that spin angular momentum even exists?
Today, the entire edifice of particle physics is built on the idea that particles
have spin, so there are countless experiments confirming it. But there
were two main pieces of experimental evidence available to the pioneers of
quantum mechanics, and both are based on the same mechanism: the link
between angular momentum and the production of magnetic fields.Spin angular momentum 181
q
r
v
Fig. 8.1 A particle of charge q moving in a circular orbit of radius r at velocity of
magnitude v produces a magnetic moment µ = qvr/2.
Consider first the case of orbital angular momentum, and recall how
magnetic fields are generated by a classical charged particle moving in a
circular trajectory. A classical particle with charge q, moving in a circular
orbit of radius r with velocity of magnitude v (Figure 8.1) produces the
current
I =
qv
2πr
and the magnetic moment is
µ = IA
=
qv
2πr
πr2
=
qvr
2
Further, the classical angular momentum is
L = mvr
so that the relation between the magnetic moment and the angular mo￾mentum for a classical charged particle in a circular orbit is
µ =
q
2m
L
For an electron with charge q = −e, this expression gives
µ = −
e
2me
L (8.5)
It is conventional to write the magnetic moment in terms of the Bohr
magneton, which is defined by
µB =
eℏ
2me
= 9.3 × 10−24 A·m2182 Quantum Mechanics: An Accessible Introduction
Then the expression for the magnetic moment of an electron can be rewrit￾ten as
µ = −
µB
ℏ
L
Note that L and ℏ have the same units, and µB has units of magnetic
moment. Now recall that both the angular momentum and the magnetic
moment are vectors. Further, we insert an extra factor gl
into the expression
for the magnetic moment, setting gl = 1. This gives
µl = −
glµB
ℏ
L (8.6)
Why did we insert this extra factor gl
, only to set it to one? The reason is
that when we generalize our result to include spin angular momentum, we
will have another factor gs, but it will not necessarily be equal to one. Using
gl
in Equation (8.6) preserves the parallel between the orbital magnetic
moment and the spin magnetic moment.
Arguing from analogy to Equation (8.6), we now postulate that the
spin angular momentum will also generate a magnetic field with magnetic
moment of the form
µs = −
gsµB
ℏ
S (8.7)
It is observed experimentally that Equation (8.7) does, in fact, apply to the
electron, but now gs ̸= 1. The value of gs for the electron is, in fact, one
of the best measured quantities in nature (X. Fan, et al., Physical Review
Letters 130, 071801, 2023):
gs = 2.00231930436118 ± 0.00000000000026
This measured value for gs leads to some obvious questions: Why is it
almost exactly equal to 2? And why is it not exactly equal to 2? It turns
out that the answers to both of these questions are very significant. The
answer to the first question can be derived from the Dirac equation, which
is the basic equation of relativistic quantum mechanics (Chapter 15). The
Dirac equation predicts that gs should be exactly equal to 2. The small
deviation from 2 is a real effect, but it was not explained until the invention
of quantum field theory by Richard Feynmann and others in the 1940’s.
This small deviation from 2 is called the anomalous magnetic moment of
the electron, and its calculation is far beyond the scope of this book. For
most practical purposes, it is sufficient to take gs = 2.
These derivations of µl and µs are based, for µl
, on purely classical ar￾guments, and, for µs, on analogy from the µl derivation, so why should theySpin angular momentum 183
be believed? The evidence, as always, is based on experiment. The first
piece of evidence comes from the energy levels of the atom. Our derivation
of the hydrogen energy levels in Chapter 6 is incomplete. In the spectrum
of hydrogen, for example, experimental evidence shows that certain of the
degenerate energy levels are not, in fact, completely degenerate but are sep￾arated by a tiny amount in energy. This can be explained by the interaction
between the spin magnetic moment of the electron and its orbital magnetic
moment; this interaction splits the degenerate levels apart in energy. This
calculation will be performed in detail in Chapter 9 after the necessary
mathematical machinery has been developed. Under the assumption that
the orbital and spin magnetic moments are given by Equations (8.6) and
(8.7), respectively, this splitting can be predicted correctly. Obviously, this
mechanism will work only if the electron has both an orbital magnetic mo￾ment and a spin magnetic moment. The former will be produced by any
charged particle with orbital angular momentum, but the latter makes sense
only if the electron has its own intrinsic angular momentum. This explana￾tion was first proposed by Goudsmit and Ulhenbeck in 1925, and it is now
known to be correct.
A “cleaner” piece of evidence for the spin magnetic moment of the elec￾tron (and, therefore, for the spin of the electron) comes from the Stern–
Gerlach experiment. Consider what happens to a classical bar magnet
placed in an inhomogeneous magnetic field, like the one shown in Figure 8.2.
In this figure, the field strength increases in the upward direction. The small
magnet on the left will be attracted upward, since the field strength at the
S pole, which pulls the magnet up, is larger than the field strength at the
N pole, which pulls the magnet down. The magnet on the right is repelled
in both directions, and the same argument shows that it will be pushed
downward.
Now consider an ideal dipole µ in an inhomogeneous field. The force
exerted on the dipole is F = −∇V , where V is the potential energy of
the dipole in the magnetic field. Assume for simplicity that B is in the z
direction, so
F = −
∂V
∂z zˆ
The potential energy of a magnetic dipole µ in a magnetic field B is
V = −µ·B
Therefore, the force on the dipole can be written as
F =
∂Bz
∂z µzzˆ (8.8)184 Quantum Mechanics: An Accessible Introduction
S
N
B
N
S
S
N
Fig. 8.2 The classical bar magnet on the left will be attracted upward in the inhomo￾geneous magnetic field, while the magnet on the right will be repelled downward.
Imagine that we shoot a beam of atoms into the page through the magnetic
field shown in Figure 8.2 and measure their deflection on a screen behind the
magnetic field. Equation (8.8) says that the force should be proportional
to the z component of the magnetic moment of the atom. In the absence
of spin, Equation (8.6) indicates that this z component should be
µlz = −
glµB
ℏ
Lz
So in the absence of spin, the force, and therefore the deflection of each
atom, should depend on the z component of the orbital angular momentum.
If the atom is in an eigenstate of Lz with quantum numbers l and ml
, then
Lz|l ml⟩ = ℏml
|l ml⟩
so the deflection should depend on ml
. Since ml can range from −l to +l,
we expect that the atoms would be split into 2l + 1 discrete beams.
Stern and Gerlach actually performed this experiment with silver atoms
in 1922 and discovered that the beam formed two bands on the screen be￾hind the magnet; in other words, the inhomogeneous magnetic field split
the beam into exactly two separate beams. This experiment was repeated
using hydrogen atoms by Phipps and Taylor in 1927. Here the experiment
is even clearer in its predictions: hydrogen in its ground state has l = 0
and ml = 0, so if orbital angular momentum is the only source of magnetic
moments in the hydrogen atom, there should be no deflection in the inho￾mogeneous magnetic field at all. However, Phipps and Taylor also got the
same answer: the beam of hydrogen atoms was split into two bands.Spin angular momentum 185
This result can be explained if the electron has spin angular momentum.
Assume that the electron in the hydrogen atom has spin s. Then the z
component of the spin magnetic moment is
Sz|s ms⟩ = ℏms|s ms⟩
For the hydrogen atoms to be split into two beams requires that ms take
on exactly two possible values, namely, ms = ±1/2. This will be true if the
electron has s = 1/2.
8.3 Adding Angular Momentum
The electrons in an atom have both orbital and spin angular momentum.
Even in the simplest atom, hydrogen, both types of angular momentum
will be present. It is important, therefore, to understand how to calculate
the total angular momentum, including both the orbital and spin compo￾nents. Classically, the addition of angular momentum is straightforward:
it corresponds to a vector sum of the two individual components of angular
momentum. In quantum mechanics, things are more complicated. We will
define the total angular momentum operator J as the sum of the L and S
operators:
J = L + S (8.9)
An eigenstate of total angular momentum and of the z component of total
angular momentum is written as |j mj ⟩ with
J
2
|j mj ⟩ = ℏ
2
j(j + 1)|j mj ⟩
Jz|j mj ⟩ = ℏmj |j mj ⟩ (8.10)
Suppose that we have a state with quantum numbers l, ml
, s, ms, and
we would like to calculate the possible values of j and mj . Clearly, J
2 ̸=
L
2 + S
2
, so there is not a simple relationship between j, l, and s. However,
it is true from Equation (8.9) that
Jz = Lz + Sz
Thus, if |ml ms⟩ is an eigenstate of both Sz and Lz such that
Lz|ml ms⟩ = ℏml
|ml ms⟩
Sz|ml ms⟩ = ℏms|ml ms⟩
then
Jz|ml ms⟩ = (Lz + Sz)|ml ms⟩ = ℏ(ml + ms)|ml ms⟩186 Quantum Mechanics: An Accessible Introduction
A comparison of this equation with Equation (8.10) shows that the z￾component quantum numbers are additive:
mj = ml + ms (8.11)
This result also provides a clue as to the possible values of j. Since
ml ≤ l and ms ≤ s, Equation (8.11) implies
mj ≤ l + s (8.12)
Since mj ≤ j, Equation (8.12) will automatically be satisfied as long as
j ≤ l + s
This quantum mechanical relation is in agreement with the upper bound
on the classical value of |J|: classically, the largest possible value of |J|
occurs when L and S are parallel, so that |J| = |L| + |S|. The smallest
possible value of |J| in the classical case occurs when L and S are pointing
in opposite directions, so that |J| = ||L| − |S||. This suggests the quantum
analog
j ≥ |l − s|
Note further that j can vary between |l−s| and l+s only in integer steps, not
half-integer steps. The reason for this can be derived from Equation (8.11).
Suppose that j and mj both have their maximum values; j = l + s and
mj = ml + ms. Since ml and ms vary by integer steps between their
maximum and minimum values, the next largest value of mj possible is
mj = ml +ms −1. However, if j could vary by half-integer steps, we would
expect to see mj = ml + ms − 1/2, which does not exist. To summarize,
the possible values of j are
j = |l − s|, |l − s| + 1, . . . , l + s − 1, l + s (8.13)
Example 8.1. Adding Angular Momenta in the Hydrogen Atom
The electron in a hydrogen atom is in an l = 1 state. What are the possible
values of j and mj ?
The electron has s = 1/2 and l = 1, so Equation (8.13) gives j = 1/2
or j = 3/2. In the usual way, mj can vary from −j to +j in integer steps,
so the possible values of j and mj are
j = 1/2, mj = −1/2, +1/2
j = 3/2, mj = −3/2, −1/2, +1/2, +3/2Spin angular momentum 187
In general, if the electron in a hydrogen atom has quantum number l,
then the possible values for j are j = l−1/2 and j = l+ 1/2. The exception
to this is the case l = 0 for which j = 1/2 is the only possible state.
Nothing in this derivation is peculiar to orbital and spin angular mo￾menta; these arguments apply to the addition of any angular momenta. For
instance, for two particles with spins s1 and s2, the possible values for the
total spin quantum number s are
s = |s1 − s2|, |s1 − s2| + 1, . . . , s1 + s2 − 1, s1 + s2
A frequently encountered situation is that of two particles each with spin
1/2, such as the electron and proton in a hydrogen atom. In this case, the
possible total spin states are s = 1 and s = 0. The s = 1 state is called
the triplet state because it has three possible values for ms (i.e., −1, 0, and
+1), while the s = 0 state is called the singlet state because it can have
only ms = 0.
8.4 The Matrix Representation of Spin
In this section we will develop a mathematical representation of spin states.
Unlike orbital angular momentum, the spin states cannot be written as
functions of position. Instead, they can be represented as column vectors.
Consider first a particle, such as the electron, which has s = 1/2. It has
two possible values for ms which are ms = −1/2 and ms = +1/2. Since ms
represents the z component of spin, it is convenient to think of these states
as two different orientations of the angular momentum vector, namely, spin
“down” and spin “up” (Figure 8.3). These states can be represented in
Dirac notation as | ↓ ⟩ for spin down and | ↑ ⟩ for spin up. Thus, we have
Sz| ↓ ⟩ = −
ℏ
2
| ↓ ⟩
Sz| ↑ ⟩ = +
ℏ
2
| ↑ ⟩
There are only a finite number of these states (i.e., two). This suggests
that they can be represented in terms of a two-dimensional vector space
consisting of column vectors. Thus, the spin up state is written as
| ↑ ⟩ ⇔ 
1
0
188 Quantum Mechanics: An Accessible Introduction
ms
 = –1/2 ms
 = +1/2
Fig. 8.3 For a particle with s = 1/2, the state ms = −1/2 is spin down, and ms = +1/2
is spin up.
and the spin down state as
| ↓ ⟩ ⇔ 
0
1

These two vectors form an orthonormal basis set, since
⟨ ↑ | ↑ ⟩ =
￾
1 0

1
0

= 1
⟨ ↓ | ↓ ⟩ =
￾
0 1

0
1

= 1
⟨ ↑ | ↓ ⟩ =
￾
1 0

0
1

= 0
⟨ ↓ | ↑ ⟩ =
￾
0 1

1
0

= 0
Although the spin 1/2 case will be investigated in the most detail, this
matrix representation can be extended to other spin states. For example,
for s = 1 there are three spin vectors, namely,
|s = 1, ms = 1⟩ ⇔


1
0
0


|s = 1, ms = 0⟩ ⇔


0
1
0


|s = 1, ms = −1⟩ ⇔


0
0
1


Now consider the spin operators Sx, Sy, and Sz. From the discussion
in Chapter 7, these should be 2 × 2 matrices, which we will now calculate.
Consider an arbitrary 2×2 matrix A. It is possible to pick out the indiviSpin angular momentum 189
elements of the matrix by the following sorts of matrix multiplications:
￾
1 0

A11 A12
A21 A22 1
0

= A11
￾
0 1

A11 A12
A21 A22 1
0

= A21
and so forth. In general, for a matrix of arbitrary size, the element Aij can
be picked out by multiplying on the left side with a row vector having 1 in
the ith entry and 0’s everywhere else, and on the right by a column vector
having 1 in the jth entry and 0’s everywhere else:
￾
0 0 · · · 1 · · · 0

 
A
!


0
0
.
.
.
1
.
.
.
0


= Aij
Since the basis vectors | ↓ ⟩ and | ↑ ⟩ are eigenvectors of the operator Sz,
it is straightforward to use this method to calculate the matrix elements of
Sz:
Sz11 = ⟨ ↑ |Sz| ↑ ⟩ = ⟨ ↑ |ℏ
2
| ↑ ⟩ =
ℏ
2
⟨ ↑ | ↑ ⟩ =
ℏ
2
Sz12 = ⟨ ↑ |Sz| ↓ ⟩ = ⟨ ↑ | − ℏ
2
| ↓ ⟩ = −
ℏ
2
⟨ ↑ | ↓ ⟩ = 0
Sz21 = ⟨ ↓ |Sz| ↑ ⟩ = ⟨ ↓ |ℏ
2
| ↑ ⟩ =
ℏ
2
⟨ ↓ | ↑ ⟩ = 0
Sz22 = ⟨ ↓ |Sz| ↓ ⟩ = ⟨ ↓ | − ℏ
2
| ↓ ⟩ = −
ℏ
2
⟨ ↓ | ↓ ⟩ = −
ℏ
2
Thus, Sz is given by the matrix
Sz =

ℏ/2 0
0 −ℏ/2

Example 8.2. Using the Matrix Representation of Sz
Here we verify that Sz gives the correct result when operating on | ↓ ⟩ and
| ↑ ⟩. The matrix representations for Sz, | ↓ ⟩, and | ↑ ⟩ give
Sz| ↑ ⟩ =

ℏ/2 0
0 −ℏ/2
 1
0

=
ℏ
2

1
0

=
ℏ
2
| 190 Quantum Mechanics: An Accessible Introduction
and
Sz| ↓ ⟩ =

ℏ/2 0
0 −ℏ/2
 0
1

= −
ℏ
2

0
1

= −
ℏ
2
| ↓ ⟩
so Sz does indeed give the correct result when applied to | ↓ ⟩ and | ↑ ⟩.
Obtaining matrix representations for Sx and Sy is a bit more compli￾cated. To do this, we make use of the spin ladder operators, which are the
analogs of the operators defined in Chapter 6 for orbital angular momen￾tum:
S+ = Sx + iSy (8.14)
S− = Sx − iSy (8.15)
As in Chapter 6, these operators raise and lower the values of ms, and
they give 0 when attempting to raise ms above its highest allowed value or
attempting to lower ms below its lowest allowed value. Thus,
S−|s ms⟩ ∝ |s ms − 1⟩ (8.16)
S+|s ms⟩ ∝ |s ms + 1⟩ (8.17)
The constants of proportionality in Equations (8.16) and (8.17) need to be
determined. Note that S
†
− = S+ and S
†
+ = S−, so if
S−|s ms⟩ = c|s ms − 1⟩ (8.18)
where c is a constant to be determined, then the dual of this equation is
⟨s ms|S+ = ⟨s ms − 1|c
∗
(8.19)
and taking the inner product of the quantities in Equations (8.18) and
(8.19) gives
⟨s ms|S+S−|s ms⟩ = c
∗
c⟨s ms − 1|s ms − 1⟩ = |c|
2
(8.20)
In order to determine c, we must express S+S− in terms of operators
whose behavior, when applied to |s ms⟩, is known. Note that
S+S− = (Sx + iSy)(Sx − iSy)
= S
2
x + S
2
y − i[Sx, Sy]
= S
2
x + S
2
y − i(iℏSz)
= S
2 − S
2
z + ℏSzSpin angular momentum 191
and we know how S
2 and Sz operate on |s ms⟩. Thus Equation (8.20) can
be written as
⟨s ms|S
2 − S
2
z + ℏSz|s ms⟩ = |c|
2
which gives
|c|
2 = ℏ
2
[s(s + 1) − m2
s + ms]
Hence, Equation (8.18) can be written as
S−|s ms⟩ = ℏ
p
s(s + 1) − ms(ms − 1)|s ms − 1⟩ (8.21)
A similar argument gives
S+|s ms⟩ = ℏ
p
s(s + 1) − ms(ms + 1)|s ms + 1⟩
For the special case of s = 1/2, we get S−| ↑ ⟩ = ℏ| ↓ ⟩ and S+| ↓ ⟩ = ℏ| ↑ ⟩.
These expressions for S+ and S− can now be used to determine the
matrix elements for Sx and Sy, because we have explicit expressions for the
way in which S+ and S− operate on | ↓ ⟩ and | ↑ ⟩, and Sx and Sy can be
written as
Sx =
1
2
(S+ + S−) (8.22)
Sy =
1
2i
(S+ − S−) (8.23)
The matrix elements of S+ are
S+11 = ⟨ ↑ |S+| ↑ ⟩ = 0 (because S+| ↑ ⟩ = 0)
S+12 = ⟨ ↑ |S+| ↓ ⟩ = ⟨ ↑ |ℏ| ↑ ⟩ = ℏ⟨ ↑ | ↑ ⟩ = ℏ
S+21 = ⟨ ↓ |S+| ↑ ⟩ = 0 (because S+| ↑ ⟩ = 0)
S+22 = ⟨ ↓ |S+| ↓ ⟩ = ⟨ ↓ |ℏ| ↑ ⟩ = 0 (because ⟨ ↓ | ↑ ⟩ = 0)
Similarly, for the matrix representing S−,
S−21 = ℏ
and all of the other matrix elements are 0. Then S+ and S− are
S+ =

0 ℏ
0 0
S− =

0 0
ℏ 0
192 Quantum Mechanics: An Accessible Introduction
Then Equations (8.22) and (8.23) give the matrices for Sx and Sy:
Sx =

0 ℏ/2
ℏ/2 0 
Sy =

0 −iℏ/2
iℏ/2 0 
It is convenient to factor out ℏ/2 from Sx, Sy, and Sz, and to write all of
these matrices in terms of the Pauli spin matrices, σx, σy, and σz:
Sx =
ℏ
2
σx
Sy =
ℏ
2
σy
Sz =
ℏ
2
σz
where σx, σy, and σz are
σx =

0 1
1 0
σy =

0 − i
i 0

σz =

1 0
0 − 1

The next step is to determine the eigenvectors and eigenvalues of the
spin operators. Note that we have already done this for Sz; the eigenvectors
and eigenvalues for Sz are
| ↑ ⟩ =

1
0

, eigenvalue = +ℏ
2
and
| ↓ ⟩ =

0
1

, eigenvalue = −
ℏ
2
Now consider the spin operator in the x direction Sx, and assume an eigen￾vector 
ψ1
ψ2

with eigenvalue c. The eigenvalue equation is
ℏ
2

0 1
1 0 ψ1
ψ2

= c

ψ1
ψ2
Spin angular momentum 193
This leads to the determinant equation:




−c ℏ/2
ℏ/2 −c




= 0
which gives c
2 − (ℏ/2)2 = 0, so that c = ±ℏ/2. Thus, the eigenvalues of
Sx are identical to the eigenvalues of Sz. However, this is exactly what
we would expect. There is no preferred direction for the particle, and the
coordinate axes can always be rotated so that the x-axis points in the z
direction, so any quantities measured along the z-axis should have the same
set of possible values if they are measured along the x-axis (or any other
axis, for that matter).
The eigenvector of Sx for c = +ℏ/2 is given by
ℏ
2

0 1
1 0 ψ1
ψ2

=
ℏ
2

ψ1
ψ2

which yields the two equations
(ℏ/2)ψ2 = (ℏ/2)ψ1
(ℏ/2)ψ1 = (ℏ/2)ψ2
As expected, these two equations are not independent of each other; both
are satisfied as long as ψ1 = ψ2. Thus, the eigenvector, which we will
designate | →⟩, can be any multiple of 
1
1

. However, the eigenvector
must be normalized. Writing | →⟩ = c

1
1

, the normalization requirement
is
⟨→ | →⟩ = |c|
2
￾
1 1

1
1

= 2|c|
2 = 1
so that c = 1/
√
2. Hence, the normalized eigenvector of Sx with spin in the
+x direction is
| →⟩ =
1
√
2

1
1

(8.24)
A similar calculation for the eigenvector corresponding to spin in the −x
direction (eigenvalue = −ℏ/2) yields
| ←⟩ =
1
√
2

1
−1

(8.25194 Quantum Mechanics: An Accessible Introduction
For Sy the eigenvectors are (Problem 8.4):
| ↗⟩ =
1
√
2

1
i

, (+y direction) (8.26)
| ↙⟩ =
1
√
2

1
−i

, (−y direction) (8.27)
Note that the set of eigenvectors of Sz, namely, | ↑ ⟩ =

1
0

and
| ↓ ⟩ =

0
1

, form an orthonormal basis set, so any other spin state can be
represented as a sum of | ↑ ⟩ and | ↓ ⟩. From Equations (8.24) and (8.25),
| →⟩ and | ←⟩ can be expressed in terms of | ↑ ⟩ and | ↓ ⟩:
| →⟩ =
1
√
2
(| ↑ ⟩ + | ↓ ⟩)
| ←⟩ =
1
√
2
(| ↑ ⟩ − | ↓ ⟩)
Thus, a particle with a spin in the +x or −x direction is a linear com￾bination of states with spins in the +z and −z directions. This is one
of the counterintuitive predictions of quantum mechanics with no classical
analog. As we will see in the next section, it leads to some rather strange
consequences.
8.5 The Stern–Gerlach Experiment
As noted in Section 8.2, the Stern–Gerlach experiment provided some of the
first evidence for the existence of spin angular momentum. In this section,
we will use an idealized Stern–Gerlach experiment to examine some of the
more bizarre consequences of quantum mechanics.
Imagine a Stern–Gerlach apparatus with an inhomogeneous magnetic
field oriented in the z direction, so that the apparatus separates particles
based on the z component of their magnetic moment. A beam of individual
electrons is passed through this apparatus, and the beam splits into two
parts with ms = +1/2 and ms = −1/2, respectively (Figure 8.4). This
allows us to separate the electrons into states of pure | ↑ ⟩ and | ↓ ⟩.
Now suppose that the beam containing the electrons in the | ↑ ⟩ state is
run through a second Stern–Gerlach apparatus with the field now aligned
in the x direction (Figure 8.5).Spin angular momentum 195
z
y
x
B
e
–
ms
 = –1/2
ms
 = +1/2
Fig. 8.4 A Stern–Gerlach apparatus with an inhomogeneous magnetic field in the z
direction will separate a beam of electrons into two states with ms = +1/2 and ms =
−1/2.
z
y
x
B
Fig. 8.5 A beam of electrons in the | ↑ ⟩ state is run through a Stern–Gerlach apparatus
with an inhomogeneous magnetic field in the x direction.
This beam now splits into two separate beams having spins of +1/2
and −1/2 in the x direction. This result can be explained from a quantum
mechanical point of view. Since Sx and Sz do not commute, the electrons
cannot simultaneously be in a state of definite Sz and definite Sx. The
first Stern–Gerlach apparatus forces the electrons into an eigenstate of Sz,
namely, | ↑ ⟩. However, this state is a linear combination of the eigenstates
of Sx. Therefore, the second Stern–Gerlach apparatus “sees” a mixture of
| →⟩ and | ←⟩ and separates the beam into these two states.
Given a set of electrons in the state | ↑ ⟩, it is possible to calculate the
probability that a second measurement, such as the one just described, will
yield a spin in the +x or −x direction. In Dirac notation, if a particle is in
a particular state |ψ⟩, and we make a measurement to determine whether
or not it is in the state |ϕ⟩, the probability that it will be found to be in196 Quantum Mechanics: An Accessible Introduction
z
y
x
B
B
Fig. 8.6 A beam of electrons in the | ↑ ⟩ state is run through a Stern–Gerlach apparatus
with an inhomogeneous magnetic field in the x direction and then another Stern–Gerlach
apparatus with an inhomogeneous magnetic field in the z direction.
the state |ϕ⟩ is
P = |⟨ϕ|ψ⟩|2
Example 8.3. Calculating Spin State Probabilities
A particle is initially in the | ↑ ⟩ state, and the spin is measured in the x
direction. What is the probability that the spin is found to be in the +x
direction?
The particle is initially in the state | ↑ ⟩ =

1
0

. We wish to know,
when the spin is measured in the x direction, whether the particle will be
found to be in the state | →⟩ =
1
√
2

1
1

. This probability is
P = |⟨→ | ↑ ⟩|2
=




1
√
2
￾
1 1

1
0




2
=
1
Spin angular momentum 197
Now here is where quantum mechanics gives a truly strange result. Sup￾pose we set up a triple Stern–Gerlach apparatus (Figure 8.6). The first
apparatus picks out the electrons in the | ↑ ⟩ state, the second apparatus
splits this beam into the | →⟩ and | ←⟩ states, and then we run the | →⟩
electrons back through a third Stern–Gerlach apparatus that is identical to
the first one: it separates the electrons on the basis of the z component of
their spins. In a classical system, since we selected out only electrons with
spins in the +z direction, the final Stern–Gerlach apparatus would produce
only a single beam of electrons with spins in the +z direction. However,
this is not what happens at all; instead, the beam splits again into a beam
with spin in the +z direction and a beam with spin in the −z direction!
To see what is happening, note that the first Stern–Gerlach apparatus
picks out electrons in the state | ↑ ⟩. The second Stern–Gerlach apparatus
separates this beam into the states | →⟩ and | ←⟩, and we keep only the
| →⟩ electrons. But | →⟩ is a mixture of | ↑ ⟩ and | ↓ ⟩ states, namely,
| →⟩ = (1/
√
2)(| ↑ ⟩ + | ↓ ⟩). So in making this measurement, we have
added back in the | ↓ ⟩ component, which shows up in the third apparatus.
The very act of measuring the spin changes the state of the particle. This
is one of the characteristics of quantum mechanics not present in classical
physics: in an experiment of this kind, there is no way to avoid changing the
state of the system through the act of measurement. This idea is examined
in more detail in the discussion of measurement theory in Section 8.8.
8.6 Spin Precession
In this section we will see an example of how spin can be incorporated
into the Schr¨odinger equation. Imagine that we have a classical magnetic
dipole µ in a magnetic field B (Figure 8.7). The magnetic field exerts a
torque µ×B on the dipole, which will cause it to line up parallel with the
field. But now suppose that in addition, the dipole has angular momentum
(Figure 8.8). A rotating body to which a torque is applied will precess in
a direction perpendicular to the angular momentum vector.
B
m
Fig. 8.7 A classical magnetic dipole µ in a magnetic field B experiences a torque µ×B,
which tends to align the dipole with the field.198 Quantum Mechanics: An Accessible Introduction
Of course, there is no way to know if these classical analogies will carry
over into the quantum realm until we solve the Schr¨odinger equation. Con￾sider an electron with magnetic moment µ at rest in an external magnetic
field B. Since we are interested in how the particle spin evolves in time, we
will use the time-dependent Schr¨odinger equation,
H|ψ⟩ = iℏ
∂
∂t|ψ⟩ (8.28)
where |ψ⟩ is the Dirac wave function for the particle. This leads to two
obvious questions: What is the form for H, and what is the form for |ψ⟩?
Since the electron is at rest, the kinetic energy part of H will be zero, and
H will be given purely by the potential energy which is
V = −µ·B
Since we are interested in the evolution of the orientation of the spin of the
electron, V must be expressed in terms of the spin rather than the magnetic
moment, using the relation
µ = −
2µB
ℏ
S
where we have taken gs = 2 for the electron. Then the potential is
V =
2µB
ℏ
B·S
We choose a coordinate system so that B is pointing in the z direction, so
B·S = BSz, and we express Sz as
Sz =
ℏ
2
σz
so that the potential becomes
V = µBBσz
Then the Schr¨odinger equation (Equation (8.28)) becomes
µBBσz|ψ⟩ = iℏ
∂
∂t|ψ⟩ (8.29)
B
m
Fig. 8.8 A classical magnetic dipole with angular momentum will precess in a magnetic
field.Spin angular momentum 199
This equation indicates the form for |ψ⟩: since σz is a 2×2 Pauli spin matrix,
|ψ⟩ is just the spin state of the electron written as a two-component column
vector
|ψ⟩ =

ψ+
ψ−

where ψ+ and ψ− will be functions of time. Then Equation (8.29) takes
the form
µBB

1 0
0 −1
 ψ+
ψ−

= iℏ
∂
∂t 
ψ+
ψ−

Carrying out the matrix multiplication yields two ordinary differential equa￾tions:
µBBψ+ = iℏ
dψ+
dt
µBB(−ψ−) = iℏ
dψ−
dt
The general solutions of these two equations give the time evolution of ψ+
and ψ−
ψ+ = A+e
−i(µBB/ℏ)t
ψ− = A−e
i(µBB/ℏ)t
where A+ and A− are constants to be determined. In matrix form, the
solution is then
|ψ⟩ =
 
A+e
−i(µBB/ℏ)t
A−e
i(µBB/ℏ)t
!
(8.30)
The constants A+ and A− are determined from the initial conditions. In
particular, if we take t = 0 to be the initial time, then
|ψ(t = 0)⟩ =

A+
A−

For example, suppose that the electron has spin up (i.e., in the +z
direction) at t = 0. This corresponds to the state
|ψ(t = 0)⟩ =

1
0
200 Quantum Mechanics: An Accessible Introduction
so that A+ = 1 and A− = 0. Then Equation (8.30) gives the wave function
at any later time t:
|ψ⟩ =

e
−i(µBB/ℏ)t
0

Although this wave function is a function of time, it represents a state of
constant spin. To see this, note that P = |⟨↑ |ψ(t)⟩|2 gives the probability
of finding the particle in the spin up state. This probability is
P =




￾
1 0

e
−(iµBB/ℏ)t
0




2
= 1
Thus, the electron starts out in the | ↑ ⟩ state, and it stays there forever.
This is consistent with the classical analog; a classical dipole pointing par￾allel to a magnetic field experiences no torque and does not rotate.
Now consider the more interesting case of an electron with spin initially
in the +x direction. In this case the initial spin state (correctly normalized)
is
|ψ(t = 0)⟩ =
1
√
2

1
1

Then A+ = 1/
√
2 and A− = 1/
√
2, so the full time-dependent wave func￾tion from Equation (8.30) is
|ψ⟩ =


1
√
2
e
−i(µBB/ℏ)t
1
√
2
e
i(µBB/ℏ)t


To simplify the equation, define a new quantity ω given by
ω = 2µBB/ℏ
where ω has units of 1/time or, equivalently, frequency. Then the wave
function is
|ψ⟩ =
1
√
2
 
e
−i(ω/2)t
e
i(ω/2)t
!
To understand the physical meaning of this wave function, we can evaluate
it at a variety of times. In particular, we have
|ψ(t = 0)⟩ =
1
√
2

1
1
Spin angular momentum 201
t = 0 t = ( ) 4
2p
v
t = ( ) 2
2p
v
t = ( ) 1 1 3
4
2p
v
2p
v
t = 
x
y
Fig. 8.9 An electron precessing in the x-y plane with frequency ω = 2µBB/ℏ.
which is just our initial condition: the spin is in the +x direction at t = 0.
Further,
|ψ(t = 2π/ω)⟩ =
1
√
2

e
−iπ
e
iπ 
= −
1
√
2

1
1

This is the original wave function multiplied by a phase factor of −1. Thus,
at t = 2π/ω, the spin is once again pointing in the +x direction. This sug￾gests that we investigate intermediate times. At the halfway point between
t = 0 and t = 2π/ω, i.e., at t = (1/2)2π/ω, we get
|ψ(t = (1/2)2π/ω)⟩ =
1
√
2

e
−iπ/2
e
iπ/2

= −
i
√
2

1
−1

which is the wave function for spin in the −x direction. Taking half of this
interval again, we get, at t = (1/4)(2π/ω),
|ψ(t = (1/4)2π/ω)⟩ =
1
√
2

e
−iπ/4
e
iπ/4

=
1
2
(1 − i)

1
i

which is the spin eigenstate in the +y direction. Similarly, taking t =
(3/4)(2π/ω) gives the spin eigenstate in the −y direction.
Putting all of this information together, we see that the electron is pre￾cessing, with the direction of its spin vector rotating in the counterclockwise
direction (Figure 8.9). The period of precession is 2π/ω, so the angular
frequency is ω = 2µBB/ℏ. This phenomenon is the basis of magnetic res￾onance imaging, which will be examined in more detail in Chapter 14.202 Quantum Mechanics: An Accessible Introduction
8.7 Spin Systems with Two Particles
In this section we consider systems of two particles with spin. We first
examine the case in which there is no spin-dependent interaction between
the two particles. We then consider what happens if there is such an inter￾action, so that the Hamiltonian depends on the spins.
Noninteracting Spins
Consider the general system of two particles, each with spin 1/2, in which
there is no spin-dependent interaction between the particles. The spin oper￾ators for particle 1 and particle 2 can be written as S1 and S2, respectively.
As in the case for a single particle, we will consider states which are eigen￾functions of S
2
1
, S
2
2
, S1z, and S2z. We have been using the notation | ↑ ⟩ and
| ↓ ⟩ to refer to eigenstates of the single particle spin operator Sz. For the
two-particle system, we write the eigenstate as |ms1 ms2⟩. So, for example,
| ↑ ↓⟩ represents the state with spin up for particle 1 and spin down for
particle 2 (i.e., ms1 = +1/2 and ms2 = −1/2). Thus,
S1z| ↑ ↓⟩ = +
ℏ
2
| ↑ ↓⟩
S2z| ↑ ↓⟩ = −
ℏ
2
| ↑ ↓⟩
The eigenstates of S
2
1 and S
2
2 do not need to be specified in the wave function
because these are fixed by the fact that the particles have spin 1/2. Thus,
S
2
1
| ↑ ↓⟩ = ℏ
2

1
2
 1
2
+ 1
| ↑ ↓⟩
S
2
2
| ↑ ↓⟩ = ℏ
2

1
2
 1
2
+ 1
| ↑ ↓⟩
So far, this is all straightforward and rather uninteresting; all we have done
is to write down a wave function which combines the spin information for
two particles together.
Now, however, consider the total spin of the system. We can write a
total spin operator
S = S1 + S2
so
Sz = S1z + S2zSpin angular momentum 203
and
S
2 = S
2
1 + S
2
2 + 2S1·S2 (8.31)
From our previous discussion about the addition of angular momentum, we
know that the quantum number for the z component of the total spin ms
is
ms = m1s + m2s
while the quantum number for the total spin s can have the values s = 0
or s = 1. Thus, the two-particle state can also be expressed in terms of
s and ms instead of m1s and m2s. The wave function corresponding to a
state of definite s and ms can be written as |s ms⟩. For example, for s = 0,
the only possible value of ms is ms = 0, and the wave function is |0 0⟩,
the singlet state. If s = 1, then ms = −1, 0, or 1 with corresponding wave
functions |1 − 1⟩, |1 0⟩, and |1 1⟩, the triplet state.
This leads to an obvious question: can we simultaneously measure s,
ms, m1s, and m2s? This would be possible only if all of the operators S
2
,
Sz, S1z, and S2z commuted with each other. Unfortunately, this is not the
case. The expression for S
2
(Equation (8.31)) contains the term 2S1·S2,
which expands out as 2(S1xS2x + S1yS2y + S1zS2z), and, for example, S1x
and S1y do not commute with S1z, and S2x and S2y do not commute with
S2z. More explicitly,
[S
2
, S1z] = [S
2
1 + S
2
2 + 2(S1xS2x + S1yS2y + S1zS2z), S1z]
= 2[S1x, S1z]S2x + 2[S1y, S1z]S2y
= −2iℏS1yS2x + 2iℏS1xS2y
which is nonzero. A similar argument indicates that S
2 does not commute
with S2z. Therefore, it is not possible to measure s and m1s, m2s simulta￾neously. The particles can be in a state in which the z component of both
spins is known exactly (written as |m1s m2s⟩), or they can be in a state in
which s and ms are known exactly (written as |s ms⟩), but not both at the
same time.
Suppose that we are in a state of definite s and ms. Although we cannot
uniquely specify the values of m1s and m2s, we can write the state |s ms⟩ as
a linear combination of the four possible |m1s m2s⟩ states, since the latter
form a basis set. In other words, we can write
|s ms⟩ = c1| ↑ ↑⟩ + c2| ↑ ↓⟩ + c3| ↓ ↑⟩ + c4| ↓ ↓⟩ (8.32)
and we can calculate the constants c1, c2, c3, and c4. One reason for
doing this is that if the particles are in a state of definite s, ms, there204 Quantum Mechanics: An Accessible Introduction
is nothing to prevent us from subsequently measuring the individual spin
states. Although we cannot predict the result in advance (since we are not
in an eigenstate of S1z and S2z), Equation (8.32) can be used to find the
probabilities of measuring a particular value of m1s and m2s.
Consider first the state |1 1⟩. It must always be true that m1s + m2s =
ms, and the only way to have m1s + m2s = 1 is for both m1s and m2s to
be +1/2, i.e., for both particles to be in the spin up state. Thus,
|1 1⟩ = | ↑ ↑⟩ (8.33)
A similar argument gives
|1 − 1⟩ = | ↓ ↓⟩ (8.34)
On the other hand, both |1 0⟩ and |0 0⟩ have ms = 0, so they are
both linear combinations of | ↑ ↓⟩ and | ↓ ↑⟩. To find the desired linear
combinations, recall that the lowering operator S− acts on |1 1⟩ to give a
multiple of |1 0⟩. Since S− is just Sx − iSy, it is correct to write
S− = S1− + S2−
We can therefore begin with Equation (8.33), apply S− to the left-hand
side, and S1− + S2− to the right-hand side (using Equation (8.21)), and
derive an expression for |1 0⟩ as a function of | ↑ ↓⟩ and | ↓ ↑⟩. This
procedure gives
S−|1 1⟩ = S1−| ↑ ↑⟩ + S2−| ↑ ↑⟩
ℏ
p
1(1 + 1) − 1(1 − 1)|1 0⟩ = ℏ
p
(1/2)(1/2 + 1) − (1/2)(1/2 − 1)| ↓ ↑⟩
+ ℏ
p
(1/2)(1/2 + 1) − (1/2)(1/2 − 1)| ↑ ↓⟩
which simplifies to
|1 0⟩ =
1
√
2
| ↓ ↑⟩ +
1
√
2
| ↑ ↓⟩ (8.35)
This method cannot be applied to the state |0 0⟩, but now note that all of
our spin states should be orthonormal. The normalized linear combination
of | ↑ ↓⟩ and | ↓ ↑⟩ which is orthogonal to √
1
2
| ↓ ↑⟩ + √
1
2
| ↑ ↓⟩ is
|0 0⟩ =
1
√
2
| ↓ ↑⟩ − 1
√
2
| ↑ ↓⟩ (8.36)Spin angular momentum 205
(Of course, there is always the freedom to multiply the right-hand side of
Equation (8.36) by a factor with unit absolute value such as −1.)
We have now expressed all four |s ms⟩ states as linear combinations of
the |m1s m2s⟩ states [Equations (8.33), (8.34), (8.35), and (8.36)]. Al￾though we have examined the specific case of two particles with spin 1/2,
this result can be generalized to particles with other spins. The constants
which appear in Equations (8.33), (8.34), (8.35), and (8.36) (and in those
more general expressions) are called Clebsch–Gordon coefficients.
Example 8.4. Probabilities for a Two-Particle System
A system of 2 particles, each with spin 1/2, is in the singlet state. A
measurement is made of the z component of the spin of the first particle.
What is the probability that m1s = +1/2?
In the singlet state, the wave function is
|0 0⟩ =
1
√
2
| ↓ ↑⟩ − 1
√
2
| ↑ ↓⟩ (8.37)
The only state with m1s = +1/2 appearing on the right-hand side of Equa￾tion (8.37) is | ↑ ↓⟩, so the probability that particle 1 is in the spin up state
is
P = |⟨↑ ↓ |0 0⟩|2
= |⟨↑ ↓ | 
1
√
2
| ↓ ↑⟩ − 1
√
2
| ↑ ↓⟩
|
2
= 1/2
Thus, there is a 50% chance that the first particle is found to be in the spin
up state and a 50% chance it is found to be in the spin down state.
Interacting Spins
Now consider two spin-1/2 particles with a spin-dependent interaction. One
of the simplest possible spin interactions is given by the Hamiltonian
H = λS1·S2 (8.38)
where λ is a real constant. Here it is assumed that the particles are fixed
in space, and there is no other interaction between them, so that Equa￾tion (8.38) gives the entire interaction. Since this Hamiltonian depends on206 Quantum Mechanics: An Accessible Introduction
all three components of S1 and S2, it will not commute with either S1z
or S2z. Hence, states of definite m1s and m2s, such as | ↑ ↑⟩, | ↑ ↓⟩, etc.,
cannot be eigenfunctions of H.
On the other hand, the Hamiltonian given in Equation (8.38) does com￾mute with S
2
. This is because Equation (8.31) can be rewritten as
S1·S2 =
1
2
(S
2 − S
2
1 − S
2
2
)
which allows the Hamiltonian in Equation (8.38) to be written as
H =
λ
2
(S
2 − S
2
1 − S
2
2
)
When written in this form, it is clear that H commutes with S
2 and Sz.
Thus, states of definite s and ms are also eigenstates of H, and we can
compute their energies. We obtain
H|s ms⟩ =
λ
2
ℏ
2

s(s + 1) −
1
2

1
2
+ 1
−
1
2

1
2
+ 1 |s ms⟩
Thus, the energy E is a function entirely of s and is independent of ms; all
three triplet states are degenerate. Inserting the actual values for s gives
the energy levels of the system:
s = 1 (triplet state) E =
1
4
λℏ
2
s = 0 (singlet state) E = −
3
4
λℏ
2
The energy levels of more complex spin-dependent Hamiltonians can be
calculated using similar methods.
Example 8.5. The Magnetic Dipole-Dipole Interaction Between
Two Particles
The magnetic dipole-dipole interaction between two particles with mag￾netic moments µ1 and µ2 fixed in space at a separation r is given by the
Hamiltonian
H =
(µ1
·µ2
)
r
3
− 3
(µ1
·r)(µ2
·r)
r
5
Consider two neutrons, which are uncharged but have spin 1/2 and mag￾netic moment µ = (gne/2mn)S. If they are fixed in space at a distance a
apart, find the energy levels of the system.
Rewriting the Hamiltonian in terms of spins gives
H =

gne
2mn
2 
(S1·S2)
r
3
− 3
(S1·r)(S2·r)
r
5
Spin angular momentum 207
The choice of the coordinate system is arbitrary, so we choose the vector r
separating the two neutrons to lie along the z-axis. Then r = azˆ and r = a,
so the Hamiltonian becomes
H =

gne
2mn
2
1
a
3
(S1·S2 − 3S1zS2z)
As above, S1·S2 can be written as S1·S2 =
1
2
(S
2 − S
2
1 − S
2
2
). It is also true
that S
2
z = (S1z + S2z)
2 = S
2
1z + S
2
2z + 2S1zS2z, so
S1zS2z =
1
2
(S
2
z − S
2
1z − S
2
2z
)
and the Hamiltonian becomes
H =

gne
2mn
2
1
a
3

1
2
(S
2 − S
2
1 − S
2
2
) −
3
2
(S
2
z − S
2
1z − S
2
2z
)

(8.39)
If the neutrons are in a state |s ms⟩, this state is an eigenfunction of
H. The only possible confusion arises from the operators S
2
1z and S
2
2z
in Equation (8.39), since the state |s ms⟩ is not a state of definite m1s and
m2s. However, note that for a spin-1/2 particle, S
2
z
| ↑ ⟩ = (ℏ/2)2
| ↑ ⟩ and
S
2
z
| ↓ ⟩ = (ℏ/2)2
| ↓ ⟩, so S
2
z applied to any spin state gives an eigenvalue of
ℏ
2/4.
Then applying H to the state |s ms⟩ yields
H|s ms⟩ =

gne
2mn
2
1
a
3

1
2
(S
2 − S
2
1 − S
2
2
) −
3
2
(S
2
z − S
2
1z − S
2
2z
)

|s ms⟩
=

g
2
n
e
2
4m2
na
3
 
1
2
ℏ
2

s(s + 1) −
1
2

1
2
+ 1
−
1
2

1
2
+ 1
−
3
2
ℏ
2
"
(m2
s −

1
2
2
−

1
2
2
#!|s ms⟩
=
g
2
n
e
2ℏ
2
8m2
na
3
[s(s + 1) − 3m2
s
]|s ms⟩
so the energy levels are
E =
g
2
n
e
2ℏ
2
8m2
na
3
[s(s + 1) − 3m2
s
]
The dipole-dipole interaction splits all of the s, ms states into distinct
energy levels with the exception of the states ms = ±1, which remain208 Quantum Mechanics: An Accessible Introduction
degenerate. These energy levels are
s = 1, ms = ±1, E =
g
2
n
e
2ℏ
2
8m2
na
3
(−1)
s = 0, ms = 0, E = 0
s = 1, ms = 0, E =
g
2
n
e
2ℏ
2
8m2
na
3
(2)
The dipole-dipole interaction between the proton and electron is the
basis for hyperfine splitting in hydrogen, which is discussed in more detail
in Chapter 9.
8.8 Measurement Theory
Consider a particle in a one-dimensional infinite square well of width a
centered at the origin. If the particle is in the ground state, then the time￾dependent wave function can be written as
Ψ(x, t) = r
2
a
cos πx
a

e
−iEt/ℏ
Rewriting the spatial part of the wave function as a sum of complex expo￾nentials, the full wave function is
Ψ(x, t) = r
1
2a
e
i(πx/a−Et/ℏ) +
r
1
2a
e
−i(πx/a+Et/ℏ)
(8.40)
This wave function looks like the superposition of two waves moving in
opposite directions. However, the particle, when observed, can obviously
only be moving in a single direction. Suppose that a measurement is made
of the direction of motion of the particle, and assume, for instance, that
the particle is found to be moving to the right. Then the wave function
becomes
Ψ(x, t) = e
i(πx/a−Et/ℏ)
(8.41)
Thus, the act of making a measurement alters the wave function, collaps￾ing it from the form given by Equation (8.40) to the form given by Equa￾tion (8.41); the wave function changes from a superposition of states into
a single state.
The idea that the particle is in an indeterminate superposition of states,
and is only forced into a single definite state by the act of measurement
is called the “Copenhagen interpretation,” and it is the most widely-heldSpin angular momentum 209
view of the nature of measurement in quantum mechanics. However,
this interpretation has some disturbing consequences. Consider, for ex￾ample, a set of two particles, each with spin 1/2, that is in the singlet
state (e.g., as in Example 8.4). If the z component of the spin of the
first particle is measured and found to be +1/2, then the second parti￾cle must have z component of spin equal to −1/2, since m1s + m2s =
ms = 0. Thus, the final wave function in this case is | ↑ ↓⟩. The act of
measuring the individual spins of the particles alters the wave function from
√
1
2
| ↓ ↑⟩ − √
1
2
| ↑ ↓⟩ to | ↑ ↓⟩. This is called the “collapse of the wave func￾tion.” Before the measurement is made, the particles have the potential to
be in either the | ↑ ↓⟩ state or the | ↓ ↑⟩ state, but they are not actually
in either state. The act of measuring the spin of one particle collapses the
wave function into one of these two states.
Now consider the following thought experiment. Two electrons are pre￾pared in a singlet state. Without either spin being measured, one electron
is left on earth while the second is transported to Alpha Centauri. A sci￾entist on earth measures the spin of the first electron and finds it to be
in the spin up state. Immediately following this measurement, a scientist
orbiting Alpha Centauri measures the spin of the second electron and, of
course, finds it to be in the spin down state.
This may not seem particularly remarkable. For example, if we began
with a white marble and a black marble, then we leave one on Earth and
transported the second one to a nearby star, the discovery that the marble
left on earth was white would immediately indicate that the other marble
must be black. The quantum mechanical situation is more subtle, however.
Strictly speaking, the two electron spins remain in a linear superposition of
the | ↑ ↓⟩ and | ↓ ↑⟩ states until one of the spins is measured. The scientist on
earth collapses the wave function by measuring the spin of the first electron,
and somehow the second electron, 4 light-years away, immediately “knows”
to assume the opposite spin state! This rather strange result is a version of
the Einstein–Rosen–Podolsky paradox.
As an even more extreme case, consider the example of “Schr¨odinger’s
cat.” A cat is inside a closed box (Figure 8.10). A radioactive substance
is decaying; if a decay occurs in a fixed time interval, poison gas will be
released into the box killing the cat. On the other hand, if no decay oc￾curs in the given time interval, the cat will remain alive. What does the
Copenhagen interpretation say about the state of the cat at any given time?
Before we open up the box to check on the cat, it can be treated as the210 Quantum Mechanics: An Accessible Introduction
Dead!
Alive!
Cat
Radioactive
trigger
Poison
Fig. 8.10 The unfortunate Schr¨odinger’s cat.
superposition of two states, |ψalive⟩ and |ψdead⟩, and we can write
|ψcat⟩ =
1
√
2
|ψalive⟩ +
1
√
2
|ψdead⟩
Now we open up the box, and our act of observing collapses the wave
function. If the cat is dead, for example, we find
|ψcat⟩ = |ψdead⟩Spin angular momentum 211
The state of the cat prior to our observation, however, seems absurd. How
can the cat be in a linear superposition of “alive” and “dead?” This seems
like a very unsatisfying state of affairs. In fact, the entire Copenhagen
interpretation represents a rather substantial shift in the way physicists
had viewed the nature of measurement, so other interpretations have been
put forward.
Hidden Variables
An alternative way of framing quantum mechanics is to assume that it
only seems like a probabilistic theory because it represents an approxima￾tion to a deeper, deterministic theory. This point of view is perhaps the
most conservative, since it assumes that the more bizarre aspects of quan￾tum mechanics are due only to our ignorance of the true underlying theory.
There are certainly precedents for this idea in other areas of physics. Sup￾pose, for instance, that several measurements are made of the speed v of
molecules in a sample of gas. This distribution of speeds would appear
to be random, and a large enough set of measurements would uncover a
probability distribution P(v) for the molecular speeds, given by
P(v) = 4π
 m
2πkT
3/2
v
2
e
−mv2/2kT
called the Maxwell distribution. One might be tempted to conclude that
the motion of the gas molecules is completely random, and the only thing
measurable is the probability distribution.
In fact, of course, this is not the case. The molecules follow trajectories
that are completely determined by classical mechanics. The motion only
seems random because of the enormous number of molecules involved. This
is the fundamental idea of statistical mechanics: there exist deterministic
systems which are so large that an exact calculation of all of the trajectories
is impractical; the best that can be done is to describe the system in terms
of probabilities.
In the same way, we can postulate that quantum mechanics is actu￾ally deterministic, and only our ignorance makes it appear random. This
is the hidden variables formulation of quantum mechanics. Unfortunately
for those dissatisfied with the Copenhagen interpretation, hidden variables
models face serious difficulties. In particular, J.S. Bell showed in 1964 that
hidden variables models can be tested experimentally. By considering ex￾periments of the sort discussed in the previous section, in which particles
with a known total angular momentum are allowed to fly apart and the212 Quantum Mechanics: An Accessible Introduction
individual spins are then measured, Bell showed that the Copenhagen in￾terpretation and the hidden variables interpretation give different results.
Experiments based on Bell’s idea have subsequently shown that it is the
hidden variables model, not the Copenhagen interpretation, which is in￾compatible with the observed behavior of such particles.
There is one loophole here: Bell’s theoretical work, as well as the sub￾sequent experimental investigations, apply only to so-called local hidden
variables models. These are models in which information propagates at a
finite speed, e.g., a speed at or below the speed of light. If information can
propagate instantaneously from one point to another, then hidden variables
theories can still be made compatible with experiment. However, this pos￾sibility seems even more outlandish than the bizarreness of the Copenhagen
interpretation, so it is normally not considered seriously.
The Many Worlds Interpretation of Quantum Mechanics
In 1957 Hugh Everett proposed another way to avoid the problem of the
collapse of the wave function: suppose that it never really collapses! Con￾sider, for example, a particle in the one-dimensional potential well discussed
in the previous section. Suppose that when you measure the direction of
the particle, the wave function doesn’t collapse; instead, the act of mea￾surement splits the universe into two separate worlds: in one world the
particle is observed to be moving to the left, and in the other world it is
moving to the right. This is called the many worlds interpretation of quan￾tum mechanics. In this interpretation, the wave function never collapses.
Instead, the universe is constantly branching into multiple worlds; any pos￾sible outcome of a quantum measurement happens in one of the resulting
worlds. So, for example, Schr¨odinger’s cat is alive in one world and dead
in another (Figure 8.11). As the quantum mechanics instructor of this au￾thor once said, “Strangely enough, there are grown men who believe this.”
(P.J.E. Peebles, Princeton University, 1979).
PROBLEMS
8.1 (a) A particle with spin 1 has orbital angular momentum l = 0.
What are the possible values for the total angular momentum quan￾tum number j?
(b) The same particle has l = 3. What are the possible values
for j?Spin angular momentum 213
Live cat Dead cat
Fig. 8.11 In the many-worlds interpretation, every measurement causes the universe to
branch into multiple worlds; each possible outcome of the measurement occurs in one of
the worlds.
8.2 (a) A particle has spin 3/2 and orbital angular momentum l =
1. What are the possible values for the total angular momentum
quantum number j?
(b) For each value of j in part (a), determine the possible values
of mj .
8.3 Determine (using the matrix representation) which of the following
operators are Hermitian and which are not: Sx, Sy, Sz, S+, S−.
8.4 Derive the eigenvalues and the corresponding normalized eigenvec￾tors of Sy given in Equations (8.26) and (8.27).
8.5 A particle has spin 1, so that ms = −1, 0, or 1. Derive the matrices
which correspond to Sx, Sy, and Sz.
8.6 (a) A particle has s = 3/2. The operator S++ is defined to be the
square of the raising operator: S++ = (S+)
2
, where S+ is the usual214 Quantum Mechanics: An Accessible Introduction
raising operator:
S+|s ms⟩ = ℏ
p
s(s + 1) − ms(ms + 1)|s ms + 1⟩
Derive the matrix corresponding to the operator S++.
(b) What is the matrix corresponding to the adjoint operator
(S++)
†
?
8.7 Let the operator Q be given by Q = S+S−, where S+ and S− are
the usual raising and lowering operators:
S−|s ms⟩ = ℏ
p
s(s + 1) − ms(ms − 1)|s ms − 1⟩
S+|s ms⟩ = ℏ
p
s(s + 1) − ms(ms + 1)|s ms + 1⟩
Derive the matrix corresponding to the operator Q for a spin 1
particle. Determine whether or not Q is Hermitian.
8.8 Using the matrix representation of the spin operators for s = 1/2,
verify the results for [Sx, Sy], [Sy, Sz], and [Sz, Sx] given in Equa￾tions (8.1)–(8.3).
8.9 A large number of spin-1/2 particles are run through a Stern–
Gerlach machine. When they emerge, all of the particles have the
same spin wave function 
ψ1
ψ2

(in the usual basis in which 
1
0

represents spin in the +z direction, and 
0
1

represents spin in
the −z direction). The spin of these particles is measured in the
z direction. On average, 9/25 of the particles have spin in the +z
direction, and 16/25 have spin in the −z direction.
(a) Determine a possible normalized spin wave function 
ψ1
ψ2

.
(b) Is there a single unique solution to part (a), a finite number
of different solutions, or an infinite number of different solutions?
(Multiplying the entire wave vector by a constant does not count
as a different solution.)
8.10 A Stern–Gerlach experiment is set up with the axis of the inhomo￾geneous magnetic field in the x-y plane, at an angle θ relative to
the x-axis. Call this direction r:Spin angular momentum 215
y
x
r
u
The spin operator in the r direction is
Sr = (cos θ)Sx + (sin θ)Sy
(a) For a spin-1/2 particle, calculate the matrix corresponding to
Sr. Calculate the eigenvalues and corresponding eigenvectors. Nor￾malize the eigenvectors and express them in the form a| ↑⟩ + b| ↓⟩,
where a and b are constants.
(b) Suppose a measurement of the spin of the particle in the r
direction is made and it is determined that the spin is in the positive
r direction, i.e., Sr|ψ⟩ = (+ℏ/2)|ψ⟩. Now a second measurement
is made to determine msx (the component of the spin in the x
direction). What is the probability that msx = −1/2? Suppose
that instead of measuring msx, the z component of the spin ms is
measured. What is the probability that ms = +1/2?
(c) Suppose that the particle has spin in the positive r direction
as in part (b). The z component of the spin is measured and it is
discovered that ms = +1/2. Now a third measurement is made to
determine msx. What is the probability that msx = −1/2?
8.11 A spin-1/2 particle is in the state |ψ⟩ =
p
2/3| ↑⟩ + i
p
1/3| ↓⟩.
(a) Verify that the wave function is correctly normalized.
(b) A measurement is made of the x component of the spin. What
is the probability that the spin will be in the −x direction?
(c) Suppose a measurement is made of the spin in the z direction
and it is discovered that the particle has ms = −1/2. Now a second
measurement is made to determine the spin in the x direction.
What is the probability that the spin will be in the +x direction?
8.12 An electron is precessing in a magnetic field. The wave function
for the electron is
|ψ⟩ =
1
√
2

cos ωt + sin ωt
cos ωt − sin ωt216 Quantum Mechanics: An Accessible Introduction
(a) Describe the plane of rotation of the spin of this particle.
(b) In what direction is it rotating in this plane?
8.13 A magnetic field pointing in the −z direction produces a Hamil￾tonian H = −ωSz, where ω is a constant with units of frequency.
A spin-1/2 particle is placed in this magnetic field. At t = 0, the
particle is pointing in the +y direction.
(a) Derive an expression for the spin vector 
ψ1
ψ2

as a function of
time.
(b) At t = π/ω, a measurement is made of the spin in the x direc￾tion. What is the probability that the spin is in the +x direction?
(c) Suppose that at t = π/ω, a measurement is made of the spin in
the x direction, and it is found that the spin is in the +x direction.
Then at the time t = 2π/ω, another measurement is made of the
spin in the x direction. What is the probability that the spin is in
the +x direction?
8.14 An electron is precessing in a magnetic field aligned along the +z￾axis. At t = 0, the spin of the electron is in the positive x direction.
The wave function is
|ψ⟩ =
1
√
2

e
−iωt/2
e
iωt/2

For t > 0, calculate the probability of finding the electron in the
state
(a) ms = +ℏ/2
(b) msx = +ℏ/2, where msx is the component of spin in the x
direction.
8.15 A spin-1/2 particle is placed in a magnetic field pointing in the +x
direction which produces a Hamiltonian H = ωSx, where ω is a
constant with units of frequency. At t = 0, the particle is pointing
in the +z direction. Derive an expression for the spin vector 
ψ1
ψ2

as a function of time.
8.16 A magnetic field pointing in the +z direction produces a Hamil￾tonian H = ωSz, where ω is a constant with units of frequency.
A spin-1 particle is placed in this magnetic field. The matrixSpin angular momentum 217
corresponding to Sz for a spin-1 particle is
Sz = ℏ


1 0 0
0 0 0
0 0 −1


At t = 0, the particle is pointing in the +x direction with normal￾ized spin vector
|ψ⟩ =


1/2
1/
√
2
1/2


Derive an expression for the spin vector


ψ1
ψ2
ψ3

 as a function of
time.
8.17 Consider a system of two particles: particle 1 has spin 1, and par￾ticle 2 has spin 1/2. Let S be the total spin angular momentum
operator for the two particles, where the eigenvalues of S
2 and Sz
are ℏ
2
s(s + 1) and ℏms, respectively. The particles are in the state
s = 3/2 and ms = 1/2.
(a) Calculate the wave function |s = 3/2 ms = 1/2⟩ as a linear
combination of the wave functions |m1s m2s⟩, where m1s is the z
component of the spin of particle 1, and m2s is the z component
of the spin of particle 2.
(b) Find the probabilities that the z component of the spin of
particle 1 is
(i) m1s = +1
(ii) m1s = 0
(iii) m1s = −1
8.18 Suppose that particle 1 (with spin 1) and particle 2 (with spin 1/2)
interact via the Hamiltonian operator
H = λS1·S2
where λ is a constant. Calculate the energy of the state |s ms⟩.
8.19 Two spin-1/2 particles are fixed in space with the Hamiltonian
H = aS2
z + bS2218 Quantum Mechanics: An Accessible Introduction
where a and b are positive constants, and as usual, S
2
is the total
spin operator squared and Sz is the operator which gives the z
component of the total spin. What are the energy levels of this
system?Chapter 9
Time-independent perturbation
theory
In theory, the Schr¨odinger equation allows us to solve any quantum me￾chanical system exactly. We simply insert the potential V and solve for
the wave function ψ and the energy E. Unfortunately, there are very few
potentials, such as the infinite square well or the Coulomb potential of
the hydrogen atom, for which a simple exact solution exists. In order to
make any further progress, we need to develop some techniques for find￾ing approximate solutions to the Schr¨odinger equation. This chapter and
Chapter 11 are devoted to a very important set of these techniques called
perturbation theory.
The basic idea of perturbation theory rests on a simple general ar￾gument. Suppose we begin with a potential for which we can solve the
Schr¨odinger equation exactly, such as the infinite square well of width a;
recall from Chapter 4 that the ground-state energy and wave function are
given by ψ =
p
2/a sin(πx/a) and E = ℏ
2π
2/2ma2
. Now suppose we make
a tiny change in V such as a small notch in the center of the potential
(Figure 9.1). We cannot solve the Schr¨odinger equation for this new po￾tential, but intuition suggests that a small change in V ought to produce
a small change in ψ and in E. This intuition is correct. The reason is
that the Schr¨odinger equation is a special kind of differential equation: it
is linear , i.e., ψ and its derivatives are taken only to the first power. Linear
differential equations like the Schr¨odinger equation have the property that
small changes in the parameters produce small changes in the solution. The
fact that a small change in V produces a small change in ψ and E is the
fundamental idea of perturbation theory.
219220 Quantum Mechanics: An Accessible Introduction
0 a
c
E
0 a
c'
E'
Fig. 9.1 The infinite square well on the left has the ground-state wave function and
energy ψ =
p
2/a sin(πx/a) and E = ℏ
2π
2/2ma2
. A small change in the potential,
shown on the right, produces a small change in ψ and E.
9.1 Derivation of Time-Independent Perturbation Theory
Now we will calculate mathematically the change in E produced by an
arbitrary small change in the Hamiltonian H. [Although we talk generically
about a change in the Hamiltonian, this usually amounts to a change in
the potential.] Assume we have a Hamiltonian H for which we can solve
the Schr¨odinger equation exactly. We need to consider two possibilities for
a small change in H: either the change in H is constant in time, or it
varies as a function of time. If the change in H is constant in time, we are
dealing with time-independent perturbation theory, which is the subject of
this chapter. If, on the other hand, the change in H varies with time, we
have time-dependent perturbation theory, which is discussed in Chapter 11.
We will now derive what happens if we have a small, time-independent
change in the Hamiltonian. Assume that we have a Hamiltonian H0, for
which we can find all of the eigenstates |ψn⟩ with energies En:
H0|ψn⟩ = En|ψn⟩
Note that this is just shorthand for an infinite set of equations: H0|ψ1⟩ =
E1|ψ1⟩, H0|ψ2⟩ = E2|ψ2⟩, and so on. For example, the |ψn⟩ could corre￾spond to the hydrogen wave functions, the spin eigenfunctions of an electron
in a magnetic field, or any other set of wave functions that are exact solu￾tions of the Schr¨odinger equation. Now add a small perturbation λH′
to
the Hamiltonian:
H = H0 + λH′
(9.1)
Here λ is taken to be a dimensionless small number, λ ≪ 1, so that the
perturbation λH′
is small compared to the original Hamiltonian H0. We
would like to solve the new Schr¨odinger equation:
H|ψ⟩ = E|ψ⟩ (9.2)Time-independent perturbation theory 221
In this equation H is the new (perturbed) Hamiltonian of Equation (9.1),
|ψ⟩ is the new wave function after we have added the perturbation to the
Hamiltonian, and E is the new energy. Of course, we cannot solve this
equation exactly (or we wouldn’t be bothering to develop perturbation the￾ory), but we can use some mathematical techniques to see how the change
in the Hamiltonian changes the wave functions and energies.
The first step is to write the new energy and wave function in Equa￾tion (9.2) as a power series in the small number λ that appears in Equa￾tion (9.1):
E = En + λE[1] + λ
2E
[2] + · · · (9.3)
|ψ⟩ = |ψn⟩ + λ|ϕ1⟩ + λ
2
|ϕ2⟩ + · · · (9.4)
In these equations, |ψn⟩ and En are the original eigenfunction and energy
before we apply the perturbation; since Equation (9.2) has an infinite num￾ber of solutions (corresponding to a small perturbation applied to any of
the eigenfunctions of H0) we have to pick a particular eigenfunction |ψn⟩
to perturb. The energies E[1]
, E[2]
, . . . and the wave functions |ϕ1⟩, |ϕ2⟩
are unknown; our goal is to solve for them.
Recall that we are interested in the small change in E which results from
our small change λH′
in the Hamiltonian. The first term in Equation (9.3)
gives us the energy before we apply the small perturbation. The rest of the
terms give us the small change in the energy due to the small change in H.
But if λ is tiny, only the first of these terms really matters. For instance,
if we take λ = 10−6
, then λ
2 = 10−12
, λ
3 = 10−18, and so on. So the third
term in Equation (9.3) is tiny compared to the second term, and the fourth
term is tiny compared to the third term. That means the change in E is
essentially λE[1], and we can ignore all of the other terms in Equation (9.3).
[Exception: if, for a particular perturbation, λE[1] is exactly zero, we will
have to go further and solve for λ
2E[2].]
Substituting the expressions for E and |ψ⟩ from Equations (9.3) and
(9.4) into the Schr¨odinger equation given by Equation (9.2) gives the fol￾lowing rather messy result:
(H0 + λH′
)(|ψn⟩ + λ|ϕ1⟩ + λ
2
|ϕ2⟩ + · · ·)
= (En + λE[1] + λ
2E
[2] + · · ·)(|ψn⟩ + λ|ϕ1⟩ + λ
2
|ϕ2⟩ + · · ·)
(9.5)
Although it looks like this is only making matters worse, we can now apply
two ideas to simplify this equation. First, recall that if λ is small, then λ is
much larger than λ
2
, which is much larger then λ
3
, and so on. This means222 Quantum Mechanics: An Accessible Introduction
that for very small λ, the terms in Equation (9.5) with different powers of
λ do not affect each other, so Equation (9.5) must be satisfied separately
for each individual power of λ. Equating powers of λ in this equation gives
λ
0 H0|ψn⟩ = En|ψn⟩ (9.6)
λ
1 λH′
|ψn⟩ + λH0|ϕ1⟩ = λEn|ϕ1⟩ + λE[1]|ψn⟩ (9.7)
λ
2 λ
2H0|ϕ2⟩ + λ
2H′
|ϕ1⟩ = λ
2E
[1]|ϕ1⟩ + λ
2E
[2]|ψn⟩ + λ
2En|ϕ2⟩ (9.8)
Equation (9.6) is just the original unperturbed Schr¨odinger equation, which
is reassuring, but we cannot make further progress with Equations (9.7)
and (9.8) unless we know what happens when H0 operates on |ϕ1⟩ and
|ϕ2⟩. However, we don’t even know what |ϕ1⟩ and |ϕ2⟩ are! Nonetheless,
we can solve this problem by applying a second idea. Recall that for any
Hamiltonian H0, we can find a set of eigenfunctions |ψm⟩ which form an
orthonormal basis, i.e., any wave function |ψ⟩ can be written as
|ψ⟩ = c1|ψ1⟩ + c2|ψ2⟩ + · · · + cm|ψm⟩ + · · ·
So even though we don’t know |ϕ1⟩ and |ϕ2⟩ in Equations (9.7) and (9.8),
we can expand them out as linear combinations of eigenfunctions of H0,
and we do know what happens when we apply H0 to these eigenfunctions.
We write
|ϕ1⟩ = c1|ψ1⟩ + c2|ψ2⟩ + · · · + cm|ψm⟩ + · · · =
X
i
ci
|ψi⟩ (9.9)
and
|ϕ2⟩ =
X
i
di
|ψi⟩ (9.10)
Then when H0 is applied to the sums in Equations (9.9) and (9.10), it
simply pulls out the appropriate energy in front of each term:
H0|ϕ1⟩ = H0
 X
i
ci
|ψi⟩
!
=
X
i
Eici
|ψi⟩ (9.11)
and
H0|ϕ2⟩ =
X
i
Eidi
|ψi⟩ (9.12)
When H0 is applied to |ϕ1⟩ in Equation (9.7), it produces the sum given in
Equation (9.11). Then we get
λH′
|ψn⟩ + λ
X
i
Eici
|ψi⟩ = λEn
X
i
ci
|ψi⟩ + λE[1]|ψn⟩ (9.13)Time-independent perturbation theory 223
We would like to solve this equation to find E[1]. We take the inner product
of ⟨ψn| with both sides of the equation, recalling that ⟨ψn|ψn⟩ = 1:
λ⟨ψn|H′
|ψn⟩ + λ
X
i
Eici⟨ψn|ψi⟩ = λEn
X
i
ci⟨ψn|ψi⟩ + λE[1] (9.14)
Note that |ψn⟩ is the original eigenfunction which satisfies the unperturbed
Schr¨odinger equation, while the |ψi⟩’s are the complete set of such eigen￾functions, including |ψn⟩ as a particular case. Hence, when we take the
inner product of ⟨ψn| with |ψi⟩, we get zero for i ̸= n and one for i = n.
This selects out i = n from the sum in Equation (9.14), giving
λ⟨ψn|H′
|ψn⟩ + λEncn = λEncn + λE[1]
so
λE[1] = ⟨ψn|λH′
|ψn⟩ (9.15)
where λE[1] is the dominant or lowest order (i.e., lowest power of λ) change
in the energy due to the small change λH′
in the Hamiltonian.
We can now calculate the second-order change in E, i.e., the term in
Equation (9.3) which is proportional to λ
2
. Of course, it is reasonable
to ask why we would ever want to know this, since λE[1] is much larger
than λ
2E[2]. Normally, the second order perturbation is irrelevant except
for one very important case: if λE[1] is exactly zero, then λ
2E[2] gives
the dominant change in the energy. To find λ
2E[2], we substitute both
Equations (9.9) and (9.10) into Equation (9.8). When H0 operates on the
sum of eigenvectors as in Equation (9.12), we get
λ
2X
i
diEi
|ψi⟩ + λ
2H′X
i
ci
|ψi⟩
= λ
2E
[1]X
i
ci
|ψi⟩ + λ
2E
[2]|ψn⟩ + λ
2En
X
i
di
|ψi⟩
As before, we take the inner product with ⟨ψn|, and now we substitute
⟨ψn|H′
|ψn⟩ for E[1]. Solving for λ
2E[2], we get
λ
2E
[2] = λ
2X
i
ci⟨ψn|H′
|ψi⟩ − λ
2
cn⟨ψn|H′
|ψn⟩
The right-hand side is the sum over all eigenfunctions |ψi⟩ minus the par￾ticular eigenfunction |ψn⟩, so it can be written as
λ
2E
[2] = λ
2X
i̸=n
ci⟨ψn|H′
|ψi⟩ (9.16)224 Quantum Mechanics: An Accessible Introduction
Now all we have to do is to find the coefficients ci which first appeared
in Equation (9.9). We go back to Equation (9.13), but now instead of
applying ⟨ψn| to both sides, we apply an arbitrary eigenfunction ⟨ψm|,
where ⟨ψm| ̸= ⟨ψn|. This gives
λ⟨ψm|H′
|ψn⟩ + λEmcm = λEncm + 0
so that
cm =
⟨ψm|H′
|ψn⟩
En − Em
(9.17)
Substituting this expression for the ci
’s in Equation (9.16) gives the final
expression for λ
2E[2]:
λ
2E
[2] =
X
i̸=n
⟨ψn|λH′
|ψi⟩⟨ψi
|λH′
|ψn⟩
En − Ei
=
X
i̸=n
|⟨ψn|λH′
|ψi⟩|2
En − Ei
(9.18)
To summarize: if we start out with some Hamiltonian H0 for which we
can solve the Schr¨odinger equation exactly, and we begin in an eigenstate
|ψn⟩ with energy En, then after we change the Hamiltonian by the small
amount λH′
, the dominant change in the energy, proportional to λ, will
be given by Equation (9.15), while the next largest change, proportional to
λ
2
, will be given by Equation (9.18).
While we have used λ to remember which terms are larger than others,
we can now simplify our expressions by writing the change in H as
H = H0 + H1
where
H1 = λH′
is very small compared to the unperturbed Hamiltonian H0. Then we write
the first and second order changes in the energy as
E
(1) = λE[1]
and
E
(2) = λ
2E
[2]
These changes in the energy are given by
E
(1) = ⟨ψn|H1|ψn⟩ (9.19)Time-independent perturbation theory 225
and
E
(2) =
X
i̸=n
|⟨ψn|H1|ψi⟩|2
En − Ei
(9.20)
where the |ψi⟩’s which appear in Equation (9.20) are all of the other eigen￾functions of H0 aside from the one being perturbed. Equations (9.19) and
(9.20) are the main result of this section; they give the first-order and
second-order perturbations to the energy from an arbitrary perturbation
to the Hamiltonian. As usual, the inner products which appear in Equa￾tions (9.19) and (9.20) can represent a variety of different mathematical
possibilities. If the wave functions and the perturbation are functions of
position (as in Example 9.1), then these inner products will be integrals.
If the eigenstates are spin states and the perturbation is a function of spin
operators (as in Example 9.2), then these inner products will be matrix
products.
There is one case in which the entire argument falls apart. If the original
eigenfunction |ψn⟩ is degenerate with some other eigenfunction |ψm⟩ of H0,
i.e., En = Em, then the argument fails. This can be seen from the fact that
both Equations (9.17) and (9.20) “blow up” in this case with zero in the
denominator. Note that Equation (9.19) might be completely well behaved
in this case, and it is a very common mistake to use Equation (9.19) in the
case of this kind of degeneracy. DON’T DO IT! Since the second-order
term in this case is infinite, the entire perturbation expansion becomes
inapplicable for the case of degeneracy. Perturbation theory applied to
degenerate eigenfunctions requires some further mathematical machinery
(degenerate perturbation theory) which is beyond the scope of this text.
Note, however, that there is one special case (which we will encounter
frequently) in which we can use Equations (9.19) and (9.20) with degenerate
wave functions: if ⟨ψn|H1|ψi⟩ = 0 whenever En = Ei
, then our expressions
will be well behaved.
Although the change in the energy is usually the quantity that can be
most easily measured directly, it is also possible to calculate the change in
the wave function due to the perturbation. Returning to Equation (9.4),
we see that the lowest-order change to |ψn⟩ is given by λ|ϕ1⟩, and |ϕ1⟩ has
already been expressed as a sum over the unperturbed eigenfunctions in
Equation (9.9) with the ci
’s that appear in this equation given by Equa￾tion (9.17). Substituting these values for the ci
’s from Equation (9.17) into226 Quantum Mechanics: An Accessible Introduction
Equation (9.9), we obtain
λ|ϕ1⟩ =
X
i̸=n
⟨ψi
|λH′
|ψn⟩
En − Ei
|ψi⟩
=
X
i̸=n
⟨ψi
|H1|ψn⟩
En − Ei
|ψi⟩
Note that we have dropped the i = n term from the sum in Equation (9.9).
We have the freedom to do this because this term is just proportional to the
original unperturbed eigenfunction |ψn⟩. Hence, in the original expansion
of the wave function (Equation (9.4)), this term can be removed from the
λ|ϕ1⟩ term and absorbed into the |ψn⟩ term. Then to first order, the new
wave function in the presence of the perturbation is
|ψ⟩ = |ψn⟩ +
X
i̸=n
⟨ψi
|H1|ψn⟩
En − Ei
|ψi⟩
Thus, the effect of the perturbation is to “mix together” all of the other
eigenfunctions in the new perturbed wave function.
Example 9.1. The Anharmonic Oscillator
In Chapter 4, we derived the solutions for the one-dimensional harmonic
oscillator potential,
V (x) = 1
2
Kx2
The energies are
E =

n +
1
2

ℏω, n = 0, 1, . . .
where ω =
p
K/m is the classical oscillation frequency, and the correspond￾ing wave functions are
ψ0(s) = 1
π
1/4
e
−s
2/2
ψ1(s) =
√
2
π
1/4
se−s
2/2
.
.
.
with s = [(Km)
1/4/ℏ
1/2
]x.Time-independent perturbation theory 227
V(x)
x
Fig. 9.2 Solid curve: the unperturbed harmonic oscillator potential V = (1/2)Kx2
.
Dashed curve: the perturbed potential V = (1/2)Kx2 + βx4
.
Suppose we begin in the first excited state ψ1 with energy E = (3/2)ℏω.
We will calculate what happens to the energy of this state if we add a small
anharmonic term to the potential (Figure 9.2):
V (x) = 1
2
Kx2 + βx4
From Equation (9.19), the first-order perturbation is
E
(1) = ⟨n = 1|βx4
|n = 1⟩
Expressing the perturbation in terms of s, we get
E(1) =
Z ∞
s=−∞ " √
2
π
1/4
se−s
2/2
#∗ 
β
ℏ
2
Km
s
4

" √
2
π
1/4
se−s
2/2
#
ds
=
2
√
π
β
ℏ
2
Km Z ∞
s=−∞
s
6
e
−s
2
ds
=
15
4
β
ℏ
2
Km
With ω =
p
K/m, the total energy including the perturbation is
E = ℏω

3
2
+
15
4
β
ℏω
K2
228 Quantum Mechanics: An Accessible Introduction
Bz
z
Bx
xˆ
ˆ
Fig. 9.3 We begin with an electron in the spin up direction in the magnetic field Bzzˆ,
and we add the small perturbation Bxxˆ.
Example 9.1 shows how to apply perturbation theory when the wave
function is a function of position. However, perturbation theory can also
be applied to the matrix representation of spin states.
Example 9.2. Spins in a Magnetic Field
Suppose we begin with an electron having spin magnetic moment µs
in
a strong magnetic field Bz in the z direction (Figure 9.3). Recall from
Chapter 8 that the potential for an electron with spin magnetic moment
µs
in a magnetic field B is
V = −µs
·B
where
µs = −
gSµB
ℏ
S
Hence, the Hamiltonian is
H0 =
gSµB
ℏ
B·S
=
gS
2
µBB·σ
and gs = 2 for the electron. The eigenstates of H0 are just the spin up
and spin down states, | ↑ ⟩ and | ↓ ⟩, with energies E+ = +µBBz and
E− = −µBBz.
Suppose we are in the spin up state, | ↑ ⟩, and we add the small magnetic
field Bxxˆ with Bx ≪ Bz (Figure 9.3). What is the change in the energy of
the electron due to this new magnetic field? Our perturbing potential is
V1 =
gS
2
µBBxσxTime-independent perturbation theory 229
with gs = 2, the first-order change in the energy is
E(1) = ⟨ψn|H1|ψn⟩
= ⟨ ↑ |µBBxσx| ↑ ⟩
= µBBx
￾
1 0

0 1
1 0 1
0

= µBBx
￾
1 0

0
1

= 0
So the first-order perturbation, proportional to Bx, is equal to zero. The
second-order perturbation is
E(2) =
X
i̸=n
|⟨ψn|H1|ψi⟩|2
En − Ei
=
|⟨ ↑ |µBBxσx| ↓ ⟩|2
E+ − E−
=
[µBBx]
2
2µBBz





1
0
 0 1
1 0 0
1




2
=
µBB2
x
2Bz
As expected, E(2) is proportional to B2
x
. In fact, this problem can be
solved exactly, and it is instructive to see how the exact solution compares
with the perturbation theory result (see Problem 9.1).
9.2 Perturbations to the Atomic Energy Levels
In Chapter 6 we developed an elegant model for the hydrogen atom. The
energy levels were determined by the principal quantum number n, while
the other quantum numbers l, ml
, and ms had no effect on the energy. As
is often the case in physics, the elegant theory is extremely accurate, but
it is not exact. There are small corrections to the theory due to internal
interactions in the hydrogen atom. With perturbation theory, we now have
the tools to derive these corrections.
Fine Structure
Recall that for hydrogen, the energy is given by
En = (−13.6 eV) 1
230 Quantum Mechanics: An Accessible Introduction
En1
En2
Fig. 9.4 A given spectral line corresponds to a single transition between two different
energy levels. If two supposedly degenerate levels are slightly separated in energy, a
double line will be produced.
In hot hydrogen gas, a series of spectral lines are observed, each one corre￾sponding to a particular transition with hν = En1 − En2
. However, upon
examining the spectrum closely, it is observed that some spectral lines are
not really single lines but are closely spaced double lines. This feature is
called fine structure. There is an obvious way to get such closely spaced
spectral lines: they will be observed if the degenerate energy levels are
not truly degenerate but separated in energy by a very small amount (Fig￾ure 9.4). Recall that a given energy level En corresponds to 2n
2 different
states. Apparently, some sort of interaction, which we have not yet ac￾counted for, splits some of these states apart in energy.
Our simple model for the hydrogen atom considered only the Coulomb
interaction between the proton and the electron. What we have neglected
are the various magnetic fields produced in the atom. The orbital motion
of the electron sets up a magnetic field with magnetic moment given by
µl = −
gle
2me
L, gl = 1 (9.21)
while the spin of the electron produces a spin magnetic moment equal to
µs = −
gse
2me
S, gs ≈ 2
So the orbital motion of the electron produces a magnetic field, and the
electron itself acts like a small magnet embedded in this magnetic field
(Figure 9.5). The electron will prefer to line up with its spin magnetic field
in the opposite direction to the orbital magnetic field. Hence, the “spin up”
and “spin down” states of the electron will have different energies. This
is the basis of fine structure: it arises from the spin-orbit coupling of the
electron.
More precisely, the interaction energy between the spin magnetic mo￾ment µs and the external magnetic field B (produced by the orbital motion
of the electron) is
H1 = −µs
·B (9.22)Time-independent perturbation theory 231
ms
+ Borbital –
Fig. 9.5 The fine-structure splitting is produced by the interaction between the spin
magnetic field of the electron and the magnetic field produced by its orbital motion.
To find B imagine that we are sitting in the rest frame of the electron
watching the proton orbit around us. In the rest frame of the electron, the
electric field of the proton,
E =
1
4πϵ0
e
r
3
r
transforms into a magnetic field, B = −v×E/c2
. Using L = r×p, we
obtain, for the magnetic field induced by the orbital motion of the electron,
B =

1
4πϵ0

e
mec
2r
3
L
Substituting our expressions for µs and B into Equation (9.22), we obtain,
for the energy of the spin-orbit interaction,
H1 =
e
2
4πϵ0m2
e
c
2r
3
S·L
Unfortunately, this expression is wrong. The problem arises because we did
the calculation in the rest frame of the electron, which is an accelerating
frame of reference, so we cannot simply transform back into the rest frame of
the proton and expect to get the right answer. When this error is corrected,
an additional factor of 1/2 is obtained (this correction is called Thomas
precession after L.H. Thomas, who explained this effect in 1926). The
corrected expression is
H1 =
e
2
8πϵ0m2
e
c
2r
3
S·L (9.23)
From a classical point of view, this expression makes sense, since we expect
the interaction energy of the two magnetic fields to depend on the alignment
of the S and L vectors (Figure 9.6).
We can get a crude order of magnitude estimate of the size of this
interaction energy by taking S ∼ ℏ, L ∼ ℏ, and r ∼ 10−10 m. Then Equa￾tion (9.23) gives a perturbation energy of the order of 10−4
eV compared to232 Quantum Mechanics: An Accessible Introduction
u
S
L
+ –
Fig. 9.6 The spin-orbit interaction Hamiltonian is proportional to S·L. Classically,
S·L = SL cos θ.
a hydrogen binding energy of 13.6 eV. It is therefore a good approximation
to treat the spin-orbit interaction as a small perturbation.
In our expression for H1, the interaction is proportional to S·L =
SxLx + SyLy + SzLz. However, this expansion is essentially useless, since
the electron is never in a state which is a simultaneous eigenstate of all three
components of angular momentum. Instead, we use the standard procedure
from Chapter 8 for dealing with dot products of operators. We define the
total angular momentum operator J to be
J = L + S
Then
J
2 = L
2 + S
2 + 2L·S
which implies
L·S =
1
2
(J
2 − L
2 − S
2
)
and the spin-orbit perturbation becomes
H1 =
e
2
16πϵ0m2
e
c
2r
3
(J
2 − L
2 − S
2
)
In Chapter 6 we wrote the hydrogen wave functions in terms of the quan￾tum numbers n, l, and ml
, and in Chapter 8 we added the spin quantumTime-independent perturbation theory 233
number ms, but now we want to express the hydrogen wave functions as
eigenfunctions of J and Jz, i.e., in the form |n l j mj ⟩, where
J
2
|n l j mj ⟩ = ℏ
2
j(j + 1)|n l j mj ⟩
Jz|n l j mj ⟩ = ℏmj |n l j mj ⟩
Then the perturbation to the energy levels due to spin-orbit coupling is
E
(1)
spin-orbit = ⟨n l j mj |H1|n l j mj ⟩
= ⟨n l j mj |
e
2
16πϵ0m2
e
c
2r
3
(J
2 − L
2 − S
2
)|n l j mj ⟩
= ℏ
2
[j(j + 1) − l(l + 1) − s(s + 1)]⟨n l j mj |
e
2
16πϵ0m2
e
c
2r
3
|n l j mj ⟩
What is the value of ⟨n l j mj |(e
2/16πϵ0m2
e
c
2
r
3
)|n l j mj ⟩? Note that this
is just an integral over the radial wave function, which is a function only of
n and l; hence, we can write
⟨n l j mj |(e
2
/16πϵ0m2
e
c
2
r
3
)|n l j mj ⟩ = fnl
where fnl is a function only of n and l. Then our expression for the change
in E due to the spin-orbit interaction (taking s = 1/2 for the electron)
becomes
E
(1)
spin-orbit = ℏ
2
fnl 
j(j + 1) − l(l + 1) −
3
4

(9.24)
From Chapter 9 recall that for l ̸= 0, j has two possible values, either l−
1/2 or l + 1/2, while for l = 0 we have only j = 1/2. From Equation (9.24),
it is clear that the spin-orbit coupling splits each state with l ̸= 0 into two
different states with j = l + 1/2 having the higher energy and j = l − 1/2
having the lower energy.
The expression for fnl can be evaluated to yield a final expression for
the change in E from spin-orbit coupling:
E
(1)
spin-orbit = |En|α
2
1
2n
[j(j + 1) − l(l + 1) − 3/4]
l(l + 1/2)(l + 1) (9.25)
where
α =
e
2
4πϵ0ℏc
Note that α is a dimensionless number with a value of roughly 1/137. Be￾cause of its origin in this calculation, α is called the fine-structure constant,
although it crops up in many other areas of physics. Recall that the hydro￾gen energy levels En are all negative, so we take the absolute value of En234 Quantum Mechanics: An Accessible Introduction
in Equation (9.25) and in Equations (9.28)–(9.29) to avoid any confusion
over the sign of the change in energy.
However, this is not the full story of the fine-structure splitting. We
have applied our standard nonrelativistic treatment to the electron, and
this is an excellent approximation, since the electron in the hydrogen atom
is not highly relativistic (its kinetic energy is much smaller than its rest
energy; classically, this corresponds to an electron velocity v much smaller
than the speed of light). However, now that we are working in the realm
of tiny changes in the energy levels, we have to take into account small
corrections due to relativistic effects.
In relativistic classical mechanics, the total energy of a particle with
rest mass m and momentum p is
E =
p
p
2c
2 + m2c
4 (9.26)
For now we are interested only in the case where the particle is only slightly
relativistic so that p ≪ mc. (We will relax this restriction in Chapter 15
when we discuss relativistic quantum mechanics in more detail.) In this
limit we can expand the square root in Equation (9.26) to obtain
E ≈ mc2 +
p
2
2m
−
p
4
8m3c
2
+ · · · (9.27)
In the limit of small p, each term in this expression is small compared
to the preceding one. In relativity, the first term in Equation (9.27) is
interpreted as the rest energy of the particle, while the remainder of the
expression corresponds to the energy of motion. But what is the correct
energy to use in the Schr¨odinger equation? In the standard nonrelativistic
Schr¨odinger equation, the Hamiltonian operator corresponds to the kinetic
energy plus the potential energy, and the rest energy plays no role. Hence,
in writing the Hamiltonian, we use the second term in Equation (9.27) to
give us the unperturbed Hamilton, while the third term gives the lowest￾order perturbation due to relativistic effects.
Then we have, for our perturbation,
H1 = −
p
4
8m3
e
c
2
and the lowest-order change in the hydrogen energy levels is
E
(1)
relativistic = −
1
8m3
e
c
2
⟨n l j mj |p
4
|n l j mj ⟩
This expression can be evaluated for the hydrogen wave functions, yielding
a final result of
E
(1)
relativistic = −|En|α
2
1
n2

2n
2l + 1
−
3
4

(9.28)Time-independent perturbation theory 235
Since E
(1)
relativistic is a function of n and l but not a function of j, the relativis￾tic correction does not contribute anything to the splitting of the energy
levels, which is determined entirely by the spin-orbit interaction, but it
does change the overall dependence of the energy levels on n and l. Since
l ≤ n − 1, the term in brackets in Equation (9.28) is always positive, so the
relativistic correction always decreases the energy levels.
Note that E
(1)
spin-orbit and E
(1)
relativistic are roughly equal in magnitude;
both of them are approximately α
2En. Hence, neither contribution to the
fine structure can be neglected. We therefore add Equations (9.25) and
(9.28) to get the total change in energy due to both the spin-orbit coupling
and relativistic effects:
E
(1)
fine structure = E
(1)
spin-orbit + E
(1)
relativistic
= |En|α
2
1
n2

3
4
−
n
j + 1/2

(9.29)
The dependence on l has cancelled out, so that the total change in energy is
a function only of j and n. The net effect of the fine structure is to split the
l−1/2 and l+1/2 states (due to the spin-orbit coupling) and to decrease the
energies of both states relative to the unperturbed hydrogen energy levels
(see Problem 9.10). The fine-structure perturbation (both the decrease in
energy relative to the unperturbed energy levels and the splitting between
the j = l + 1/2 and the j = l − 1/2 states) is of order α
2En ≈ 10−4En,
since the other factors in Equation (9.29) are all of order unity.
We now introduce a standard, if somewhat arcane, notation to describe
the angular momentum states of the hydrogen atom. In this notation, the
different l states of the hydrogen atom are written with different capital
letters: the l = 0 state is called the S state, the l = 1 state is called the
P state, the l = 2 state is called the D state, the l = 3 state is called
the F state, and then the sequence continues alphabetically (G, H, I, . . .).
(The origin of these abbreviations is buried in the history of spectroscopy;
there is nothing particularly logical about them.) The standard way of
writing the various j states is to indicate the value of j as a subscript, e.g.,
P1/2 is the notation for l = 1, j = 1/2. [We will see an additional twist to
this notation in Chapter 13.] The different hydrogen energy levels written
in this notation are shown in Figure 9.7. The S states (l = 0) do not split
since they correspond to a single value of j, while the l ̸= 0 states split into
the j = l + 1/2 state and the j = l − 1/2 state, with the former having
higher energy than the latter.236 Quantum Mechanics: An Accessible Introduction
n = 1
n = 2
n = 3
S1/2
l = 0
S1/2
P1/2
P3/2
l = 1
P1/2
P3/2
D5/2
D3/2
l = 2
S1/2
Fig. 9.7 The energy levels of hydrogen showing the fine structure (not drawn to scale).
Sp
Se
+ –
Fig. 9.8 The spin-spin interaction between the proton and electron produces the hy￾perfine splitting.
Finally, note that we have blithely applied first-order perturbation the￾ory to degenerate states, ignoring the warning in the previous section. How￾ever, it is all right to use nondegenerate perturbation theory in this case,
since ⟨n l ml ms|H1|n l′ m′
l m′
s
⟩ = 0 if l ̸= l
′ or ml ̸= m′
l
or ms ̸= m′
s
.
There is a second internal magnetic interaction in the hydrogen atom
with a much smaller effect. The proton has a spin magnetic moment given
by
µp =
gpe
2mp
S (9.30)
with gp ≈ 5.6. So the electron also feels this magnetic field and is per￾turbed by it (Figure 9.8). However, a comparison of Equation (9.30) with
Equation (9.21) shows that the ratio of the spin magnetic field of the pro￾ton to the magnetic field produced by the orbital motion of the electron
is roughly me/mp ≈ 6 × 10−4
. Hence, we expect the splitting from the
spin-spin interaction to be much smaller than the effect of the spin-orbit
interaction.
Nonetheless, this spin-spin interaction does produce a splitting in ener￾gies. Since it is so much smaller than the fine structure, it is called hyperfineTime-independent perturbation theory 237
splitting. In the ground state of hydrogen, for example, the triplet (S = 1)
state has a higher energy than the singlet (S = 0) state; the energy dif￾ference is ∆E = 5.9 × 10−6
eV. Although this energy difference is tiny,
hyperfine splitting has an importance out of proportion to its magnitude.
The universe contains clouds of neutral hydrogen gas; this gas radiates
by dropping from the triplet into the singlet state. The frequency of this
radiation is ν = ∆E/h = 1420 MHz, corresponding to a wavelength of
λ = 21 cm: the famous “21-centimeter line.”
Vacuum Polarization and the Lamb Shift
The fine-structure calculations in the previous section predict that the hy￾drogen energy levels do not depend on l. Hence, two states with the same
n and j quantum numbers but different values of l should be degenerate
in energy. In 1947, Willis Lamb and his student, R.C. Retherford, showed
experimentally that this was not the case. Specifically, they measured a
splitting between the n = 2, S1/2 state and the n = 2, P1/2 state.
This splitting, now called the Lamb shift, cannot be explained in the
context of quantum mechanics, but arises from the more esoteric area of
quantum field theory (which was, in part, motivated by Lamb’s experimen￾tal result). Quantum field theory is beyond the scope of this book; here we
will simply use one of the predictions of the theory to explain part of the
Lamb shift.
In quantum field theory, the vacuum is no longer simply empty space;
it is literally seething with activity. Virtual particles, such as electron￾positron pairs, can pop into existence and disappear. As long as the energy
of the particles E and their lifetime t satisfy Et < ℏ/2, these particle￾antiparticle pairs cannot be detected directly. [This is a rather crude ex￾planation, but is made much more precise within the framework of quantum
field theory.]
These particle-antiparticle pairs produce an effect called vacuum po￾larization. Consider a dielectric surrounding a point positive charge. The
point charge polarizes the dielectric, attracting negative charge inward and
repelling positive charge outward. This tends to cancel the electric field
produced by the point charge, leading to a reduced electric field inside the
dielectric (Figure 9.9).
Now consider the same positive charge in a vacuum. The production
of virtual electron-positron pairs tends to cancel the charge, just as in a
physical dielectric. However, unlike a dielectric, we can never remove the238 Quantum Mechanics: An Accessible Introduction
+ –
+
–
–
+
– +
+ +
Dielectric Vacuum
e
+
e
–
e
+
e
–
e
– e
+
Fig. 9.9 In a dielectric, polarization reduces the electric field produced by a point charge.
Vacuum polarization produces the same effect in a vacuum.
positive charge from the vacuum polarization to measure its true charge:
the charge we measure has already been cancelled by the effect of the vac￾uum polarization. This means that the “bare” charge, which cannot be
measured directly, is much larger than we thought; in fact, it is mathemat￾ically infinite!
The upshot of all of this is that the electric field of a point charge must
be modified at the origin (where the charge is “infinite”), but everywhere
else in space the charge has already been cancelled by the effects of vacuum
polarization, so the electric field is unchanged. The result for V (r), derived
from quantum field theory, is
V (r) = −
e
2
4πϵ0
1
r
−
αe2
15πϵ0
ℏ
2
m2
e
c
2
δ
3
(r) (9.31)
where δ
3
(r) is the three-dimensional Dirac delta function discussed in Chap￾ter 7. The second term in Equation (9.31) is the perturbation to the Hamil￾tonian, so the first-order shift in the energy is
E
(1) = ⟨n l ml ms|H1|n l ml ms⟩ (9.32)
=
Z
d
3
r ψ
∗
nlml
(r)

−
αe2
15πϵ0
ℏ
2
m2
e
c
2
δ
3
(r)

ψnlml
(r) (9.33)
= −
αe2
15πϵ0
ℏ
2
m2
e
c
2
|ψnlml
(0)|
2
(9.34)Time-independent perturbation theory 239
Recall that the hydrogen wave functions are all identically zero at the origin,
except for the l = 0 states. Thus, the effect of vacuum polarization is to
reduce the energy of the l = 0 states relative to the corresponding l ̸= 0
states. The effect is smaller than the fine-structure splitting, e.g., for the
n = 2 states, the splitting between the l = 0 and l = 1 state is about
10−7
eV. As bizarre as all of this sounds, it is important to remember that
this is based on solid experimental evidence.
While all of this is correct as far as it goes, it does not go quite far
enough. There are additional contributions to the Lamb shift that arise
in quantum field theory. These are actually larger than the effect we have
discussed here, and with opposite sign. Thus, the full (experimentally mea￾sured) Lamb shift corresponds to the l = 0 state having a higher energy
than the corresponding l = 1 state.
9.3 The Atom in External Electric or Magnetic Fields
In the previous section, we discussed perturbations which are intrinsic to
the atom. We will now examine what happens when the atom is placed in an
external electromagnetic field. Since the atom consists of charged particles,
and the electrons produce both a spin and orbital magnetic moment, any
external electric or magnetic field will perturb the energy levels of the atom.
The effect produced by an external electric field is called the Stark effect,
while the effect of an external magnetic field is the Zeeman effect.
The Atom in an Electric Field: The Stark Effect
We will first examine the effect of a uniform electric field with magnitude
E on the ground state of hydrogen. Recall that the ground-state wave
function is
ψ100 =
1
√
πa3
0
e
−r/a0
where the “100” subscript denotes the n l ml quantum numbers. We can
ignore the spin state of the electron, since the spin interacts only with mag￾netic fields through the electron’s spin magnetic moment. (Of course, we
will have to consider spin in the next section when we discuss external mag￾netic fields.) We take the electric field to be uniform, static, and pointing
in the z direction.
Since the ground state of hydrogen is nondegenerate, we can use the
perturbation theory expressions from Section 9.1. Classically, the potential240 Quantum Mechanics: An Accessible Introduction
energy of a charge −e in an electric field E is V = eEz, so the perturbation
H1 produced by the electric field is
H1 = eEz
and the first-order change in the energy of the hydrogen atom is, from
Equation (9.19),
E
(1) = ⟨ψ100|eEz|ψ100⟩ (9.35)
Taking z = r cos θ and writing Equation (9.35) in spherical coordinates, we
get
E
(1) =
Z 
1
√
πa3
0
e
−r/a0

(eEr cos θ)

1
√
πa3
0
e
−r/a0

r
2
dr sin θ dθ dϕ
But the integral over θ vanishes:
Z π
θ=0
cos θ sin θ dθ =
1
2
sin2
θ|
π
0 = 0
so E(1) = 0.
Since the first-order perturbation vanishes, we must use second-order
perturbation theory to calculate the change in the energy due to the exter￾nal electric field. Equation (9.20) gives
E
(2) =
X
n,l,ml
|⟨ψ100|eEz|ψnlml
⟩|2
E1 − En
(9.36)
where En = 13.6 eV/n2
. Recall from Chapter 6 that every hydrogen wave
function can be written as the product of a radial wave function Rnl(r) and
the spherical harmonic Y
m
l
(θ, ϕ). Then the inner product which appears in
Equation (9.36) can be written in the form
⟨ψ100|eEz|ψnlml
⟩ = eE
Z
R
∗
10(r)Y
0∗
0
(θ, ϕ) r cos θ Rnl(r)Y
m
l
(θ, ϕ) d
3
r
(9.37)
But now, recall that Y
0
0 = 1/
√
4π, and Y
0
1 =
p
3/4π cos θ, so Y
0
0
cos θ =
(1/
√
3)Y
0
1
. This allows us to write Equation (9.37) as
⟨ψ100|eEz|ψnlml
⟩ =
eE
√
3
Z
R
∗
10(r)Rnl(r)r
3
drZ
Y
0∗
1
(θ, ϕ)Y
m
l
(θ, ϕ) sin θ dθ dϕ
Since the Y
m
l
’s are orthonormal,
R
Y
0∗
1
(θ, ϕ)Y
m
l
(θ, ϕ) sin θ dθ dϕ = 1 (l = 1, m = 0)
= 0 (l ̸= 1 or m ̸= 0)Time-independent perturbation theory 241
Hence, in the sum in Equation (9.36), only the l = 1, m = 0 terms are
nonzero giving
E
(2) =
X
n
|(eE/
√
3) R
R∗
10(r)Rn1(r)r
3 dr|
2
E1 − En
(9.38)
The integral under the sum in Equation (9.38) can be evaluated exactly for
all values of n, and the terms in the series decrease rapidly with n:
E
(2) = −(4πϵ0)a
3
0E
2
(1.48 + 0.20 + 0.066 + · · ·) = −
9
4
(4πϵ0)a
3
0E
2
The change in energy is negative, since the hydrogen atom becomes po￾larized and aligns itself so as to partially cancel the external electric field
(Figure 9.10; see also Problem 9.2). Since the change in energy is propor￾tional to the square of the applied electric field, this effect is called the
quadratic Stark effect.
Our use of nondegenerate perturbation theory breaks down for the ex￾cited states of hydrogen, since these states are degenerate. Using degener￾ate perturbation theory, it is possible to show that the change in energy for
these excited states is proportional to E rather than E
2
. Hence, the change
in energy when an electric field is applied to the excited states of hydrogen
is called the linear Stark effect.
The Atom in a Magnetic Field: The Zeeman Effect
Now consider what happens when we apply an external magnetic field B
to the hydrogen atom. Assume that the magnetic field has magnitude B
and is pointing in the z direction so that
B = Bzˆ
The potential energy of a magnetic dipole µ in a magnetic field B is just
V = −µ·B, so the perturbation produced by the magnetic field is
H1 = −µ·B (9.39)
In Equation (9.39), there are two contributions to the atomic magnetic
moment: the contribution from the orbital magnetic moment µl and the
contribution from the spin magnetic moment of the electron µs
. (In princi￾ple, we should also include the spin magnetic moment of the proton, but this
is much smaller and can be ignored.) Hence, the total magnetic moment is
µ = µl + µs
= −
glµB
ℏ
L −
gsµB
ℏ
S242 Quantum Mechanics: An Accessible Introduction
 atomic
 external
–
+
Fig. 9.10 A classical picture of the quadratic Stark effect: the hydrogen atom is polar￾ized by the external electric field, and the field produced by the polarized atom is in the
opposite direction to the external field.
Recall that gl = 1 and gs ≈ 2, so the expression for µ becomes
µ = −
µB
ℏ
[L + 2S] (9.40)Time-independent perturbation theory 243
S
S
J
L
m
Fig. 9.11 The magnetic moment µ of the hydrogen atom is proportional to L + 2S,
while the total angular momentum J is proportional to L + S, so µ and J are not, in
general, parallel.
Note that the magnetic moment of the atom is not proportional to the
total angular momentum operator J, which is L + S. In classical terms,
the angular momentum vector J and magnetic moment vector µ are not
parallel (Figure 9.11). This has important consequences for the Zeeman
effect. (You are already familiar with a much larger classical system in
which the angular momentum and magnetic dipole are not parallel; the
Earth!)
We can use Equation (9.40) to rewrite the perturbation in Equa￾tion (9.39) as
H1 = B
µB
ℏ
[Lz + 2Sz]
Applying this perturbation to the hydrogen state |n l ml ms⟩ gives the
first-order change in energy,
E
(1) = ⟨n l ml ms|(BµB/ℏ)(Lz + 2Sz)|n l ml ms⟩
= BµB(ml + 2ms) (9.41)
The problem with this result is that it requires the atom to be in a state of
definite ml and ms (or, equivalently, an eigenstate of Sz and Lz). However,
as we have seen in our discussion of fine structure in Section 9.2, the spin￾orbit coupling drives the atom into an eigenstate of J
2
, which does not
commute with Sz and Lz. Hence, the atom is in a state of definite j and
mj rather than ml and ms, so our argument would appear to be invalid.244 Quantum Mechanics: An Accessible Introduction
l = 1
ml = –1, 0, 1
ms = –1/2, +1/2
ml
 + 2ms
2
1
0
–1
–2
ml = 1, ms = 1/2
ml = 0, ms = 1/2
ml = –1, ms = 1/2
ml = 1, ms = –1/2
ml = 0, ms = –1/2
ml = –1, ms = –1/2
Fig. 9.12 The strong-field Zeeman effect for the energy levels of an l = 1 state in
hydrogen.
To clarify this situation, we can write the full Hamiltonian as
H = H0 +
e
2
8πϵ0m2
e
c
2r
3
S·L + B
µB
ℏ
[Lz + 2Sz] (9.42)
where the second term is the perturbation due to the spin-orbit interaction
(given in Equation (9.23)), and the third term is the perturbation from the
external magnetic field.
Now consider two possible cases: for very strong magnetic fields (B ≫
1 T), the third term in Equation (9.42) dominates the second term, while
for weak magnetic fields (B ≪ 1 T), the second term dominates the third.
Consider the case of strong magnetic fields first. For this case we sim￾ply ignore the effect of the spin-orbit coupling; the strong magnetic field
overwhelms the spin-orbit coupling and drives the atom back into a state
of definite ml and ms. Therefore, for the strong magnetic field case, the
expression we derived for E(1) in Equation (9.41) is correct:
E
(1) = BµB(ml + 2ms)
This regime of the Zeeman effect is called the strong-field Zeeman effect or
the Paschen-Back effect. An illustration of this perturbation in the energy
levels is shown in Figure 9.12 for the case l = 1.
Now consider the opposite regime in which spin-orbit coupling domi￾nates the effect of the external magnetic field. In this case the atom is in
a state of definite j and mj rather than ml and ms, and the perturbation
must be written as
E
(1) = ⟨n l j mj |(BµB/ℏ)(Lz + 2Sz)|n l j mj ⟩Time-independent perturbation theory 245
This can be partially simplified by using the fact that Jz = Lz + Sz:
E
(1) = ⟨n l j mj |(BµB/ℏ)(Jz + Sz)|n l j mj ⟩
= BµBmj +
BµB
ℏ
⟨n l j mj |Sz|n l j mj ⟩ (9.43)
In order to further simplify this expression, the state |n l j mj ⟩ must be
written as a linear combination of the |n l ml ms⟩ states. From Chapter 8,
we know that s = 1/2 and a given value of l can couple to give either
j = l + 1/2 or j = l − 1/2, while mj = ml + ms. The actual linear
combination is
|j = l + 1/2, mj ⟩ =

l + 1/2 + mj
2l + 1 1/2
|ml = mj − 1/2, ms = 1/2⟩
+

l + 1/2 − mj
2l + 1 1/2
|ml = mj + 1/2, ms = −1/2⟩
|j = l − 1/2, mj ⟩ =

l + 1/2 − mj
2l + 1 1/2
|ml = mj − 1/2, ms = 1/2⟩
−

l + 1/2 + mj
2l + 1 1/2
|ml = mj + 1/2, ms = −1/2⟩
We can use these equations to solve for ⟨n l j mj |Sz|n l j mj ⟩. For j =
l + 1/2, we get
⟨n l j mj |Sz|n l j mj ⟩ =
"
l + 1/2 + mj
2l + 1 1/2
⟨ml = mj − 1/2, ms = 1/2|
+

l + 1/2 − mj
2l + 1 1/2
⟨ml = mj + 1/2, ms = −1/2|
#
× Sz
"
l + 1/2 + mj
2l + 1 1/2
|ml = mj − 1/2, ms = 1/2⟩
+

l + 1/2 − mj
2l + 1 1/2
|ml = mj + 1/2, ms = −1/2⟩
#
=
ℏ
2

l + 1/2 + mj
2l + 1 
−
ℏ
2

l + 1/2 − mj
2l + 1 
=
mjℏ
2l + 1246 Quantum Mechanics: An Accessible Introduction
Similarly, for j = l − 1/2, we obtain
⟨n l j mj |Sz|n l j mj ⟩ = −
mjℏ
2l + 1
Combining the results for j = l + 1/2 and j = l − 1/2, we get
⟨n l j mj |Sz|n l j mj ⟩ =
mjℏ
2l + 1
2(j − l)
and substituting this result into Equation (9.43) yields
E
(1) = BµBmj

2j + 1
2l + 1 
In analogy with the gs factor for the electron spin and gl for the orbital
angular momentum, we can write
g =
2j + 1
2l + 1
where this g is called the Land´e g factor. In terms of the Land´e g factor,
the energy shift becomes
E
(1) = gBµBmj
In contrast to gs and gl
, which are constant, the Land´e g factor is not
constant, but rather is a function of j and l.
The reason for this is the fact, already alluded to, that µ is not parallel
to J, since the operator which determines µ is L + 2S while J = L + S.
Hence, the ratio between µ and J can depend on the relative orientation of
L and S (Figure 9.11), so µ is not a fixed multiple of mj . The effect of the
weak-field Zeeman effect is to split the energies of the individual mj levels,
with a magnitude which depends on both the magnitude of the magnetic
field and the value of the Land´e g factor (Figure 9.13).
To summarize, for weak magnetic fields, the hydrogen atom can be taken
to be in a state of definite j and mj , and the magnetic field separates the
energies of the individual mj states. As the magnetic field is increased, it
eventually becomes stronger than the internal magnetic fields of the atom.
In this limit, the magnetic field drives the hydrogen atom into a state of
definite ml and ms, and the perturbation in energy is just proportional to
ml + 2ms.Time-independent perturbation theory 247
mj
+3/2
+1/2
+1/2
–1/2
–1/2
–3/2
P3/2 (l = 1, j = 3/2)
P1/2 (l = 1, j = 1/2)
g = 4/3
g = 2/3
Fig. 9.13 The splitting of the P3/2 and P1/2 states in the weak-field Zeeman effect.
PROBLEMS
9.1 (a) In Example 9.2, the energy of the system can be calculated
exactly. Take B = Bxxˆ + Bzzˆ, and calculate the exact energies.
[Hint: Feel free to use a different coordinate system; the energy
levels cannot depend on the choice of the coordinate system].
(b) Take the answer in part (a) and expand it out in powers of Bx,
remembering that Bx ≪ Bz. Show that the terms proportional to
Bx and B2
x
correspond to the answers derived in Example 9.2.
9.2 A particle is in a potential V0 in its ground state |ψ0⟩. A small
perturbation H1 is applied to the particle. Suppose that the first
order perturbation to the energy is zero: E(1) = ⟨ψ0|H1|ψ0⟩ = 0.
Show that the lowest-order effect of H1 is to decrease the energy of
the ground state.
9.3 A particle of mass m is confined to move in a one-dimensional248 Quantum Mechanics: An Accessible Introduction
square well with infinite potential barriers at x = 0 and x = a,
with V = 0 for 0 ≤ x ≤ a. The particle is in the ground state.
A perturbation H1 = λδ(x − a/2) is added, where λ is a small
constant.
(a) What units does λ have?
(b) Calculate the first-order perturbation E(1) due to H1.
(c) Calculate the second-order perturbation E(2). The answer may
be expressed as an infinite series.
9.4 A particle of mass m is confined to move in a narrow, straight
tube of length a which is sealed at both ends with V = 0 inside
the tube. Treat the tube as a one-dimensional infinite square well.
The tube is placed at an angle θ relative to the surface of the
earth. The particle experiences the usual gravitational potential
V = mgh. Calculate the lowest-order change in the energy of the
ground state due to the gravitational potential.
9.5 A particle of mass m is in the ground state in the harmonic oscil￾lator potential
V (x) = 1
2
Kx2
A small perturbation βx6
is added to this potential.
(a) What are the units of β?
(b) How small must β be in order for perturbation theory to be
valid?
(c) Calculate the first-order change in the energy of the particle.
9.6 In the hydrogen atom, the proton is not really a point charge but
has a finite size. Assume that the proton behaves as a uniformly￾charged sphere of radius R = 10−15 m. Calculate the shift this
produces in the ground-state energy of hydrogen.
9.7 The photon is normally assumed to have zero rest mass. If the
photon had a small mass, this would alter the potential energy
which the electron experiences in the electric field of the proton.
Instead of
V (r) = −
e
2
4πϵ0
1
r
(9.44)
we would have
V (r) = −
e
2
4πϵ0
e
−r/r0
r
(9.45)Time-independent perturbation theory 249
where r0 is a constant with units of length. Assume r0 is large
compared to the size of the hydrogen atom, so the potential energy
given in Equation (9.45) differs only slightly from the standard one
given by Equation (9.44) in the vicinity of the electron. Calculate
the change in the ground state energy of hydrogen if the correct
potential is given by Equation (9.45) instead of Equation (9.44).
9.8 Suppose that the proton had spin 0 instead of spin 1/2.
(a) How would this alter the fine structure of the energy levels of
the hydrogen atom?
(b) How would this alter the hyperfine structure of the energy levels
of the hydrogen atom?
9.9 We have seen that the spin-orbit interaction splits the l ̸= 0 states
in the hydrogen atom into j = l + 1/2 states (with slightly higher
energy) and j = l−1/2 states (with slightly lower energy). Suppose
that the electron had spin 1. How many different energy levels
would the spin-orbit interaction produce, and what would their
relative energies be? Be sure to consider how the answer would
depend on the value of l.
9.10 Equation (9.29) gives the fine-structure energy shift.
(a) Show that the j = l + 1/2 state has a higher energy than the
j = l − 1/2 state.
(b) Show that the change in energy, E
(1)
f ine structure, is always neg￾ative.
9.11 An electron is in the ground state in a three-dimensional rectan￾gular box given by 0 ≤ x ≤ a, 0 ≤ y ≤ b, and 0 ≤ z ≤ c, where
V = 0 inside the box, and there are infinite potential barriers at all
of the walls. A homogeneous, static electric field with magnitude
E is applied in the x direction. What is the lowest-order change in
the energy of the electron?
9.12 A hydrogen atom in its ground state is placed in a homogeneous,
static electric field with magnitude E in the x direction.
(a) Show that the first-order perturbation E(1) is 0.
(b) Show that the second-order perturbation E(2) is the same as
if the field was pointing in the z direction. [This is obvious from
symmetry, but calculate E(2) using perturbation theory and show
it explicitly.]250 Quantum Mechanics: An Accessible Introduction
9.13 A hydrogen atom is in its ground state. A proton is fixed in space a
distance R from the nucleus of the hydrogen atom, where R ≫ a0.
Calculate the perturbation to the energy of the hydrogen atom due
to the electric field of this proton.
9.14 The electron in a hydrogen atom is in a D state. A homogenous,
static magnetic field is applied in the z direction.
(a) Draw a diagram showing the splitting of the energy levels in
the weak-field limit. Calculate the value of g for each energy level.
(b) Draw a diagram showing the splitting of the energy levels in
the strong-field limit.
9.15 (a) A particle is in a state |ψ⟩ which is an eigenfunction of the
Hamiltonian H0 with energy E. A perturbation H1 is applied such
that H1|ψ⟩ = 0. Show that the energy of the system is completely
unchanged by this perturbation.
(b) In the ground state of the helium atom, both electrons are in the
l = 0 state, and the spin wave function for the two electrons is the
singlet spin state (s = 0 and ms = 0). [This is a consequence of the
Pauli exclusion principle, which will be discussed in Chapter 13.]
A homogeneous, static magnetic field is applied in the z direction.
Show that the energy of the ground state of helium is completely
unaffected by this magnetic field. [Ignore the magnetic moment of
the nucleus.] What is the physical reason for this?Chapter 10
The variational principle
In the previous chapter, we began with systems for which the Schr¨odinger
equation could be solved exactly, and calculated the change in energy when
a small, time-independent perturbation was added to the Hamiltonian. The
next logical step is to examine time-dependent perturbations. However, be￾fore doing so, we will take a slight detour and develop a technique called the
variational principle. The variational principle applies to time-independent
systems, but it is not a form of perturbation theory; i.e., it does not assume
that a small perturbation is applied to a known exact solution. Instead, the
variational principle is a technique for estimating the ground-state energy
of an arbitrary Hamiltonian for which the Schr¨odinger equation cannot be
solved at all. For example, the Schr¨odinger equation cannot be solved ex￾actly for atoms with more than one electron, but the variational principle
provides a tool to estimate the ground-state energies for such atoms.
The variational principle is based on a simple idea: the expectation value
of the Hamiltonian calculated for an arbitrary wave function gives an upper
bound on the ground-state energy. By “varying” the wave function used
to calculate this expectation value and picking out the smallest resulting
value for the expectation value, we obtain an estimate for the ground-state
energy. We will derive this result below and then apply it to two different
examples.
251252 Quantum Mechanics: An Accessible Introduction
10.1 Variational Principle: Theory
Suppose we have a Hamiltonian H with a set of energies and eigenfunctions:
H|ψ0⟩ = E0|ψ0⟩
H|ψ1⟩ = E1|ψ1⟩
.
.
.
H|ψn⟩ = En|ψn⟩
.
.
.
Assume further that we cannot necessarily solve for any of the energies
or eigenfunctions explicitly. Now suppose that we choose a completely
arbitrary wave function |ψ⟩, which need not be normalized, and we calculate
the expectation value of H, ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩. (The ⟨ψ|ψ⟩ in the denominator
is necessary because we have not assumed that |ψ⟩ is normalized.) The
variational principle is based on the fact that this expectation value gives
an upper bound on the ground-state energy E0:
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
≥ E0 (10.1)
First we will prove the result in Equation (10.1), and then explore the
consequences.
Recall that the eigenfunctions of H can be chosen to be an orthonormal
basis set, so the arbitrary wave function |ψ⟩ that appears in Equation (10.1)
can be expanded as a linear combination of these eigenfunctions:
|ψ⟩ = c0|ψ0⟩ + c1|ψ1⟩ + · · · + cn|ψn⟩ + · · ·
Substituting this expansion into the numerator on the left-hand side of
Equation (10.1) gives
⟨ψ|H|ψ⟩ = (c
∗
0
⟨ψ0| + c
∗
1
⟨ψ1| + · · · + c
∗
n
⟨ψn| + · · ·)H(c0|ψ0⟩ + c1|ψ1⟩
+ · · · + cn|ψn⟩ + · · ·)
But H simply pulls out the appropriate energy when it operates on each
eigenfunction, so
⟨ψ|H|ψ⟩ = (c
∗
0
⟨ψ0| + c
∗
1
⟨ψ1| + · · · + c
∗
n
⟨ψn| + · · ·)(c0E0|ψ0⟩
+ c1E1|ψ1⟩ + · · · + cnEn|ψn⟩ + · · ·) (10.2)
Because the eigenfunctions are orthonormal, ⟨ψ0|ψ0⟩ = 1, ⟨ψ1|ψ1⟩ = 1, . . .,
⟨ψn|ψn⟩ = 1, . . . , and all of the terms containing ⟨ψm|ψn⟩ with m ̸= n are
zero. Therefore, Equation (10.2) simplifies to
⟨ψ|H|ψ⟩ = |c0|
2E0 + |c1|
2E1 + · · · + |cn|
2En + · · ·The variational principle 253
Similarly, the denominator in Equation (10.1) can be expressed as
⟨ψ|ψ⟩ = (c
∗
0
⟨ψ0| + c
∗
1
⟨ψ1| + · · · + c
∗
n
⟨ψn| + · · ·)
(c0|ψ0⟩ + c1|ψ1⟩ + · · · + cn|ψn⟩ + · · ·)
= |c0|
2 + |c1|
2 + · · · + |cn|
2 + · · ·
so
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
=
|c0|
2E0 + |c1|
2E1 + · · · + |cn|
2En + · · ·
|c0|
2 + |c1|
2 + · · · + |cn|
2 + · · ·
(10.3)
Because E0 is the ground-state energy, it must be true that
E0 ≤ E1 ≤ · · · ≤ En ≤ · · ·
so the numerator in Equation (10.3) satisfies
|c0|
2E0 + |c1|
2E1 + · · · + |cn|
2En + · · ·
≥|c0|
2E0 + |c1|
2E0 + · · · + |cn|
2E0 + · · ·
Substituting this bound into Equation (10.3) yields
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
≥
|c0|
2E0 + |c1|
2E0 + · · · + |cn|
2E0 + · · ·
|c0|
2 + |c1|
2 + · · · + |cn|
2 + · · ·
which reduces to Equation (10.1).
Equation (10.1) says that ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩ gives an upper bound on the
ground-state energy, but how can it be used to estimate the ground-state
energy for the Hamiltonian H? One possibility would be to simply substi￾tute a large number of different wave functions |ψ⟩ into the left-hand side
of Equation (10.1) and pick the one which gives the smallest answer. Since
we are guaranteed that this quantity is an upper bound on E0, the smallest
answer will give the best approximation to E0. There is, however, a method
to sample an infinite number of trial wave functions. We can write the trial
wave function |ψ⟩ as a function of some continuous parameter α, which we
can vary. Then the quantity ⟨ψ(α)|H|ψ(α)⟩/⟨ψ(α)|ψ(α)⟩ is a continuous
function of α, and it is guaranteed to be larger than E0. By choosing α so
as to minimize ⟨ψ(α)|H|ψ(α)⟩/⟨ψ(α)|ψ(α)⟩, we obtain the best estimate of
E0 (Figure 10.1). What happens if we get lucky and accidently choose a
form for |ψ(α)⟩ for which a value of α exists that makes |ψ(α)⟩ exactly equal
to the ground-state wave function |ψ0⟩? In this case it is easy to see that
the estimate given by Equation (10.1) is exactly equal to the ground-state
energy (Problem 10.1).254 Quantum Mechanics: An Accessible Introduction
Minimum
E0
a
^cHc&
^cc&
Fig. 10.1 Because ⟨ψ(α)|H|ψ(α)⟩/⟨ψ(α)|ψ(α)⟩ ≥ E0, the best estimate for E0 is ob￾tained by minimizing ⟨ψ(α)|H|ψ(α)⟩/⟨ψ(α)|ψ(α)⟩.
Example 10.1. The Bouncing Ball
Consider a particle subject to the linear potential V (x) = mgx but with an
infinite potential barrier at x = 0 (Figure 10.2). Estimate the ground-state
energy using the variational principle.
First we need to choose a trial wave function ψ(x). There is no “correct”
choice for ψ(x), but the more closely ψ(x) can be made to resemble the
true ground-state solution of the Schr¨odinger equation with V (x) = mgx,
the more accurate our variational estimate of the ground-state energy will
be. We first note that the infinite potential barrier at x = 0 will give
ψ(0) = 0 for the true ground-state wave function, so our variational wave
function should also have this property. Furthermore, since we are dealing
with a bound state, we expect the true wave function to satisfy ψ(x) → 0
as x → ∞. Finally, our experience with solutions of the one-dimensional
Schr¨odinger equation (Chapter 4) indicates that the true ground-state wave
function will not cross the x-axis for x > 0. There are still an infinite
number of functions with these desired properties, so our final choice willThe variational principle 255
V(x)
x
x = 0
Fig. 10.2 The potential V (x) = mgx with an infinite barrier at x = 0.
be somewhat arbitrary. We will use the simple trial wave function
ψ(x) = xe−αx
Note that this wave function increases from ψ = 0 at x = 0 up to a
maximum at x = 1/α, and then ψ decreases exponentially to 0 as x → ∞.
The next step is to calculate ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩. The numerator is
⟨ψ|H|ψ⟩ =
Z ∞
0
(xe−αx)

−
ℏ
2
2m
∂
2
∂x2
+ mgx
(xe−αx) dx
=
Z ∞
0
e
−2αx 
mgx3 −
ℏ
2
2m
α
2x
2 +
ℏ
2
m
αx
dx
=
3mg
8α4
+
ℏ
2
8mα
and the denominator is
⟨ψ|ψ⟩ =
Z ∞
0
x
2
e
−2αxdx
=
1
4α3
so the total expression to be minimized is
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
=
3mg
2α
+
ℏ
2
2m
α
2
(10.4)256 Quantum Mechanics: An Accessible Introduction
Taking the derivative of the right-hand side and setting it to zero gives
−
3mg
2α2
+
ℏ
2
m
α = 0
with the solution
α =

3m2
g
2ℏ
2
1/3
Now this value for α must be substituted back into Equation (10.4) to give
the estimate for the ground-state energy. We obtain
Eestimated =

3
2
5/3
(mg2
ℏ
2
)
1/3
To see how our estimate depends on the actual choice of the trial wave
function, see Problem 10.5.
The variational principle, therefore, is a three-stage process: first,
choose a trial wave function that depends on a parameter α; next, vary α
so as to minimize ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩; and finally, substitute the resulting wave
function back into ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩ to obtain the estimate of the ground￾state energy E0. It is guaranteed that the answer will provide an upper
bound on E0, and it may even provide an excellent approximation to E0,
depending on how closely the trial wave function can be made to resem￾ble the true ground-state wave function. Some common mistakes in using
the variational principle are forgetting to include the kinetic energy term
in H when evaluating ⟨ψ|H|ψ⟩, forgetting to divide by ⟨ψ|ψ⟩, and forget￾ting to complete the solution by substituting α back into the expression for
⟨ψ|H|ψ⟩/⟨ψ|ψ⟩.
There is no “correct” choice for the trial wave function, but the form
of the potential will often provide a guide as to a reasonable choice. As
noted, the goal is to pick something which can be made to resemble the
true ground-state wave function as closely as possible. It is also possible to
use the variational principle to estimate the first excited-state energy (see
Problem 10.2 and Problem 10.6).
10.2 Variational Principle: Application to the Helium
Atom
As we have seen, quantum mechanics provides an excellent description of
the hydrogen atom. The energy levels and wave functions can be calculatedThe variational principle 257
via the Schr¨odinger equation, and perturbation theory can predict the small
changes to these energy levels due to magnetic interactions in the atom.
Now it is time to reveal an unpleasant fact: the Schr¨odinger equation cannot
be solved in a simple way for any of the other atoms! Even adding a
single electron, to produce a helium atom, yields an intractable Schr¨odinger
equation. On the other hand, the calculation of the ground-state energy of
helium is the “classic” problem for the variational principle.
The helium atom contains a nucleus of charge +2e and two negatively￾charged electrons (Figure 10.3). Labelling the electrons “1” and “2”, the
Hamiltonian for the helium atom is
H =
P
2
1
2me
+
P
2
2
2me
−
2e
2
4πϵ0r1
−
2e
2
4πϵ0r2
+
e
2
4πϵ0|r1 − r2|
(10.5)
where, for simplicity, we use the electron mass me rather than the reduced
mass. In this equation, r1 and r2 are the positions of the two electrons rel￾ative to the nucleus with corresponding radial components r1 and r2. The
operators P1 and P2 are the momentum operators for the two electrons,
given by derivatives with respect to the coordinate of the appropriate elec￾tron, e.g., P1 = −iℏ∇1, where ∇1 = ˆx(∂/∂x1) + ˆy(∂/∂y1) + ˆz(∂/∂z1),
etc. Then the physical meaning of the various terms in the Hamiltonian is
clear: the first and second terms give the kinetic energy of the two electrons,
the third and fourth terms are the potentials that each electron feels in the
Coulomb field of the nucleus, and the last term gives the change in the
energy due to the mutual repulsion of the electrons. It is this last term
which causes all the trouble in trying to find an exact solution.
Instead of looking for an exact solution, we will use the variational
principle to estimate the ground-state energy. First, consider an arbitrary
nucleus of charge Z with only a single electron orbiting it. In this case the
+2e
–e
r1
r2
r1
 – r2
–e
Fig. 10.3 The helium atom contains two electrons at positions r1 and r2 relative to the
nucleus.258 Quantum Mechanics: An Accessible Introduction
Schr¨odinger equation can be solved exactly, just as in the case for hydrogen,
but now the charge e for the nucleus must be replaced by the charge Ze.
Recall from Chapter 6 that the ground-state wave function for hydrogen is
ψ(r) = 1
√
π

1
a0
3/2
e
−r/a0
so the ground-state wave function for a single-electron atom with charge Z
on the nucleus is
ψ(r) = 1
√
π

Z
a0
3/2
e
−Zr/a0
(10.6)
Note that the wave function for helium should be a single function of the
positions of the two electrons, not two separate wave functions for the two
electrons. We will take, as our trial wave function, the product of two wave
functions of the form given by Equation (10.6):
ψ(r1, r2) = 
1
√
π

Z
a0
3/2
e
−Zr1/a0
! 1
√
π

Z
a0
3/2
e
−Zr2/a0
!
(10.7)
Rather than setting Z = 2 for the charge on the helium nucleus, we will
take Z to be our variational free parameter. This choice is reasonable from
a physical point of view: each electron partly cancels the positive charge
that the other electron feels from the nucleus, so the “effective” value of Z
should lie between 1 and 2.
Equation (10.7) simplifies to
ψ(r1, r2) = 1
π

Z
a0
3
e
−Z(r1+r2)/a0
Note that this wave function is already normalized, i.e., ⟨ψ|ψ⟩ = 1 for any
value of Z. Then the quantity to be minimized is
⟨ψ|H|ψ⟩ = ⟨ψ|
P
2
1
2me
|ψ⟩ + ⟨ψ|
P
2
2
2me
|ψ⟩ − ⟨ψ|
2e
2
4πϵ0r1
|ψ⟩
− ⟨ψ|
2e
2
4πϵ0r2
|ψ⟩ + ⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩
By symmetry,
⟨ψ|
P
2
1
2me
|ψ⟩ = ⟨ψ|
P
2
2
2me
|ψ⟩
and
⟨ψ|
2e
2
4πϵ0r1
|ψ⟩ = ⟨ψ|
2e
2
4πϵ0r2
|ψ⟩The variational principle 259
Using these results, we get
⟨ψ|H|ψ⟩ = 2⟨ψ|
P
2
1
2me
|ψ⟩ − 2⟨ψ|
2e
2
4πϵ0r1
|ψ⟩ + ⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ (10.8)
The integrals in the first two terms on the right-hand side of Equation (10.8)
are straightforward; they yield
2⟨ψ|
P
2
1
2me
|ψ⟩ =
e
2
4πϵ0a0
Z
2
(10.9)
and
−2⟨ψ|
2e
2
4πϵ0r1
|ψ⟩ =
e
2
4πϵ0a0
(−4Z) (10.10)
The third term on the right-hand side of Equation (10.8) is not so easy
to evaluate, so we derive it in more detail. Written as an integral, this term
is
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩
=
e
2
4πϵ0
Z
1
π

Z
a0
3
e
−Z(r1+r2)/a0
1
|r1 − r2|
1
π

Z
a0
3
e
−Z(r1+r2)/a0 d
3
r1 d
3
r2
=
e
2
4π
3ϵ0

Z
a0
6 Z
e
−2Z(r1+r2)/a0
p
(r1 − r2)·(r1 − r2)
d
3
r1 d
3
r2
=
e
2
4π
3ϵ0

Z
a0
6 Z
e
−2Z(r1+r2)/a0
p
r
2
1 + r
2
2 − 2r1r2 cos θ12
d
3
r1 d
3
r2
where θ12 is the angle between the vectors r1 and r2. We perform the
integral over r2 first. Since r1 is treated as a constant for the integration
over r2, we can choose a spherical coordinate system in which r1 lies on the
polar axis. Then θ12 gives the angle between r2 and the polar axis: it is
just θ2 in the integration over r2 in polar coordinates. We get
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ =
e
2
4π
3ϵ0

Z
a0
6 Z
e
−2Z(r1+r2)/a0
p
r
2
1 + r
2
2 − 2r1r2 cos θ2
× r
2
1 dr1 sin θ1 dθ1 dϕ1r
2
2 dr2 sin θ2 dθ2 dϕ2260 Quantum Mechanics: An Accessible Introduction
Performing the integration over θ2 and ϕ2 gives
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ =
e
2
4π
3ϵ0

Z
a0
6 Z
(2π)e
−2Z(r1+r2)/a0
p
r
2
1 + r
2
2 + 2r1r2 −
p
r
2
1 + r
2
2 − 2r1r2
r1r2
r
2
1 dr1 sin θ1 dθ1 dϕ1r
2
2 dr2
=
e
2
2π
2ϵ0

Z
a0
6 Z
e
−2Z(r1+r2)/a0
(r1 + r2 − |r1 − r2|)r1 dr1 sin θ1 dθ1 dϕ1r2 dr2
Now note that r1+r2−|r1−r2| = 2r2 when r1 > r2, and r1+r2−|r1−r2| =
2r1 when r1 < r2. This can be expressed as r1+r2−|r1−r2| = 2 Min(r1, r2),
where the function Min gives the smaller of its two arguments. Furthermore,
the integrand is now independent of θ1 and ϕ1, so integration over those
variables gives 4π, and we get
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩
=
4e
2
πϵ0

Z
a0
6 Z ∞
r1=0
Z ∞
r2=0
e
−2Z(r1+r2)/a0Min(r1, r2)r1 dr1r2 dr2
where we have now written out the limits of integration for r1 and r2
explicitly, in order to explain how to deal with the Min function. The
presence of the Min function in the integrand forces us to break the integral
over r2 into two pieces: one for r2 < r1, for which Min(r1, r2) = r2, and the
second for r2 > r1, for which Min(r1, r2) = r1. Then the integral becomes
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ =
4e
2
πϵ0

Z
a0
6 Z ∞
r1=0
Z r1
r2=0
e
−2Z(r1+r2)/a0 r1 dr1r
2
2 dr2
+
Z ∞
r1=0
Z ∞
r2=r1
e
−2Z(r1+r2)/a0 r
2
1 dr1r2 dr2

Performing the two integrations over r2 gives
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ =
4e
2
πϵ0

Z
a0
6
Z ∞
r1=0 
e
−4Zr1/a0

−
a0
2Z
r
2
1 −
a
2
0
2Z2
r1 −
a
3
0
4Z3

+ e
−2Zr1/a0
a
3
0
4Z3

r1 dr1
+
Z ∞
r1=0
e
−4Zr1/a0
a
2
0
4Z2

2Zr1
a0
+ 1
r
2
1 dr1
The variational principle 261
and integrating over r1 gives the final result:
⟨ψ|
e
2
4πϵ0|r1 − r2|
|ψ⟩ =
e
2
4πϵ0a0
5
8
Z (10.11)
Combining the results of Equations (10.9), (10.10), and (10.11), and using
the fact that ⟨ψ|ψ⟩ = 1, we get
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
=
e
2
4πϵ0a0

Z
2 − 4Z +
5
8
Z

(10.12)
Taking the derivative of the right-hand side with respect to Z and setting
this derivative equal to 0 gives the value Zmin for which ⟨ψ|H|ψ⟩/⟨ψ|ψ⟩ is
a minimum:
2Zmin −
27
8
= 0
so Zmin = 27/16. As expected, 1 < Zmin < 2. Inserting Zmin back into the
right-hand side of Equation (10.12) gives the estimate of the ground-state
energy:
Eestimated =
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
= −77.5 eV
For comparison, the measured ground-state energy of helium (i.e., the en￾ergy needed to remove both electrons) is
E0 = −79.0 eV
As expected, Eestimated > E0. However, the error in the value of the
ground-state helium energy from the variational principle is only 2%, which
is an excellent approximation!
PROBLEMS
10.1 Suppose that the trial wave function |ψ(α)⟩ happens to be exactly
equal to the true ground-state wave function |ψ0⟩ for some value
of α. Show that in this case, the estimate of the ground-state
energy given by the variational principle will be equal to the true
ground-state energy.
10.2 Suppose that the trial wave function |ψ⟩ used in the variational
principle is orthogonal to the ground-state wave function of the
Hamiltonian: ⟨ψ0|ψ(α)⟩ = 0 for all values of α. Show that in this
case
⟨ψ|H|ψ⟩
⟨ψ|ψ⟩
≥ E1
where E1 is the energy of the first excited state of H.262 Quantum Mechanics: An Accessible Introduction
10.3 (a) In order to use the variational principle to estimate the ground￾state energy of the one-dimensional potential V (x) = Kx4
, where
K is a constant, which of the following wave functions would be a
better trial wave function?
(i) ψ(x) = e
−αx2
(ii) ψ(x) = xe−αx2
Explain.
(b) In order to use the variational principle to estimate the ground￾state energy of the one-dimensional potential V (x) = Kx3
for x > 0
with an infinite potential barrier at x = 0, which of the following
wave functions would be a better trial wave function?
(i) ψ(x) = e
−αx2
(ii) ψ(x) = xe−αx2
Explain.
10.4 A particle of mass m is in the one-dimensional potential given by
V (x) = Kx3
for x ≥ 0, where K is a positive constant. There
is an infinite potential barrier at x = 0, so V (0) = ∞. Use the
variational principle with the trial wave function |ψ⟩ = xe−αx to
estimate the ground-state energy.
10.5 Repeat the calculation in Example 10.1 using the trial wave func￾tion
ψ(x) = xe−αx2
where α is the parameter to be varied. Is the final result a better
or a worse approximation to the true ground-state energy than the
result of Example 10.1?
10.6 (a) A particle of mass m is in the one-dimensional potential given
by V (x) = Kx4
, where K is a positive constant. Use the variational
principle with the trial wave function ψ(x) = e
−αx2
to estimate the
ground-state energy.
(b) The true ground-state wave function for this potential is a sym￾metric function of x, i.e., ψ0(−x) = ψ0(x). Use the result of Prob￾lem 10.2, along with an appropriately chosen trial wave function,
to estimate the energy of the first excited state.The variational principle 263
10.7 A three-dimensional spherically-symmetric harmonic oscillator has
the potential V (r) = (1/2)Kr2
. The full Hamiltonian is then
H =
−ℏ
2
2m
h
1
r
2
∂
∂r r
2 ∂
∂r +
1
r
2 sin2
θ
∂
2
∂ϕ2
+
1
r
2 sin θ
∂
∂θ sin θ
∂
∂θ
i
+
1
2
Kr2
[Note that the L
2 operator has been written out in terms of deriva￾tives.]
(a) Use the trial wave function ψ(r) = e
−αr to calculate an approx￾imation to the ground-state energy of the harmonic oscillator.
(b) The exact ground-state energy for the three-dimensional har￾monic oscillator is E = (3/2)ℏω. What is the relative error in the
estimate from part (a)?
10.8 Here is another approach to solve for the ground-state energy of
helium.
(a) Begin with the Hamiltonian of Equation (10.5), but neglect
the interaction between the two electrons. Solve the Schr¨odinger
equation in this case to derive the wave function of the two electrons
and the energy.
(b) Now add the interaction of the electrons as a perturbation:
H1 =
e
2
4πϵ0|r1 − r2|
Use first-order perturbation theory to calculate the change in en￾ergy, and add this change to the energy derived in part (a) to give
an estimate for the total ground-state energy.
(c) Is the estimate in part (b) more accurate or less accurate than
the estimate from the variational principle?
10.9 (a) Singly-ionized lithium has a nucleus of charge +3e and two
electrons. Use the variational principle to estimate the ground￾state energy.
(b) Now consider a nucleus of charge Ze with two electrons. Use
the variational principle to estimate the ground-state energy.This page intentionally left blankChapter 11
Time-dependent perturbation theory
Although we first encountered the Schr¨odinger equation in full time￾dependent form, we have thus far been concerned almost exclusively with
solutions to the time-independent Schr¨odinger equation. There is a good
reason for this: time-dependent problems are more difficult! Here we return
to the full time-dependent Schr¨odinger equation. We will not attempt to
solve it exactly; instead, we will develop a form of perturbation theory that
can be applied to time-dependent problems.
In Chapter 9, we examined what happens if we begin with a Hamiltonian
H0 whose eigenfunctions |ψn⟩ and energies En are known, and then add a
small change in the Hamiltonian which is constant in time: H = H0 + H1.
Here we consider what happens if the small change H1 is a function of time:
H = H0 + H1(t)
(Here H0 is still taken to be constant in time.) In practice H1(t) will nor￾mally be produced by a time-dependent change in the potential V. Many
different types of time dependence are possible for H1(t). For example,
consider an electron in a time-dependent electric field. One could imag￾ine suddenly “turning on” the electric field, applying an oscillating electric
field, or producing a very slow change in the electric field (called an adia￾batic change). These three possibilities give the forms for H1(t) shown in
Figure 11.1. As we shall see, these different time dependences for H1(t)
produce different predictions for the time evolution of the wave function.
The basic idea, as in Chapter 9, is that a small change in the Hamilto￾nian will produce a small change in the wave function. For a time-dependent
perturbation, there can be a nonzero probability that a system initially
in a particular eigenstate of H0 will undergo a transition into a different
eigenstate of H0. Our goal will be to calculate the probability of such a
transition.
265266 Quantum Mechanics: An Accessible Introduction
H1
(t)
t
Fig. 11.1 Possible forms for the time dependence of H1(t) include a sharp change (top),
an oscillating perturbation (middle), or an adiabatic change [i.e., a slowly-varying H1(t)]
(bottom).
11.1 Derivation of Time-Dependent Perturbation Theory
Before deriving the effect of adding a small perturbation to H0, we need to
derive some general results about the time evolution of the eigenfunctions
of H0 itself. Suppose that at t = 0, we have an eigenfunction |ψn⟩ of H0
with energy En. (We use Dirac notation to indicate that these are general
eigenfunctions; they could be functions of position or spin states represented
in column matrix form.) We will assume for now that H0 is unperturbed.
Recall from Chapter 3 that the time evolution of the eigenstates is given
by
|ψn(t)⟩ = |ψn⟩e
−iEnt/ℏ
where |ψn⟩ represents the state at t = 0. (Although we derived this result
only for wave functions that are taken to be functions of position, the
derivation carries over to the case of abstract states in Dirac notation.)
Now suppose we begin at t = 0 in the eigenstate |ψn⟩, and we would
like to know the probability Pn(t) that we are still in the same eigenstateTime-dependent perturbation theory 267
at some later time t. This probability is
Pn(t) = |⟨ψn|ψn(t)⟩|2
= |e
−iEnt/ℏ
|
2
|⟨ψn|ψn⟩|2
= 1 (11.1)
Thus, a particle in a given eigenstate of H0 remains in that same eigenstate
forever.
Now consider a particle in an arbitrary state |ψ(t)⟩, not necessarily an
eigenfunction of H0. Since the eigenfunctions of H0 at t = 0 form a basis
set, we can represent the wave function |ψ(t)⟩ at any time t as a linear
combination of these eigenfunctions:
|ψ(t)⟩ =
X
m
dm(t)|ψm⟩ (11.2)
where the coefficients dm(t) are functions of time since the wave function
|ψ(t)⟩ evolves with time, but the |ψm⟩’s are not functions of time. Suppose
a particle is in the state given by |ψ(t)⟩ in Equation (11.2), and a mea￾surement is made to see if it is in a given eigenstate of H0, namely |ψn⟩.
Equation (11.2) can be used to determine the probability Pn(t) of finding
the particle in the state |ψn⟩:
Pn(t) = |⟨ψn|ψ(t)⟩|2
=





X
m
dm(t)⟨ψn|ψm⟩





2
= |dn(t)|
2
(11.3)
This gives the physical meaning of the expansion in Equation (11.2): the
absolute value squared of the coefficient dn(t) provides the probability that
the particle will be in the eigenstate |ψn⟩ at some time t.
Time-dependent perturbation theory allows us to address the following
problem. Suppose a system is initially in some state |ψi⟩, which is an
eigenstate of H0. At a later time we make a measurement to determine
if it is in some other final eigenstate |ψf ⟩ of H0. From Equation (11.1),
we know that this probability is 0. But now we “turn on” a small time￾dependent perturbation H1(t). This means that the full Hamiltonian is now
H = H0+H1(t), and the states |ψi⟩ and |ψf ⟩ are no longer eigenstates of H.
Therefore, Equation (11.1) is no longer valid: now there might be a nonzero
probability that the system can begin in the state |ψi⟩ and evolve into the
state |ψf ⟩ (where |ψi⟩ and |ψf ⟩ are eigenstates of the original unperturbed268 Quantum Mechanics: An Accessible Introduction
Hamiltonian H0). The calculation of this probability is the main point of
time-dependent perturbation theory.
Consider an arbitrary state |ψ(t)⟩, subject to the initial Hamiltonian
H0 plus a small time-dependent perturbation H1. The time-dependent
Schr¨odinger equation in this case is
[H0 + H1(t)]|ψ(t)⟩ = iℏ
∂|ψ(t)⟩
∂t (11.4)
We can expand |ψ(t)⟩ in the form given by Equation (11.2). Now,
however, we will define a new set of time-dependent coefficients cm(t) given
by
dm(t) = cm(t)e
−iEmt/ℏ
so that |ψ(t)⟩ is given by
|ψ(t)⟩ =
X
m
cm(t)e
−iEmt/ℏ
|ψm⟩ (11.5)
where Em are the energies of the eigenstates for the original, unperturbed,
time-independent Hamiltonian H0. There is no deep significance to this
change of variables from dm(t) to cm(t); we do it to simplify the algebra.
Note that because |e
−iEmt/ℏ
|
2 = 1, the probability given in Equation (11.3)
can be written as
Pn(t) = |cn(t)|
2
so we will be interested in determining cn(t).
Inserting the expansion given by Equation (11.5) into the Schr¨odinger
equation [Equation (11.4)] gives
X
m
cm(t)e
−iEmt/ℏEm|ψm⟩ +
X
m
H1(t)cm(t)e
−iEmt/ℏ
|ψm⟩
= iℏ
X
m
dcm
dt e
−iEmt/ℏ
|ψm⟩ + iℏ
X
m
(−iEm/ℏ)cm(t)e
−iEmt/ℏ
|ψm⟩
The first term on the left-hand side and the last term on the right-hand
side cancel, since together they just represent the unperturbed Schr¨odinger
equation, and we get
X
m
H1(t)cm(t)e
−iEmt/ℏ
|ψm⟩ = iℏ
X
m
dcm
dt e
−iEmt/ℏ
|ψm⟩Time-dependent perturbation theory 269
Applying ⟨ψn| to both sides of this equation and recalling that ⟨ψn|ψm⟩ =
δmn gives
dcn
dt =
1
iℏ
X
m
⟨ψn|H1(t)|ψm⟩cm(t)e
i(En−Em)t/ℏ
(11.6)
Note that we have made no approximations so far; Equation (11.6) is exact,
and in principle it gives the evolution of all of the coefficients cn(t). The
problem is that it gives the time derivative of cn as a function of all of the
other coefficients cm; in many cases this could be an infinite number!
Making further progress requires using the fact that H1(t) represents
a small perturbation to H0. Suppose that the system begins in an initial
eigenstate |ψi⟩ for which ci = 1 and cm = 0 for m ̸= i, and we would like to
calculate the probability that it evolves into some final eigenstate |ψf ⟩. If
the perturbation is small, then it is a good approximation to assume that
the system does not evolve very far from its initial state, so that at any later
time we still have ci ≈ 1 on the right-hand side of Equation (11.6), while
all of the other cm’s are so small in comparison that they can be ignored.
With this approximation (and identifying the state n with the final state
f), Equation (11.6) becomes
dcf
dt =
1
iℏ
⟨ψf |H1(t)|ψi⟩e
i(Ef −Ei)t/ℏ
which can be integrated to give cf :
cf =
1
iℏ
Z tf
ti
dt⟨ψf |H1(t)|ψi⟩e
i(Ef −Ei)t/ℏ
(11.7)
This is the fundamental equation of first-order time-dependent perturbation
theory [the time-dependent analog to Equation (9.19)]. Here |ψi⟩ and |ψf ⟩
represent eigenstates of the unperturbed Hamiltonian H0 with i ̸= f. (Note
that |ψi⟩ and |ψf ⟩ are assumed to be orthogonal and must be correctly
normalized!) The probability that the system beginning in state |ψi⟩ at
time ti will end up in state |ψf ⟩ at time tf when a perturbation H1(t) is
applied is
P(i → f) = |cf |
2 =
1
ℏ
2




Z tf
ti
dt⟨ψf |H1(t)|ψi⟩e
i(Ef −Ei)t/ℏ




2
It will often be the case that the perturbation H1(t) can be factored into
a time-independent operator H1 and a time-dependent piece f(t) which
does not operate on the wave functions:
H1(t) = H1f(t)270 Quantum Mechanics: An Accessible Introduction
In this case the inner product in Equation (11.7) can be pulled outside of
the time integral, giving
cf =
1
iℏ
⟨ψf |H1|ψi⟩
Z tf
ti
dt f(t)e
i(Ef −Ei)t/ℏ
(11.8)
and the transition probability becomes
P(i → f) = 1
ℏ
2
|⟨ψf |H1|ψi⟩|2




Z tf
ti
dt f(t)e
i(Ef −Ei)t/ℏ




2
(11.9)
This allows us to make general statements about the time evolution of the
system even if we only know the time behavior of the perturbation f(t) and
know nothing about ⟨ψf |H1|ψi⟩.
We now examine how several forms for this time dependence f(t) trans￾late into the time dependence of the transition probability. Consider first
the case of a step-function perturbation of the form H1 = H1f(t), in which
the perturbation is “turned on” with constant magnitude at t = 0 (Fig￾ure 11.1, top). We take f(t) = 0 for t < 0 and f(t) = 1 for t ≥ 0.
Equation (11.8) gives, for this case,
cf =
1
iℏ
⟨ψf |H1|ψi⟩
Z tf
0
dt ei(Ef −Ei)t/ℏ
(11.10)
Note that E/ℏ has units of frequency, so it is convenient to define the
frequency ω0 given by
ω0 = (Ef − Ei)/ℏ
Then Equation (11.10) integrates to
cf = ⟨ψf |H1|ψi⟩
1
ℏω0
(1 − e
iω0tf
)
Finally, the probability that the system has evolved into the state |ψf ⟩ at
the time tf is
P(i → f) = |cf |
2 =
1
ℏ
2
|⟨ψf |H1|ψi⟩|2
sin2
(ω0tf /2)
(ω0/2)2
(11.11)
This gives the general time dependence of the transition probability for any
perturbation which is a step function in time. The behavior of P(i → f)
is shown in Figure 11.2. If tf is small compared with 1/ω0 such that
ω0tf ≪ 1, the transition probability increases as t
2
f
. Eventually, however,
this probability oscillates as shown.Time-dependent perturbation theory 271
P(i → f )
t
f
Fig. 11.2 The probability P(i → f) as a function of time tf for a transition in the case
of a step-function perturbation.
t
H1
(t)
Fig. 11.3 The perturbation H1 = H1 cos(ωt) is “turned on” at time t = 0.
Second, we consider an oscillatory perturbation of the form H1 =
H1 cos(ωt) which is “turned on” at time t = 0 (Figure 11.3). Equa￾tion (11.8) gives, for this case,
cf =
1
iℏ
⟨ψf |H1|ψi⟩
Z tf
0
dt cos(ωt)e
i(Ef −Ei)t/ℏ
(11.12)272 Quantum Mechanics: An Accessible Introduction
As in the previous example, define the frequency ω0 to be given by
ω0 = (Ef − Ei)/ℏ
while cos(ωt) can be expanded in exponentials as
cos(ωt) = e
iωt + e
−iωt
2
so that Equation (11.12) becomes
cf =
1
iℏ
⟨ψf |H1|ψi⟩
Z tf
0
dt1
2

e
i(ω0+ω)tf + e
i(ω0−ω)tf

which integrates to
cf =
1
iℏ
⟨ψf |H1|ψi⟩
1
2

1
i(ω0+ω)

e
i(ω0+ω)tf −1

+
1
i(ω0−ω)

e
i(ω0−ω)tf − 1


(11.13)
This expression is rather complex, but it can be simplified for certain
values of ω. Assume first that Ef > Ei
, so that ω0 > 0. Then if ω
is close to ω0 (which is where the transition probability is largest), the
second term in Equation (11.13) dominates the first [since, in this case,
1/(ω0 − ω) ≫ 1/(ω0 + ω)]. Dropping the first term and calculating |cf |
2
to
derive the transition probability P(i → f), we get
P(i → f) = |cf |
2 =
|⟨ψf |H1|ψi⟩|2
4ℏ
2
sin2
[(ω − ω0)tf /2]
[(ω − ω0)/2]2
(11.14)
Conversely, if Ef < Ei
, then ω0 < 0. In this case the transition prob￾ability is largest when ω is close to −ω0, in which case the first term in
Equation (11.13) dominates the second, and we get
P(i → f) = |cf |
2 =
|⟨ψf |H1|ψi⟩|2
4ℏ
2
sin2
[(ω + ω0)tf /2]
[(ω + ω0)/2]2
(11.15)
These general results are applicable to any sinusoidal perturbation, in￾dependent of the value of ⟨ψf |H1|ψi⟩. Consider the case ω0 > 0. If we fix
the final time tf and examine how the transition probability varies with the
applied frequency ω, we see that it reaches a maximum at ω = ω0; this is
similar to the phenomenon of resonance in classical systems. As ω moves
away from ω0, the transition probability decreases in an oscillatory fashion
(Figure 11.4).Time-dependent perturbation theory 273
P(i → f )
v0
v
Fig. 11.4 The transition probability P(i → f) at a fixed time as a function of the
applied frequency ω for a perturbation which varies as cos(ωt).
As we have emphasized, Equations (11.11) and (11.14)–(11.15) give the
general time evolution for any perturbations of the form H1(t) = H1f(t),
when f(t) is a step function or a sinusoidal function. These cases represent
two of the three types of time dependence shown in Figure 11.1. The third
case (an adiabatic, i.e., slowly-varying perturbation) is left as an exercise
(see Problem 11.4). Of course, these three cases do not exhaust all possi￾bilities; many other forms for the time dependence of H1(t) are conceivable
(see, for example, Problems 11.1 and 11.2).
We now apply these results to two examples.
Example 11.1. A Hydrogen Atom in an Electric Field Turned on
at t = 0
A hydrogen atom is in its ground state. A uniform electric field with mag￾nitude E aligned in the positive z direction is turned on at time t = 0 and
left on. At some later time, tf > 0, what is the probability that the atom
will be in each of the following excited states?
(a) n = 2, l = 1, ml = −1
(b) n = 2, l = 1, ml = 0
(c) n = 2, l = 1, ml = +1
This perturbation is of the form H1(t) = H1f(t) with f(t) a step func￾tion, so the transition probability P(i → f) is given by Equation (11.11).274 Quantum Mechanics: An Accessible Introduction
We need to calculate ⟨ψf |H1|ψi⟩. For the hydrogen atom in an electric
field, the time-independent factor in the perturbation, H1, is
H1 = eEz
just as in the case of the Stark effect in Chapter 9. Then
⟨ψf |H1|ψi⟩ = eE⟨ψf |z|ψi⟩
= eE⟨ψf |r cos θ|ψi⟩
The initial wave function is the ground state of hydrogen:
|ψi⟩ → ψ100(r, θ, ϕ) = 1
√
π

1
a0
3/2
e
−r/a0
In case (a) the final state is
|ψf ⟩ → ψ21−1(r, θ, ϕ) = 1
8
√
π

1
a0
3/2 
r
a0

e
−r/2a0
sin θe−iϕ
so that
⟨ψf |H1|ψi⟩=
eE
8πa4
0
Z ∞
r=0
Z π
θ=0
Z 2π
ϕ=0
(r
2
dr sin θ dθ dϕ)(r
2
e
−3r/2a0
)(sin θ cos θ)e
iϕ
The integral over ϕ gives zero, so the final transition probability is
P(i → f) = 0
Now consider case (b) for which the final state is
|ψf ⟩ → ψ210(r, θ, ϕ) = 1
4
√
2π

1
a0
3/2 
r
a0

e
−r/2a0 cos θ
so that
⟨ψf |H1|ψi⟩ =
eE
4
√
2πa4
0
Z ∞
r=0
Z π
θ=0
Z 2π
ϕ=0
(r
2
dr sin θ dθ dϕ)(r
2
e
−3r/2a0
)(cos2
θ)
This can be integrated to give
⟨ψf |H1|ψi⟩ =
128√
2
243
eEa0
Substituting this back into Equation (11.11) gives the final transition prob￾ability:
P(i → f) = |cf |
2 =
131072
59049
e
2E
2a
2
0
(E2 − E1)
2
sin2

E2 − E1
2ℏ
t

Here E1 and E2 are the energies of the ground state and first excited state
of hydrogen, respectively.
In case (c) we get the same answer (for the same reason) as in case (a):
P(i → f) = 0Time-dependent perturbation theory 275
Now consider an example involving spin eigenstates and an oscillating
potential.
Example 11.2. Spins in an Oscillating Magnetic Field
An electron is in a strong, uniform, constant magnetic field with magnitude
B0 aligned in the −z direction. The electron is initially in the state | ↑⟩. A
weak, oscillating magnetic field in the x direction of the form
B1 = B1 cos(ωt)ˆx
is turned on at t = 0. Calculate the probability that the electron is in
the state | ↓⟩ at some later time t, assuming we are near resonance, so
Equation (11.14) or (11.15) applies.
Since the constant magnetic field is B0 = −B0zˆ, the spin-up state
| ↑⟩ has energy E = −µBB0, while the spin-down state | ↓⟩ has energy
E = +µBB0, so that the initial and final energies are
Ei = −µBB0
Ef = +µBB0
Then ω0 > 0, so Equation (11.14) applies with ω0 given by
ω0 = (Ef − Ei)/ℏ = 2µBB0/ℏ
When the perturbation H1(t) is written as H1(t) = H1 cos(ωt), the expres￾sion for H1 is
H1 = −µ·B1
= −B1µx
= −B1

−
2µB
ℏ

Sx
= B1µBσx
This gives
⟨ψf |H1|ψi⟩ = ⟨↓ |B1µBσx| ↑⟩
or in matrix form,
⟨ψf |H1|ψi⟩ = B1µB
￾
0 1

0 1
1 0 1
0

= B1µ276 Quantum Mechanics: An Accessible Introduction
Then we obtain, using Equation (11.14), the final result:
P(i → f) = B2
1µ
2
B
4ℏ
2
sin2
[(ω − ω0)t/2]
[(ω − ω0)/2]2
with
ω0 = 2µBB0/ℏ
11.2 Application: Selection Rules for Electromagnetic
Radiation
In Chapter 6 we developed a model for the hydrogen atom. In this pic￾ture the energy levels E1, E2, . . . , En correspond to the principle quan￾tum numbers, and the electron can drop from a higher energy level Ei
into a lower energy level Ef by emitting a photon with angular frequency
ω = (Ei − Ef )/ℏ (Figure 11.5, left). In Chapter 9 we showed that vari￾ous internal interactions and corrections split some of the degenerate states
in a given energy level, producing slightly separated energy levels. How￾ever, we still expect that transitions will occur between these energy levels
with the corresponding emission of a photon with the correct energy (Fig￾ure 11.5, right). This picture is essentially complete, in the sense that all
observed spectral lines correspond to a predicted pair of hydrogen energy
levels. However, the reverse is not true: there are spectral lines predicted
by this picture which are very weak or nonexistent. Apparently, something
is preventing some transitions from occurring; these are called forbidden
transitions. For example, the transition from the state n = 2, l = 0 to the
state n = 1, l = 0 is not seen to occur via emission of a single photon. We
will now use time-dependent perturbation theory to understand why. The
rules we will derive that determine the allowed and forbidden transitions
are called selection rules.
n = 2
n = 1
P3/2
P1/2
S1/2
Fig. 11.5 Left: The electron can drop from energy level Ei to energy level Ef with the
emission of a photon of angular frequency ω = (Ei − Ef )/ℏ. Right: The actual energy
levels display fine structure, but transitions occur in the same way.Time-dependent perturbation theory 277
We will actually consider photon absorption rather than emission, since
the calculation for absorption is more straightforward. Since emission is just
the time reverse of absorption, if a given absorption process is allowed, the
corresponding emission process will also be allowed, and the same goes for
forbidden processes. Consider an electromagnetic wave incident upon the
electron in a hydrogen atom. Recall that this wave consists of an oscillating
electric field and an oscillating magnetic field, so the obvious question is:
which is more important, the interaction of the electron with the magnetic
field of the wave, or with its electric field? Classically, recall that the force
experienced by an electron in an electric field E and magnetic field B is
F = −e[E + v×B]
Further, the magnitudes of the electric and magnetic fields in an electro￾magnetic wave satisfy the relation
E = Bc
Combining these two equations, we see that the force due to the electric
field FE and the force due to the magnetic field FB satisfy
FB
FE
≈
v
c
which is much less than one as long as the electron is nonrelativistic. This
is a standard result from classical electromagnetism: in examining the in￾teraction of an electromagnetic wave with matter, it is the electric field of
the wave, not its magnetic field, which dominates the interaction.
The electric field due to an electromagnetic wave propagating in the k
direction can be written in the form
E = E0e
i(k·r−ωt) = E0e
ik·r
e
−iωt (11.16)
where E0 points in a direction perpendicular to k.
The dependence of E on the position r is sinusoidal, but we can simplify
this dependence by noting that we will be interested in frequencies for
which kr ≪ 1. In the hydrogen atom, for example, a transition from
one bound state to another corresponds to a photon energy E < 13.6 eV,
which corresponds to λ > 1.5 × 10−8 m. In comparison, the typical “size”
of the hydrogen atom over which we need to apply this perturbation is
a0 ∼ 10−10 m. Thus, it is a good approximation to take E to be roughly
constant over the radius of the hydrogen atom, corresponding to kr ≪ 1
(Figure 11.6).
Mathematically, this approximation corresponds to expanding out the
exponential in Equation (11.16) in the form
E = E0e
−iωt 
1 + ik·r +
1
2
(ik·r)
2 + · · · 
(11.17)278 Quantum Mechanics: An Accessible Introduction
+ –
Fig. 11.6 For electromagnetic radiation with wavelength λ ≫ a0, the electric field can
be taken to be constant in space over the radius of the atom.
and retaining only the first term in the expansion:
E = E0e
−iωt(1) (11.18)
This is called the dipole approximation.
Suppose we begin with the hydrogen atom in some initial bound state
|ψi⟩ and apply the electric field in Equation (11.18). Then the change in
the energy of the electron due to this electric field is
H1(t) = e(E0·r)e
−iωt
and the probability that the electron will end up in some other bound state
|ψf ⟩ derived from time-dependent perturbation theory (Equation (11.9)) is
P(i → f) = |cf |
2 =
e
2
ℏ
2
|⟨ψf |E0·r|ψi⟩|2




Z
e
i[(Ef −Ei)/ℏ−ω]t
dt




2
(11.19)
The time dependence of this probability is irrelevant (which is why the
limits of integration in the time integral have been left unspecified). The
important thing is whether or not the transition can occur at all, which is
completely determined by whether or not the quantity ⟨ψf |E0·r|ψi⟩ is zero.
We now take the initial state to be the hydrogen wave function with
quantum numbers ni
, li
, and mi (all of the m’s here will refer to ml
; we
temporarily drop the l subscript for clarity) and the final state will have
quantum numbers nf , lf , and mf . For now we will take E0 to be in the z
direction, so that
E0·r = E0z = E0r cos θ
This choice for E0 indicates that the light is polarized in the z direction.
Since the value of l does not depend on the choice of coordinate axes, we do
not expect the selection rules for l to depend on the choice of polarization.
This will not be true, however, for the selection rules for ml
.Time-dependent perturbation theory 279
The inner product which determines whether or not the transition can
occur becomes
⟨ψf |E0·r|ψi⟩
= E0
Z
(r
2
dr sin θ dθ dϕ)R
∗
nf lf
(r)Y
mf ∗
lf
(θ, ϕ)(r cos θ)Rnili
(r)Y
mi
li
(θ, ϕ)
Consider the integral over θ and ϕ:
Z
(sin θ dθ dϕ)Y
mf ∗
lf
(θ, ϕ)(cos θ)Y
mi
li
(θ, ϕ)
It can be shown that the spherical harmonics have the property that
Y
m
l
(θ, ϕ) cos θ = aY m
l+1(θ, ϕ) + bY m
l−1
(θ, ϕ)
where a and b are constants that depend on the particular values of l and
m. This relation allows us to rewrite the angular integral as
Z
(sin θ dθ dϕ)Y
mf ∗
lf
(θ, ϕ)(cos θ)Y
mi
li
(θ, ϕ)
=
Z
(sin θ dθ dϕ)Y
mf ∗
lf
(θ, ϕ)[aY mi
li+1(θ, ϕ) + bY mi
li−1
(θ, ϕ)] (11.20)
Finally, recall the orthogonality relation for the spherical harmonics:
Z
(sin θ dθ dϕ)Y
m′∗
l
′ (θ, ϕ)Y
m
l
(θ, ϕ) = 0, unless l = l
′
and m = m′
Applying this orthogonality condition to Equation (11.20), we see that
the integral will vanish (and therefore the transition probability in Equa￾tion (11.19) will be zero) unless
lf = li + 1 or lf = li − 1 (11.21)
and
mf = mi
These are the correct selection rules for light polarized in the z direction,
but only the selection rule for l (Equation (11.21)) carries over to arbitrary
polarizations, since, as we have argued, anything involving l must be inde￾pendent of the coordinate system. The selection rule we have derived for
m applies only to this particular polarization state; for light polarized in
the x or y directions, we obtain instead (Problem 11.8)
mf = mi + 1 or mf = mi − 1
The full selection rules then can be expressed in the succinct form
∆l = ±1280 Quantum Mechanics: An Accessible Introduction
and
∆ml = 0, ±1
where ∆l = lf − li and ∆ml = mf − mi
. Finally, there is an additional
selection rule for the total angular momentum quantum number j:
∆j = 0, ±1 (11.22)
with the single exception that ji = 0 → jf = 0 is forbidden. We will not
give a rigorous proof of the j selection rules but rather explain their physical
origin. The photon has spin 1, so if it is absorbed by an atom with initial
total angular momentum quantum number ji
, the two angular momenta
can couple to give total angular momentum of ji − 1, ji
, or ji + 1, from
the rules for adding angular momentum in Chapter 8. These, therefore,
are the possible values of jf , giving the selection rule in Equation (11.22).
The single exception occurs when ji = 0, which can couple to the spin-1
photon only to give jf = 1. This is why the transition ji = 0 to jf = 0
is forbidden. (Of course, j = 0 never occurs in the hydrogen atom, but it
does occur in multielectron atoms.)
Example 11.3. The Allowed Transitions in Hydrogen from n = 3
to n = 1
An electron in the n = 3 state of hydrogen emits a photon and drops into
the ground state. What are the allowed transitions?
The state n = 1 has only one possible value for l, namely, l = 0 and
one possible value for j, namely, j = 1/2. In the spectroscopic notation
introduced in Chapter 9, this state is written S1/2.
The state n = 3 has the following possible l and j states:
l = 0, j = 1/2
l = 1, j = 1/2, j = 3/2
l = 2, j = 3/2, j = 5/2
The selection rule for l tells us that ∆l = ±1. Since the final state has
l = 0, and l cannot be negative, the only allowed initial state is l = 1.
For l = 1 in the initial state, we can have either j = 1/2 or j = 3/2.
Since j = 1/2 in the final state, the j = 1/2 initial state corresponds
to ∆j = 0, and the j = 3/2 initial state corresponds to ∆j = −1. The
selection rule for j is ∆j = 0, ±1, so either of these initial j states is allowed.Time-dependent perturbation theory 281
The allowed transitions, therefore, are
l = 1, j = 1/2 → l = 0, j = 1/2
l = 1, j = 3/2 → l = 0, j = 1/2
or, in spectroscopic notation,
P1/2 → S1/2
P3/2 → S1/2
Transitions which are not allowed by our selection rules are called for￾bidden transitions, but this is somewhat misleading. Such transitions can
sometimes occur but at a much slower rate. There are two possible ways of
evading the selection rules: first, a transition may occur through one of the
higher-order terms that were dropped in Equation (11.17). For example,
a transition occurring through the term linear in k·r is called an electric
quadrupole transition. Second, we have ignored the interaction between the
magnetic field of the electromagnetic wave and the electron in the atom,
but this interaction can lead to a magnetic dipole transition, or a higher or￾der magnetic transition. Therefore, the term “forbidden” transition really
means “forbidden to electric dipole radiation.”
PROBLEMS
11.1 The electron in a hydrogen atom is initially in the ground state.
At t = 0, a homogeneous electric field aligned in the z direction is
turned on. The magnitude of the electric field decreases exponen￾tially:
E = E0zeˆ
−t/τ
where E0 and τ are constants. A measurement is made at tf = +∞;
what is the probability that the electron will be in the first excited
state?
11.2 A system is in an eigenstate |ψi⟩ with energy Ei
. The perturbation
H1(t) = H1e
−α
2
t
2
is turned on at ti = −∞ and left on until tf = +∞. Here H1 is
independent of time, and α is a constant. Show that at tf = +∞,
the probability that the system has evolved into the eigenstate |ψf ⟩
with energy Ef is
P(i → f) = π
ℏ
2α2
|⟨ψf |H1|ψi⟩|2
e
−(Ef −Ei)
2/2ℏ
2α
2
(11.23)282 Quantum Mechanics: An Accessible Introduction
11.3 An electron is in a strong, uniform, constant magnetic field with
magnitude B0 aligned in the +x direction. The electron is initially
in the state | →⟩ with x component of spin equal to +ℏ/2. A
weak, uniform, constant magnetic field of magnitude B1 (where
B1 ≪ B0) in the +z direction is turned on at t = 0 and turned off
at t = t0. Let P(i → f) be the probability that the electron is in
the state | ←⟩ with x component of spin equal to −ℏ/2 at a later
time tf > t0. Show that
P(i → f) = (B1/B0)
2
sin2
(µBB0t0/ℏ)
11.4 Consider a time-dependent perturbation H1(t) which is adiabatic,
i.e., slowly varying. The system is initially in the state |ψi⟩ at
ti = −∞. The potential is turned on, and we wish to derive the
probability that the system will be in the state |ψf ⟩ at some later
time tf . Write down the standard expression for cf in this case and
use integration by parts to break the expression into two terms, one
of which contains dH1/dt. Since H1 is slowly varying, this term
may be taken to be 0. Then use the fact that H1(−∞) = 0 to
derive the final expression for the transition probability:
P(i → f) = |⟨ψf |H1(tf )|ψi⟩|2
(Ei − Ef )
2
11.5 A particle with mass m is in a one-dimensional infinite square-well
potential of width a, so V (x) = 0 for 0 ≤ x ≤ a, and there are
infinite potential barriers at x = 0 and x = a. Recall that the
normalized solutions to the Schr¨odinger equation are
ψn(x) = r
2
a
sin nπx
a

with energies
En =
ℏ
2π
2n
2
2ma2
where n = 1, 2, 3, . . . .
The particle is initially in the ground state. A delta-function per￾turbation
H1 = Kδ 
x −
a
2

(where K is a constant) is turned on at time t = −t1 and turned
off at t = t1. A measurement is made at some later time t2, where
t2 > t1.Time-dependent perturbation theory 283
(a) What is the probability that the particle will be found to be in
the excited state n = 3?
(b) There are some excited states n in which the particle will never
be found, no matter what values are chosen for t1 and t2. Which
excited states are these?
11.6 An electron is in a strong, static, homogeneous magnetic field with
magnitude B0 in the z direction. At time t = 0, the spin of the
electron is in the +z direction. At t = 0 a weak, homogenous
magnetic field with magnitude B1 (where B1 ≪ B0) is turned on.
At t = 0 this field is pointing in the x direction, but it rotates
counterclockwise in the x-z plane with angular frequency ω, so
that at any later time t this field is at an angle ωt relative to the
x-axis:
vt
z
x
B
Do not assume anything about the particular value of ω. Calculate
the probability that at a later time tf the electron spin has flipped
to the −z direction.
11.7 A hydrogen atom is in the ground state. At t = 0 an electric
field with magnitude E is turned on. At t = 0 the electric field
points in the x direction, and it rotates counterclockwise in the x-y
plane with angular frequency ω (i.e., at any later time t the field
is oriented at an angle ωt relative to the x-axis). This rotating
field causes the atom to undergo a transition to an n = 2 state.
Determine which of the l, ml states are possible final states and
which are impossible.284 Quantum Mechanics: An Accessible Introduction
11.8 (a) Consider an electromagnetic wave polarized in the x direction,
incident on a hydrogen atom. Show that in this case, the selection
rules for ml are
∆ml = ±1
(b) Repeat this calculation for an electromagnetic wave polarized
in the y direction.
11.9 A hydrogen atom in the n = 4 state emits electric dipole radiation
and drops into the n = 3 state. Determine all possible transitions
in terms of their initial and final values for l and j. Express the
answer in spectroscopic notation.
11.10 (a) The electron in a hydrogen atom is initially in the state n = 5,
l = 0, j = 1/2. The atom emits electric dipole radiation and drops
into an n = 3 state. Determine all l, j states which are possible
final states.
(b) An electron in a hydrogen atom is initially in the state n = 5,
l = 2, j = 5/2. It emits electric dipole radiation and drops into
the state n = 4, l = l1, j = j1. From this state, it emits electric
dipole radiation again and drops into the hydrogen ground state.
Determine l1 and j1.
11.11 An electron is contained in a three-dimensional rectangular box
given by 0 ≤ x ≤ a, 0 ≤ y ≤ b, and 0 ≤ z ≤ c. The solutions
of the Schr¨odinger equation are specified by the quantum numbers
nx, ny, and nz. Recall that the normalized wave function is
ψ(x, y, z) = r
8
abc sin nxπx
a

sin nyπy
b

sin nzπz
c

with energy
E =

ℏ
2π
2
2m
 
n
2
x
a
2
+
n
2
y
b
2
+
n
2
z
c
2
!
where nx, ny, and nz are positive integers. The electron is initially
in the state nx, ny, nz. An electromagnetic wave is incident po￾larized in the y direction, so that the electric field vector is given
by:
E = E0e
−iωt 
1 + ik·r +
1
2
(ik·r)
2 + · · · Time-dependent perturbation theory 285
where E0 is a constant vector in the y direction. Use the dipole
approximation and time-dependent perturbation theory to derive
the selection rules for the electron to absorb the radiation and end
up in the final state n
′
x
, n
′
y
, n
′
z
.This page intentionally left blankChapter 12
Scattering theory
In this chapter, we return to the theory of scattering, i.e., the behavior
of a particle incident on a fixed potential. The one-dimensional case was
examined for step-function potentials in Chapter 4. In that case it was
possible to solve the Schr¨odinger equation exactly. Here we extend the
discussion to the case of three-dimensional potentials. In most cases the
Schr¨odinger equation for scattering in three dimensions cannot be solved
exactly, so approximation methods must be used. This chapter deals with
two of these approximation methods: the Born approximation and the
method of partial waves. The Born approximation can be applied when
the energy of the incident particle is much larger than the potential from
which it scatters. While the method of partial waves is applicable to any
scattering problem, it takes a particularly simple form in the limit where
the energy of the incident particle is low.
12.1 Definition of the Cross Section
Before examining these quantum mechanical approximations, we will re￾view some of the concepts of scattering from classical mechanics. Suppose
that a region of space is filled with targets having a number density n. A
particle enters this region and travels a distance L (Figure 12.1). Clearly,
the probability P that the particle will strike one of the targets is propor￾tional to the distance L that it travels, and it is also proportional to the
number density of targets n, so it is possible to write
P = nLσ (12.1)
where σ is a constant of proportionality that depends on the nature of the
targets. Since P is a probability, it must be a dimensionless number, while
n has units of 1/length3
and L has units of length. Hence, σ must have units
287288 Quantum Mechanics: An Accessible Introduction
L
Fig. 12.1 A particle moves a distance L through a region of space having a number
density of targets n.
of length2
, or area. The quantity σ is called the cross section for scattering.
In a classical scattering problem in which the incident particle physically
collides with the targets, σ is just the cross-sectional area of each target,
i.e., the area that the incident particle “sees” head-on. This is not the case
(even classically) when the incident particle and the targets interact via a
long-range force.
Now suppose that instead of a single particle, a large number of incident
particles Ni all travel a distance L through this region of targets, and let
Ns be the number of these particles that scatter off of one of the targets.
In this case P gives the fraction of particles that scatter, so that
P = Ns/Ni
which implies that
Ns = NinLσ (12.2)
Often, however, it is important to know not only the total probability for
scattering but also the probability that the incident particles are scattered
in a particular direction. In order to quantify this idea, we set up a spherical
coordinate system with the polar axis aligned along the direction of motion
of the incident particle (Figure 12.2). Consider a small solid angle of size
dΩ in the θ, ϕ direction:
dΩ = sin θ dθ dϕScattering theory 289
u
f
r
Direction of incident particle
Fig. 12.2 A spherical coordinate system with the polar axis along the direction of motion
of the incident particle.
u
f
Incident particle
Scattered
particle
Fig. 12.3 The differential cross section, dσ/dΩ, determines the probability that an
incident particle will be scattered in the θ, ϕ direction.
If Ns is the total number of particles scattered (as in Equation (12.2)), let
dNs be the total number of particles scattered into the small solid angle
dΩ in the θ, ϕ direction, where dNs will be a function of the scattering
direction and will be proportional to dΩ. Then the equation analogous to
Equation (12.2) is
dNs = NinL dσ
dΩ
dΩ
Thus, dσ/dΩ, which is a function of θ and ϕ, determines the probability that
the incident particle will be scattered in the θ, ϕ direction (Figure 12.3).
For instance, θ = 0 corresponds to no scattering, while θ = π represents
scattering directly backwards. The quantity dσ/dΩ is called the differential
cross section and, therefore, σ is often called the total cross section. Given
dσ/dΩ, the total cross section is just the integral of the differential cross
section over all angles:
σ =
Z π
θ=0
Z 2π
ϕ=0 
dσ
dΩ

sin θ dθ dϕ
It will frequently be the case that the scattering potential is spheri￾cally symmetric. In this case the system as a whole (incident particle plus
scattering potential) has azimuthal symmetry, i.e., there is no preferred ϕ
direction. On the other hand, while the potential is symmetric with respect290 Quantum Mechanics: An Accessible Introduction
u
a
a
a
a
Fig. 12.4 A particle scatters from a hard sphere of radius a. The scattering angle is θ,
and the angle of incidence and angle of reflection are both α.
to θ, the system as a whole is not, since the direction of the incident parti￾cle defines a special direction with respect to the θ coordinate. Thus, for a
spherically-symmetric scattering potential, we expect dσ/dΩ to depend on
θ but to be independent of ϕ.
As an example of how these ideas work, we will now calculate a classical
scattering cross section; this is not a quantum mechanical calculation!
Example 12.1. Classical Scattering from a Hard Sphere
Suppose that we are shooting particles at a solid sphere of radius a, where
the size of the incident particles is negligible compared to the size of the
sphere. The particles reflect off of the sphere elastically, so that the angle
of incidence equals the angle of reflection. We now calculate the differential
cross section, dσ/dΩ, and the total cross section σ.
As usual, let θ be the scattering angle for the particle. When the particle
scatters, the angle of reflection equals the angle of incidence; we let α be
both of these angles (Figure 12.4). The particle scatters off of a cross￾sectional area consisting of a ring of radius s and width ds (Figure 12.5).
The cross-sectional area of this ring is
dσ = 2πs ds
and from Figure 12.5, we have
s = a sin αScattering theory 291
a
a
a
s
s
a
ds
Fig. 12.5 The particle scatters off of a cross-sectional area consisting of a ring of radius
s, width ds: (left) side view, (right) head-on view.
These two equations give dσ in terms of α:
dσ = (2π)(a sin α)(a cos α dα) (12.3)
However, we want to express everything in terms of the scattering angle θ.
Note from Figure 12.4 that
θ = π − 2α
Substituting this into Equation (12.3) gives
dσ = (2π)a
2
[(sin θ)/2](dθ/2)
Note that if the particle strikes this area dσ, it scatters into the solid an￾gle dΩ = (sin θ dθ)(2π), where the 2π comes from the fact that we have
integrated over ϕ. Then the differential cross section is
dσ
dΩ
=
2πa2
[(sin θ)/2](dθ/2)
2π sin θ dθ
=
a
2
4
Thus, the differential cross section in this case is independent of both θ
and ϕ.
The total cross section is
σ =
Z π
θ=0
Z 2π
ϕ=0 
dσ
dΩ

sin θ dθ dϕ
=
Z π
θ=0
Z 2π
ϕ=0
a
2
4
sin θ dθ dϕ
= πa2292 Quantum Mechanics: An Accessible Introduction
This result makes sense physically because πa2
is the cross-sectional area
of the sphere, i.e., a particle striking the sphere sees, in projection, a circle
of radius a and area πa2
.
The general scattering problem in quantum mechanics is the calculation
of dσ/dΩ for a particle incident on an arbitrary potential V . In principle,
the Schr¨odinger equation should be solved and the resulting wave function
used to find the cross section. In practice, the Schr¨odinger equation for
scattering problems is usually difficult to solve, so approximation methods
must be used. There are two cases for which the problem is much simpler.
In the limit in which the energy of the particle E is much larger than the
potential V we can use a variant of perturbation theory called the Born
approximation. In the opposite limit, when E ≪ V , we utilize the method
of partial waves. We now discuss these in turn.
12.2 The Born Approximation
Consider an incident particle with energy E scattering off of a potential
V (r). (Although the potential will often be taken to have spherical sym￾metry, this is not essential in using the Born approximation, so we begin
with the most general case.) We assume that the potential is “weak” in the
sense that E ≫ V (r), which allows us to use the results of time-dependent
perturbation theory from the previous chapter. We will assume further that
V (r) → 0 when r → ∞ so that the potential can be ignored for sufficiently
large r.
Assume that the incident particle has wave vector ki
, and it scatters
with final wave vector kf (Figure 12.6). These correspond to initial and
final energies of
Ei =
ℏ
2k
2
i
2m
Ef =
ℏ
2k
2
f
2m
We have assumed that the potential vanishes for large r, so at locations far
from the potential the time-independent wave functions correspond to free
particles. These time-independent wave functions (from Chapter 4) are
ψi = e
iki·r
ψf = e
ikf ·rScattering theory 293
V
ki
kf
Fig. 12.6 A particle scatters from the potential V (r) with initial wave vector ki and
final wave vector kf .
The scattering potential is assumed to be constant in time. However, we
can think of this problem in terms of time-dependent perturbation theory.
Initially, when the particle is far from the potential, it “sees” V = 0. Then,
as the particle enters the region where V ̸= 0, the particle experiences
the potential and scatters. Finally, as the particle leaves the region of the
potential, it once again “sees” V = 0. Hence, we will assume that the
potential is “turned on” at some arbitrary time, which we will take to be
t = 0, and we wish to know the probability that the particle has scattered
from the state ψi to ψf by the time t. Formally, since the potential is being
treated as a small perturbation, this probability is just given by the result
of time-dependent perturbation theory from Chapter 11:
P(i → f) = 1
ℏ
2




Z t
0
dt′
⟨ψf |V (r)|ψi⟩e
i(Ef −Ei)t
′/ℏ




2
=
1
ℏ
2
|⟨ψf |V (r)|ψi⟩|2




Z t
0
dt′
e
i(Ef −Ei)t
′/ℏ




2
=
1
ℏ
2
|⟨ψf |V (r)|ψi⟩|2




ℏ
i(Ef − Ei)

e
i(Ef −Ei)t/ℏ − 1





2
=
1
ℏ
2
|⟨ψf |V (r)|ψi⟩|2
4ℏ
2
(Ef − Ei)
2
sin2

(Ef − Ei)t
2ℏ

(12.4)
Although this expression is formally correct, there are several further steps
before this result can be used to derive an actual scattering cross section.
First, the wave functions must be normalized. This represents a prob￾lem, since a function of the form e
ik·r does not have a well-defined integral
over all of space. To resolve this, we put a box of volume V around the
incident and scattered wave functions. This may seem like a bit of a fraud,
but as long as the volume of the box is much larger than the system under
consideration, it cannot affect the final results. In this case the normalized294 Quantum Mechanics: An Accessible Introduction
wave functions become
ψi =
1
√
V
e
iki·r
ψf =
1
√
V
e
ikf ·r
since, for example,
Z
V
ψ
∗
i ψi d
3
r =
Z
V

1
√
V
2
e
−iki·r
e
iki·r
d
3
r = 1
Thus, the inner product in Equation (12.4) can be written as
⟨ψf |V (r)|ψi⟩ =
Z
V
d
3
r
1
√
V
e
−ikf ·rV (r)
1
√
V
e
iki·r
=
1
V
Z
V
d
3
r V (r)e
i(ki−kf )·r
and the transition probability from Equation (12.4) becomes
P(i → f) = 4
(Ef − Ei)
2
sin2

(Ef − Ei)t
2ℏ

1
V2




Z
V
d
3
r V (r)e
i(ki−kf )·r




2
(12.5)
Now we come to another problem: Equation (12.5) gives the transition
probability from a specific initial wave vector ki with energy ℏ
2k
2
i
/2m to a
specific final wave vector kf with energy ℏ
2k
2
f
/2m. In a physical scattering
problem, it is certainly possible to control the initial energy, but not the final
energy. Hence, Equation (12.5) must be integrated over all possible final
energies Ef . In doing this, however, there is an additional complication:
there are more quantum states corresponding to higher energies than to
lower ones. For instance, recall from Chapter 6 that a particle in a cubic
box of side a has an energy given by
E =
ℏ
2π
2
2ma2
[n
2
x + n
2
y + n
2
z
] (12.6)
If the energy is fixed to lie in the small range between E and E + dE, then
the number of different values of nx, ny, and nz that produce an energy in
this range increases as E increases. To quantify this, consider the three￾dimensional “space” defined by nx, ny, and nz (Figure 12.7). We now fix
the energy E and calculate how many states have energies between E and
E +dE. This number is given by 1/8 of the volume of a thin spherical shell
with radius n, where
n
2 = n
2
x + n
2
y + n
2
zScattering theory 295
n
ny
nx
nz
Fig. 12.7 The number of states with energies between E and E + dE is given by 1/8 of
the volume of a thin spherical shell with radius n, where E = (ℏ
2π
2/2ma2
)n
2
.
and the factor of 1/8 arises because the physical states all lie in the octant
defined by nx > 0, ny > 0, and nz > 0. If N(E) dE gives this number of
states, we get
N(E) dE =
1
8
(4πn2
dn) (12.7)
Further, Equation (12.6) allows us to express n in terms of E:
E =
ℏ
2π
2
2ma2
n
2
(12.8)
and using Equation (12.8) to rewrite the right-hand side of Equation (12.7)
in terms of E rather than n, we get
N(E) dE =
V
4π
2
(2m)
3/2
ℏ
3
√
E dE (12.9)
In this equation, N(E) is called the density of states. Physically, Equa￾tion (12.9) says that there are more ways for a system to have a large
energy than a small energy (and the density of states scales as the square
root of the energy).
Now Equation (12.5) can be multiplied by N(Ef ) dEf and integrated
over the final possible energies. However, we also have to include the fact
that the density of final states is proportional to dΩf /4π. Hence, the296 Quantum Mechanics: An Accessible Introduction
x
sin2 ax
x
2
Fig. 12.8 In the limit a → ∞, the function sin2 ax/x2 becomes sharply peaked and can
be approximated as a multiple of the delta function.
transition probability dP for scattering into a small solid angle dΩf is
dP(i → any E) = Z
P(i → f)N(Ef ) dEf
dΩf
4π
=
Z
4
(Ef − Ei)
2
sin2

(Ef − Ei)t
2ℏ

1
V2




Z
V
d
3
r V (r)e
i(ki−kf )·r




2
×
V
4π
2
(2m)
3/2
ℏ
3
p
Ef dEf
dΩf
4π
(12.10)
Note the factor sin2
[(Ef − Ei)t/2ℏ]/(Ef − Ei)
2
in Equation (12.10). The
generic function sin2
(ax)/x2 becomes arbitrarily sharply peaked as a → ∞
(Figure 12.8). More rigorously,
sin2
ax
x
2 → πaδ(x), as a → ∞ (12.11)
Since we are interested in the behavior of this system in the limit where t
becomes large, we can use Equation (12.11) to write
sin2
[(Ef − Ei)t/2ℏ]
(Ef − Ei)
2 → π(t/2ℏ)δ(Ef − Ei)
When we substitute this delta function into Equation (12.10), the integra￾tion over Ef picks out the value Ef = Ei
. This makes sense on physical
grounds; in the limit where perturbation theory is applicable, scattering off
of the potential should not change the energy of the incident particle by
very much, which implies that Ef ≈ Ei
. After performing this integrationScattering theory 297
and taking Ei = ℏ
2k
2
i
/2m, we obtain
dP(i → any E) = mtki
πℏ
3V




Z
V
d
3
r V (r)e
i(ki−kf )·r




2 
dΩf
4π

(12.12)
with the added restriction that |kf | = |ki
|, since the delta function integra￾tion gave Ef = Ei
.
There remains one final task: determining the relationship between the
transition probability dP in Equation (12.12) and the differential cross sec￾tion dσ/dΩ. At the beginning of this section, we derived the relationship
between the total scattering cross section and the scattering probability
in terms of the total distance L travelled by the incident particle (Equa￾tion (12.1)). If the incident particle has velocity vi and travels for a time
t, we can substitute L = vit into Equation (12.1) to obtain an alternative
relation between scattering probability and cross section
P = nvitσ
For scattering into a small solid angle dΩf , the corresponding relation is
dP = nvit
dσ
dΩf
dΩf
so that the differential cross section is
dσ
dΩ
=
dP
nvit dΩf
(12.13)
Substituting the expression for dP given by Equation (12.12) into Equa￾tion (12.13), using vi = pi/m = ℏki/m and assuming one target per volume
V so that n = 1/V, we get a final expression for the differential cross section:
dσ
dΩ
=
 m
2πℏ
2
2




Z
d
3
r V (r)e
i(ki−kf )·r




2
(12.14)
where we have now taken the limit where V goes to infinity, so the integral
is over all space. Equation (12.14) is called the Born approximation. Fur￾thermore, when this approximation is valid, it will always be true that the
incident wave vector ki and the scattered wave vector kf satisfy |ki
| = |kf |.
The Born approximation can be expressed in a more compact form by
defining a new wave vector K (Figure 12.9):
K = kf − ki
where K is called the momentum transfer because ℏK gives the change in
the momentum of the particle as it scatters. Taking θ to be the scattering298 Quantum Mechanics: An Accessible Introduction
kf
ki
K
u/2
u/2
Fig. 12.9 The momentum transfer K = kf − ki gives the change in momentum ℏK of
the particle as it scatters. This figure shows that K = 2k sin(θ/2).
angle, i.e., the angle between kf and ki
, and taking k = |ki
| = |kf |,
Figure 12.9 shows that
K = 2k sin(θ/2) (12.15)
In terms of the momentum transfer, the Born approximation is
dσ
dΩ
=
 m
2πℏ
2
2




Z
d
3
r V (r)e
−iK·r




2
(12.16)
When the scattering potential is spherically symmetric [V (r) = V (r)],
the expression for the cross section can be further simplified. In this case
we can expand the Born approximation out in spherical coordinates and
perform the integrals over θ and ϕ. Equation (12.16) becomes
dσ
dΩ
=
 m
2πℏ
2
2




Z
sin θ dθ dϕ r2
dr V (r)e
−iK·r




2
The integral over ϕ just gives 2π, and the integral over θ can be simplified by
choosing a coordinate system so that the polar axis points in the direction
of K; in this case K·r = Kr cos θ (note that this is not the same θ that
appears in Equation (12.15) and Figure 12.9). This gives
dσ
dΩ
=
 m
2πℏ
2
2




Z
sin θ dθ dϕ r2
dr V (r)e
−iKr cos θ




2
Integrating over both ϕ and θ, the expression for the cross section simplifies
to
dσ
dΩ
=
4m2
ℏ
4K2
Z ∞
r=0
sin(Kr)V (r)r dr2
(12.17)Scattering theory 299
V(r)
V0
R
r
Fig. 12.10 A repulsive spherical well has V = V0 inside a sphere of radius R, and V = 0
outside of this sphere.
Equation (12.17) is the form of the Born approximation applicable to any
spherically-symmetric potential.
Example 12.2. Scattering from a Three-Dimensional Repulsive
Spherical Well
A particle scatters from the three-dimensional repulsive spherical well of
radius R given by (Figure 12.10):
V (r) = V0, r ≤ R
V (r) = 0, r > R
The energy of the particle is much greater than V0. Use the Born approxi￾mation to calculate the differential cross section.
This is a spherically-symmetric potential, so we can use the form of the
Born approximation given by Equation (12.17). This gives
dσ
dΩ
=
4m2
ℏ
4K2
 Z R
r=0
sin(Kr)V0r dr!2300 Quantum Mechanics: An Accessible Introduction
ds
dΩ
kR sin(u/2)
1 2 3 4 5 6 7 8
Fig. 12.11 The differential cross section dσ/dΩ as a function of kR sin(θ/2) for a re￾pulsive spherical square-well potential of radius R, where k is the wave number of the
incident particle and θ is the scattering angle.
Integrating over r,
dσ
dΩ
=
4m2V
2
0
ℏ
4K2

sin(KR)
K2
−
R cos(KR)
K
2
Normally, dσ/dΩ is expressed in terms of the scattering angle θ; recall that
the magnitude of the momentum transfer K and the scattering angle θ are
related through K = 2k sin(θ/2), where k is the magnitude of both the
incident and scattered wave vector. Using this expression for K,
dσ
dΩ
=
4m2
ℏ
4
V
2
0 R
6

sin[2kR sin(θ/2)] − 2kR sin(θ/2) cos[2kR sin(θ/2)]
[2kR sin(θ/2)]3
2
A graph of the differential cross section as a function of kR sin(θ/2) is given
in Figure 12.11. The differential cross section has a large central peak at
small values of kR sin(θ/2) with tiny oscillations (barely visible on the scale
of this figure) at larger values.Scattering theory 301
Here is another example of the Born approximation, this time with a po￾tential that is not spherically symmetric.
Example 12.3. Scattering from a Delta-Function Potential
(a) A particle of mass m scatters off of a delta-function potential at the
origin:
V (x, y, z) = aℏ
2
m
δ(x)δ(y)δ(z)
(Here a is a constant with units of length, and the constant in front of
the delta functions ensures that V has units of energy.) Use the Born
approximation to calculate dσ/dΩ.
(b) Repeat this calculation with the delta-function potential located at
the point (b, 0, 0), so
V (x, y, z) = aℏ
2
m
δ(x − b)δ(y)δ(z)
(c) Now suppose that there are delta-function potentials at both (0, 0, 0)
and (b, 0, 0), so that
V (x, y, z) = aℏ
2
m
[δ(x − b)δ(y)δ(z) + δ(x)δ(y)δ(z)]
Calculate dσ/dΩ in this case, and compare it to the sum of the cross sections
in (a) and (b).
(a) Since we are dealing with potentials which are not symmetric about
the origin, we use the full Born approximation, Equation (12.16):
dσ
dΩ
=
 m
2πℏ
2
2




Z
d
3
r V (r)e
−iK·r




2
Substituting the first delta-function potential from part (a) gives
dσ
dΩ
=
 m
2πℏ
2
2




Z
dx dy dz aℏ
2
m
δ(x)δ(y)δ(z)e
−i(Kxx+Kyy+Kzz)




2
The integral over the delta function picks out the value x = 0, y = 0, z = 0
in the exponential, giving e
0 = 1, and the cross section reduces to
dσ
dΩ
=
a
2
4π
2
Note that the cross section has units of area, as expected.302 Quantum Mechanics: An Accessible Introduction
(b) For the delta function at (b, 0, 0), we have
dσ
dΩ
=
 m
2πℏ
2
2




Z
dx dy dz aℏ
2
m
δ(x − b)δ(y)δ(z)e
−i(Kxx+Kyy+Kzz)




2
=
a
2
4π
2

e
−iKxb


2
=
a
2
4π
2
i.e., the cross section is unchanged when the delta-function potential is
moved to a different position.
(c) Now consider the case with both delta functions together:
dσ
dΩ
=
 m
2πℏ
2
2




Z
dx dy dz aℏ
2
m
[δ(x − b)δ(y)δ(z)
+ δ(x)δ(y)δ(z)]e
−i(Kxx+Kyy+Kzz)




2
=
a
2
4π
2



e
−iKxb + e
i(0)



2
Using the identity
|1 + e
ix|
2 = 4 cos2
(x/2)
the cross section reduces to
dσ
dΩ
=

a
2
π
2

cos2

Kxb
2

Now we see an interesting result: the cross section calculated in part
(c) is not the sum of the cross sections in (a) and (b). The reason is the
wave nature of the scattering particle: just as for optical scattering, there
is interference between the waves scattering off of the two delta functions,
so the individual cross sections from the two delta functions cannot simply
be added together.
As noted several times, the Born approximation is valid when the potential
can be treated as a small perturbation, i.e., when the energy of the incident
particle is much greater than V . In the next section we consider the opposite
limit of low-energy scattering.Scattering theory 303
12.3 Partial Waves
Although the method of partial waves is simplest when the energy of the
incident particle is low, we do not need to introduce this assumption im￾mediately. Suppose we have an incident particle moving in the z direction,
and it scatters off of a spherically-symmetric potential V (r) centered at the
origin. As in the previous section, we will assume that V (r) → 0 as r → ∞.
The time-independent wave function for the incident particle far from the
origin is
ψi = e
ikz
but what about the wave function ψf for the scattered particle? In general,
the scattered particle is given by a wave expanding radially outward from
the scattering potential with an amplitude that depends on the angular
direction.
To construct the wave function corresponding to such a wave, consider
first the case of perfect spherical symmetry, i.e., a wave expanding radi￾ally outward with equal amplitude in all angular directions. This wave
represents a solution to the radial Schr¨odinger equation (Equation (6.40)):
−
ℏ
2
2m
∂
2
∂r2
(rR(r)) + ℏ
2
l(l + 1)
2mr2
rR(r) + V (r)rR(r) = ErR(r)
Since we are interested in a freely-expanding wave, we take V = 0, and
the condition that the wave be spherically symmetric implies that l = 0.
Further, we would like to express the particle momentum in terms of k,
rather than E, where E = ℏ
2k
2/2m. Then the radial Schr¨odinger equation
becomes
∂
2
∂r2
(rR) + k
2
(rR) = 0
which has the general solution
R = A
e
ikr
r
+ B
e
−ikr
r
where A and B are constants to be determined. The first term represents a
radially outgoing wave, while the second term represents a radially incoming
wave. Thus, for a scattered particle, the second term makes no sense on
physical grounds, so B must be zero, giving
R = A
e
ikr
r
(12.18)304 Quantum Mechanics: An Accessible Introduction
c = eikz
c =
e
ikr
r
Fig. 12.12 The wave function ψ = e
ikz represents a wave moving in the z direction;
ψ = e
ikr/r represents a spherically-symmetric wave moving radially outward.
Equation (12.18) represents the radial equivalent of a plane wave. Just as
e
ikz gives a wave moving in the z direction, the quantity e
ikr/r represents
a spherically-symmetric wave moving radially outward (Figure 12.12).
Now, if a particle scatters from the potential, the outgoing wave need
no longer be isotropic. Since we have assumed a spherically-symmetric
potential, the amplitude of the scattered wave can be a function of θ, but
it should be independent of ϕ. The most general form we can write for a
radially-expanding wave with a dependence on θ is
ψf = f(θ)
e
ikr
r
and the total wave function far from the origin, including both the incident
and scattered particle, will be
ψT = ψi + ψf
= e
ikz + f(θ)
e
ikr
r
(12.19)
The cross section is a function of f(θ). To determine this function, we
express the cross section in terms of scattered energy rather than discrete
particles:
dσ
dΩ
=
scattered energy/solid angle
incident energy
=
r
2
|ψf |
2
|ψi
|
2Scattering theory 305
Substituting our expressions for ψi and ψf gives
dσ
dΩ
= |f(θ)|
2
So the problem of determining the differential cross section reduces to solv￾ing the Schr¨odinger equation in order to find f(θ).
We will derive such a solution in the region far from the potential, so
that V = 0. The radial Schr¨odinger equation for V = 0 can be written as
∂
∂r2
(rR(r)) −
l(l + 1)
r
R(r) + k
2
(rR(r)) = 0
This equation can be solved exactly for any value of l; the solutions for
R(r) are called spherical Bessel functions and are written as jl(kr). These
solutions, for the first few values of l, are
l = 0 : R = j0(kr) = sin(kr)
kr
l = 1 : R = j1(kr) = sin(kr)
(kr)
2
−
cos(kr)
kr
l = 2 : R = j2(kr) = 
3
(kr)
3
−
1
kr 
sin(kr) −
3 cos(kr)
(kr)
2
As usual, the general solution to the Schr¨odinger equation is the product
of this radial solution and the appropriate spherical harmonic:
ψ(r, θ, ϕ) = jl(kr)Y
m
l
(θ, ϕ) (12.20)
However, this result leads to a puzzle. We already have a set of solutions
to the Schr¨odinger equation with V = 0, namely,
ψ = e
ik·r
(12.21)
Thus, it would appear that there are two different sets of solutions to the
three-dimensional Schr¨odinger equation for the case of V = 0. In fact, both
sets of solutions [Equations (12.20)–(12.21)] are valid. They simply repre￾sent solutions in spherical and rectangular coordinate systems, respectively.
Furthermore, either set of solutions can be used as a basis set. This means,
for example, that an incoming wave in the z direction can be written as a
sum of spherical waves:
e
ikz =
X
l,m
clmjl(kr)Y
m
l
(θ, ϕ) (12.22)
where clm’s are the constants in the expansion.306 Quantum Mechanics: An Accessible Introduction
p
p
s
s
V r0
Fig. 12.13 A particle with momentum p scatters off of a potential V of radius r0. The
potential will affect the particle only if the point of closest approach s is smaller than r0.
Physically, Equation (12.22) corresponds to expressing a plane wave as
the sum of wave functions with different angular momenta. This expansion
is useful because we can now show that, in the low-energy limit, it can be
a good approximation to retain only the l = 0 term. To see the reason for
this, consider a particle scattering off of a potential with fixed radius r0,
so that V is negligible for r > r0. The spherical Bessel functions have the
property that for kr ≪ l,
jl(kr) ∝ (kr)
l
Thus, if k is sufficiently small that kr0 ≪ 1, all of the spherical Bessel
functions are negligible in the vicinity of the potential (r < r0) except for
l = 0. In this case only the l = 0 component of the incident plane wave
“feels” the potential.
This argument has a simple classical analog. Consider a particle with
momentum p scattering off of a potential that vanishes for r > r0 (Fig￾ure 12.13). Let s be the closest distance that the particle attains relative
to the center of the potential. Since the potential is negligible for distances
greater than r0, scattering can occur only if s < r0. But this immediately
tells us something about the angular momentum of the particle relative to
the origin. The angular momentum is L = ps, and the requirement that
s < r0 translates into the relation
L < pr0Scattering theory 307
Thus, in the classical case, low-energy scattering also translates into low
angular momentum scattering.
We can assume then that in the low-energy limit, only the l = 0 compo￾nent of the incoming wave is scattered and the higher l waves are unaffected.
Therefore, this approximation is called s-wave scattering where s indicates
that l = 0. In this limit we write the sum in Equation (12.22) as
e
ikz = c00j0(kr)Y
0
0
(θ, ϕ) +X
l>0
clmjl(kr)Y
m
l
(θ, ϕ) (12.23)
To find c00 we multiply both sides of Equation (12.23) by Y
0∗
0
, set z =
r cos θ on the left-hand side, and integrate over θ and ϕ. Because of the
orthogonality of the spherical harmonics, only the first term on the right￾hand side contributes, and we get
Z
e
ikr cos θY
0∗
0
sin θ dθ dϕ =
Z
c00j0(kr)|Y
0
0
|
2
sin θ dθ dϕ
Taking Y
0
0 = 1/
√
4π and j0(kr) = sin(kr)/kr and performing the integra￾tions gives
1
√
4π
2π
1
ikr
￾
e
ikr − e
−ikr
= c00
sin(kr)
kr (12.24)
Now we recall that sin(x) = (e
ix −e
−ix)/2i, so Equation (12.24) reduces to
c00 =
√
4π
Using this value for c00 and writing j0 = sin(kr)/kr in terms of complex
exponentials, we can express Equation (12.23) as
e
ikz =
1
2i

e
ikr
kr −
e
−ikr
kr 
+
X
l>0
terms
Note that this represents the incident wave ψi
. What does the scattered
wave look like? Since we have assumed that only the l = 0 part of the wave
is actually affected by the potential, the only contribution of the scattering
will be an outgoing spherical wave with l = 0. Thus, the total wave function
ψT = ψi + ψf will be
ψT =
1
2i

η0
e
ikr
kr −
e
−ikr
kr 
(12.25)
where we have dropped the l > 0 terms, and the effect of the scattering
has been to add a term proportional to e
ikr/kr. We do not yet know
the amplitude of this additional term, so we have absorbed it into a new
unknown complex number η0, which we need to calculate308 Quantum Mechanics: An Accessible Introduction
Conservation of particle probability means that |η0|
2 = 1, so it is con￾ventional to re-express η0 in terms of a function with unit magnitude
η0 = e
2iδ0
(12.26)
where δ0, defined by Equation (12.26), is called the s-wave phase shift. In
order to calculate a cross section, we need to write ψT in Equation (12.25)
in the form of an incident plane wave and a scattered spherical wave (as in
Equation (12.19)). Pulling out the terms that correspond to the incident
plane wave e
ikz and expressing η0 in terms of δ0, we get
ψT = e
ikz +

e
2iδ0 − 1
2ik 
e
ikr
r
Then the cross section is
dσ
dΩ
= |f(θ)|
2
=




e
2iδ0 − 1
2ik




2
=
sin2
δ0
k
2
Note that the differential cross section in this case is completely isotropic,
i.e., independent of the scattering angle. This is because of our assumption
of s-wave scattering; in this limit only the l = 0 part of the wave undergoes
scattering, and the l = 0 wave is isotropic. The total cross section is then
just
σ = 4π
sin2
δ0
k
2
(12.27)
Of course, the problem now is to find the phase shift δ0; this calculation is
performed by solving the Schr¨odinger equation for the scattering potential,
as shown here.
Example 12.4. Low-Energy Scattering from an Infinitely Hard
Sphere
A particle is incident on a central potential V (r) which is infinitely high
at r ≤ a with V = 0 for r > a. The energy of the particle is sufficiently
low that s-wave scattering is a good approximation. Find the total cross
section.Scattering theory 309
The wave function outside the potential is given by Equation (12.25):
ψT =
1
2i

η0
e
ikr
kr −
e
−ikr
kr 
=
1
2i

e
ikr+2iδ0
kr −
e
−ikr
kr 
At the surface of the potential, r = a, the infinite potential forces the wave
function to zero, so ψT (r = a) = 0. This means that
e
ika+2iδ0 − e
−ika = 0
which has the solution δ0 = −ka. Then the s-wave expression for the cross
section, Equation (12.27), gives
σ = 4π
sin2
ka
k
2
In the low-energy limit, k → 0, and we get
σ = 4πa2
Note that this is four times the classical scattering cross section from a hard
sphere (Example 12.1). In the classical case, the incident particle “sees”
the geometrical cross-sectional area of the sphere, which is just πa2
. In
the quantum mechanical system, the incident particle acts like a wave and
diffracts around the target, giving a larger cross section.
The idea of s-wave scattering can be extended by summing over all of the
l’s in the spherical wave expansion and finding the phase shift δl for each
partial wave. The result is a total cross section which looks like
σ =
4π
k
2
X∞
l=0
(2l + 1) sin2
δl
The case of s-wave scattering, which is the only one we have examined in
detail, can be obtained from this result by taking only the l = 0 term in
the series.
PROBLEMS
12.1 Show that in the Born approximation, the differential cross section
obtained from the negative of a given potential −V (r) is exactly
the same as that obtained from the potential V (r).310 Quantum Mechanics: An Accessible Introduction
12.2 An incident particle with mass m, velocity v, and charge ze scatters
off of a charge Ze at the origin. Use the Born approximation to
calculate the differential scattering cross section for the screened
Coulomb potential
V (r) = (zZe2
/4πϵ0r)e
−r/d
Then let d → ∞, so that V (r) approaches the normal Coulomb po￾tential, and show that dσ/dΩ approaches the Rutherford scattering
differential cross section
dσ
dΩ
=

1
4πϵ0
2
zZe2
2mv2
2
1
sin4
(θ/2)
12.3 (a) A particle with charge +e is incident on an electric dipole con￾sisting of a charge of +e and a charge of −e separated by the vector
d (which runs from −e to +e). The energy of the incident particle
is sufficiently large to treat the dipole as a small perturbation. Cal￾culate the differential scattering cross section dσ/dΩ as a function
of the initial wave vector ki
, the scattered wave vector kf , and the
standard Rutherford scattering cross section (dσ/dΩ)R, given by

dσ
dΩ

R
=



−
m
2πℏ
2
Z
d
3
r Vc(r)e
−iK·r




2
where K = kf − ki and Vc(r) is the Coulomb potential.
(b) In the limits kid ≪ 1 and kid ≫ 1, determine whether the
dipole differential cross section is larger or smaller than the Ruther￾ford differential cross section. Explain the physical reason for these
results.
12.4 A particle which is travelling in the +z direction scatters off of
a potential consisting of four delta functions at the vertices of a
square in the x-y plane at the points (−a, 0, 0), (+a, 0, 0), (0, −a,
0), and (0, +a, 0).Scattering theory 311
y
x
The potential is
V = Aδ(x + a)δ(y)δ(z) + Aδ(x − a)δ(y)δ(z)
+ Aδ(x)δ(y + a)δ(z) + Aδ(x)δ(y − a)δ(z)
where A is a constant. Use the Born approximation to calculate the
differential scattering cross section. Express the answer in terms
of the magnitude of the incident wave vector k and the scattering
angles θ and ϕ. (This is an example where the cross section does
depend on ϕ.)
12.5 (a) A particle of mass m and energy E scatters off of the central
potential V (r) = Ar−2
, where A is a constant. Use the Born
approximation to calculate the differential cross section dσ/dΩ as
a function of E and the scattering angle θ.
(b) Show that the total cross section σ is infinite.
12.6 A particle of mass m is incident on the potential V (r) = V0e
−r/r0
,
where V0 and r0 are constants with units of energy and length,
respectively. The potential is independent of θ and ϕ. The energy
of the particle is large, so that the potential can be treated as a
small perturbation. Calculate the differential scattering cross sec￾tion dσ/dΩ. Express the final answer as a function of the scattering
angle θ and the energy of the particle E.312 Quantum Mechanics: An Accessible Introduction
12.7 (a) A particle with mass m scatters off of the potential
V = Aδ(z), for −a ≤ x ≤ a and −a ≤ y ≤ a
V = 0, otherwise
where A is a constant. In other words, this potential forms a square
in the x-y plane and is infinitesimally thin in the z direction. Use
the Born approximation to calculate the differential scattering cross
section. (Assume an arbitrary direction for the incident particle,
and express the answer in terms of the momentum transfer vector
K = kf − ki
.)
(b) Show that in the limit where a → ∞ (so that the scattering
potential occupies the entire x-y plane), the resulting differential
cross section corresponds to only two possible results: either the
particle will pass through without any scattering or else it will
scatter with the angle of incidence equal to the angle of reflection.
12.8 Suppose a particle with mass m scatters off of a finite spherical
potential of radius R0 given by
V (r) = V0 (r ≤ R0)
V (r) = 0 (r > R0)
In the limit where the energy of the incident particle is small, show
that the total cross section is
σ = 4πR2
0

tanh(kR0)
kR0
− 1
2
where k =
p
2m(V0 − E)/ℏ
2.Chapter 13
Multiparticle Schr¨odinger equation
Thus far, we have examined the solution of the Schr¨odinger equation for
a single particle. However, the real world consists of systems composed of
many particles. While it is straightforward to generalize the Schr¨odinger
equation to systems of many particles, something very interesting happens
when dealing with systems of identical particles: the requirement that two
particles be treated as identical imposes certain restrictions on the proper￾ties of the wave function.
When dealing with systems containing multiple particles, we will not
write down a separate wave function for each particle. Instead, we will
have a single wave function that encodes the information about all of the
particles together. We will show that for systems of identical particles, the
wave function is either unchanged or multiplied by −1 when any two of the
particles are exchanged. This, in turn, leads to an important result called
the Pauli Exclusion Principle, which turns out to be crucial to the very
existence of matter as we know it.
13.1 Wave Function for Identical Particles
For a single particle with definite energy E, the Schr¨odinger equation has
the familiar form
−
ℏ
2
2m
∇2ψ(r) + V (r)ψ(r) = Eψ(r)
Now suppose that we have two particles, not necessarily identical. In order
to treat these two particles as a single system, we must have a single wave
function which combines the information for both particles (i.e., instead of
separate wave functions for each particle). This wave function is written
as ψ(r1, r2). The physical interpretation of this wave function in terms of
313314 Quantum Mechanics: An Accessible Introduction
probabilities is similar to the one-particle wave function. Recall that for
a single particle, |ψ(r)|
2 d
3
r gives the probability that the particle can be
found in a small volume d
3
r near r. For the two-particle wave function,
|ψ(r1, r2)|
2 d
3
r1 d
3
r2 gives the probability that particle 1 is located in the
small volume d
3
r1 near r1 and particle 2 is located in the small volume
d
3
r2 near r2.
Example 13.1. Interpretation of the Two-Particle Wave Function
Two particles are confined in an infinite one-dimensional square well with
width a. They are in a state with a wave function given by
ψ(x1, x2) = 2
a
sin πx1
a

sin πx2
a

A measurement is made of the positions of both particles. Calculate the
probability that particle 1 is on the left-hand side of the potential well
(x < a/2) and particle 2 is on the right-hand side (x > a/2).
This probability is
P =
Z a/2
x1=0
Z a
x2=a/2
|ψ(x1, x2)|
2
dx1 dx2
=
Z a/2
x1=0
Z a
x2=a/2
4
a
2
sin2
πx1
a

sin2
πx2
a

dx1 dx2
=
4
a
2

x1
2
−
a
4π
sin 
2πx1
a
a/2
x1=0

x2
2
−
a
4π
sin 
2πx2
a
a
x2=a/2
=
1
4
The two-particle wave function ψ(r1, r2) obeys the Schr¨odinger equation
in the form
−
ℏ
2
2m
∇2
1ψ(r1, r2) −
ℏ
2
2m
∇2
2ψ(r1, r2) + V (r1, r2)ψ(r1, r2) = Eψ(r1, r2)
(13.1)
where the symbol ∇2
1
is the sum of second derivatives taken with respect
to r1:
∇2
1 =
∂
2
∂x2
1
+
∂
2
∂y2
1
+
∂
2
∂z2
1
and, similarly, for ∇2
2
the derivatives are taken with respect to r2:
∇2
2 =
∂
2
∂x2
2
+
∂
2
∂y2
2
+
∂
2
∂z2
2Multiparticle Schr¨odinger equation 315
e
–
1
e
–
2
e
–
2
e
–
1
Electrons
interchanged
e
–
1
e
–
2
e
–
1
e
–
2
Electrons not
interchanged
Fig. 13.1 Electron 1 and electron 2 are indistinguishable. It is therefore impossible to
determine whether or not they have been interchanged.
and the potential V is now a function of the positions of both particles. So
far, this is a straightforward generalization of the one-particle wave function
and one-particle Schr¨odinger equation. Now, however, we introduce a twist.
Subatomic particles have the property that any two of the same kind of par￾ticle (two protons, two electrons, etc.) are indistinguishable. This means
that they have exactly the same mass, the same spin, etc. In practical
terms, consider the following experiment: two electrons are placed at two
different locations in a laboratory (Figure 13.1). You turn your back, and
the laboratory assistant either leaves the electrons in place or interchanges
the two particles. When you again observe the electrons, there is literally
no way to determine whether or not the electrons have been interchanged,
since they are absolutely identical. This is a practical definition of indis￾tinguishable particles. This property of indistinguishability has profound
consequences.
To determine these consequences, define a new operator called the ex￾change operator, E12 which has the effect of interchanging particle 1 and
particle 2. Thus, the effect of the exchange operator on the wave function
is
E12ψ(r1, r2) = ψ(r2, r1)316 Quantum Mechanics: An Accessible Introduction
It is possible to show (Problem 13.1) that the exchange operator commutes
with the Hamiltonian as long as the two-particle potential has the property
that
V (r1, r2) = V (r2, r1) (13.2)
In fact, most reasonable potentials have this property; the most common
situation is for two particles each to be subject to the same external po￾tential, and to interact with each other via a potential that is symmetric
under the interchange of the two particles. For example, each electron in
the helium atom experiences the Coulomb potential of the nucleus, and
the electrons also repel each other via a Coulomb potential, leading to the
potential
V (r1, r2) = −
2e
2
4πϵ0
1
r1
−
2e
2
4πϵ0
1
r2
+
e
2
4πϵ0
1
|r1 − r2|
(13.3)
Clearly, this potential satisfies Equation (13.2). We will assume throughout
the remainder of this chapter that we are dealing exclusively with Hamil￾tonians that commute with the exchange operator.
Therefore, we can take the two-particle wave function to be an eigen￾function of E12 and attempt to determine the possible eigenvalues. Let γ
be an eigenvalue of E12:
E12ψ(r1, r2) = γψ(r1, r2)
Now note that for any wave function, applying E12 twice simply restores
the original wave function; the particles are interchanged, then interchanged
back to their original positions. Mathematically,
E
2
12ψ(r1, r2) = E12ψ(r2, r1) = ψ(r1, r2) (13.4)
But if ψ(r1, r2) is an eigenfunction of E12 with eigenvalue γ, then applying
E12 twice will pull out a factor of γ
2
:
E
2
12ψ(r1, r2) = γ
2ψ(r1, r2) (13.5)
Combining Equations (13.4) and (13.5) gives the possible values for γ:
γ
2 = 1
so
γ = ±1
Therefore, the exchange operator can produce only two possible results
when applied to the wave function. If γ = 1, then the eigenfunctionMultiparticle Schr¨odinger equation 317
equation gives E12ψ(r1, r2) = ψ(r1, r2), while the definition of E12 gives
E12ψ(r1, r2) = ψ(r2, r1) so that
ψ(r1, r2) = ψ(r2, r1) (13.6)
and the wave function is symmetric under the interchange of the two
particles. Conversely, if γ = −1, then E12ψ(r1, r2) = −ψ(r1, r2), and
E12ψ(r1, r2) = ψ(r2, r1) so
ψ(r1, r2) = −ψ(r2, r1) (13.7)
and the wave function is antisymmetric under the interchange of the two
particles.
It is observed in nature that any given particle obeys either Equa￾tion (13.6) or Equation (13.7) but not both. Particles with wave functions
that are symmetric under particle interchange are said to obey Bose–
Einstein statistics and are called bosons, while particles with wave func￾tions that are antisymmetric under particle interchange obey Fermi–Dirac
statistics and are called fermions. It is further observed that the category
that a given particle belongs to is entirely determined by its spin. Par￾ticles with integer spin (s = 0, 1, 2, . . .) behave as bosons, while particles
with half-integer spin (s = 1/2, 3/2, . . .) behave as fermions. Hence, the
electron, proton, and neutron, each with spin 1/2, are fermions, while the
photon, with spin 1, is a boson.
This result leads immediately to the Pauli exclusion principle, which
states that two fermions cannot occupy the same quantum state. For ex￾ample, suppose that the two electrons in the helium atom have all of the
same quantum numbers, and represent the two-particle wave function in
Dirac notation as |1 2 ⟩. If the two electrons have exactly the same quan￾tum numbers, then the wave function is invariant when the two electrons
are exchanged, i.e., |1 2 ⟩ = |2 1 ⟩. However, this contradicts the fact that
the wave function of two fermions must be antisymmetric under their in￾terchange: |1 2 ⟩ = −|2 1 ⟩. Hence, two fermions cannot occupy the exact
same quantum state. If it were not for the exclusion principle, all of the
electrons in a multielectron atom would simply drop down into the ground
state, n = 1. It is the exclusion principle which forces the electrons into
higher-energy states, making atoms and chemistry as we know it possible.
(This is discussed in more detail in Section 13.2.)
More generally, the symmetry or antisymmetry of the wave function
restricts the allowed solutions of the Schr¨odinger equation. As an example,
consider a potential of the form
V (r1, r2) = V0(r1) + V0(r2) + V1(|r1 − r2|)318 Quantum Mechanics: An Accessible Introduction
for which both particles experience the same external potential V0 while
interacting with each other via the potential V1. The Schr¨odinger equation
is difficult to solve with a general potential of this type, but it is instructive
to take the limit where V1 ≪ V0, so that as a first approximation, the
interaction potential can be ignored. Even in this limit, the particles still
affect each other through the requirement that the wave function be either
symmetric or antisymmetric. When V1 ≪ V0, the two-particle Schr¨odinger
equation (Equation (13.1)) takes the form
−
ℏ
2
2m
∇2
1ψ(r1, r2) + V (r1)ψ(r1, r2) −
ℏ
2
2m
∇2
2ψ(r1, r2) + V (r2)ψ(r1, r2)
= Eψ(r1, r2) (13.8)
where we have dropped the “0” subscript on the potential for simplicity.
Equation (13.8) is applicable whenever two particles experience the same
external potential but do not interact directly with each other.
This equation resembles the sum of two single-particle Schr¨odinger equa￾tions, and this property can be exploited to find a solution of the two￾particle equation. Suppose that the single-particle Schr¨odinger equation
with potential V ,
−
ℏ
2
2m
∇2ψ(r) + V (r)ψ(r) = Eψ(r)
can be solved exactly, yielding single-particle wave functions and corre￾sponding energies ψn(r) and En, respectively. Then we can verify by di￾rection substitution into Equation (13.8) that the product of any two of
these solutions for the two particles, ψm(r1)ψn(r2), is a solution of Equa￾tion (13.8):
−
ℏ
2
2m
∇2
1
[ψm(r1)ψn(r2)] + V (r1)[ψm(r1)ψn(r2)]
−
ℏ
2
2m
∇2
2
[ψm(r1)ψn(r2)] + V (r2)[ψm(r1)ψn(r2)]
= ψn(r2)

−
ℏ
2
2m
∇2
1ψm(r1) + V (r1)ψm(r1)

+ ψm(r1)

−
ℏ
2
2m
∇2
2ψn(r2) + V (r2)ψn(r2)

= ψn(r2)Emψm(r1) + ψm(r1)Enψn(r2)
= (Em + En)ψm(r1)ψn(r2)
Thus, a general solution to Equation (13.8) is the wave function ψmn(r1, r2)
given by
ψmn(r1, r2) = ψm(r1)ψn(r2) (13.9)Multiparticle Schr¨odinger equation 319
where ψm and ψn are the eigenfunctions of the one-particle Schr¨odinger
equation with potential V , and the energy corresponding to ψmn is
Emn = Em + En
Although ψmn satisfies the two-particle Schr¨odinger equation, this solution
is neither symmetric nor antisymmetric under the exchange of the two
particles. The way to resolve this problem is to note that there are actually
two different solutions which have the same energy Emn; in addition to the
solution in Equation (13.9), there is another solution obtained by switching
m and n:
ψnm(r1, r2) = ψn(r1)ψm(r2)
Since both of these wave functions correspond to the same energy, Em +En,
any linear combination of them will also satisfy the Schr¨odinger equation
and have energy Em + En. In particular, these two solutions can be com￾bined to produce a wave function that is symmetric under interchange of
the two particles:
ψmn(r1, r2)symm =
1
√
2
[ψm(r1)ψn(r2) + ψn(r1)ψm(r2)] (13.10)
and a wave function that is antisymmetric under interchange of the two
particles:
ψmn(r1, r2)antisymm =
1
√
2
[ψm(r1)ψn(r2) − ψn(r1)ψm(r2)] (13.11)
where the 1/
√
2 factor insures that the two-particle wave functions are nor￾malized as long as the individual one-particle wave functions are correctly
normalized. These, then, are the symmetric and antisymmetric solutions
to the two-particle Schr¨odinger equation.
One special case must be treated separately: the wave functions for
which n = m. For the case of antisymmetric wave functions, Equa￾tion (13.11) gives ψnn = 0, so such wave functions are not allowed.
(This is another corollary of the exclusion principle.) Thus, if the allowed
single-particle wave functions correspond to the quantum number n, where
n = 1, 2, 3, . . . , then for antisymmetric wave functions, the lowest-energy
state is n = 1, m = 2. For symmetric wave functions, there is no similar
restriction; the state m = n gives a perfectly acceptable wave function,
and m = 1, n = 1 is the lowest-energy state. However, in this case the
normalizing factor 1/
√
2, which is derived based on the assumption that320 Quantum Mechanics: An Accessible Introduction
ψm(r1)ψn(r2) and ψn(r1)ψm(r2) are orthogonal wave functions, is no longer
correct. Instead, the normalized wave function is simply
ψnn(r1, r2) = ψn(r1)ψn(r2) (13.12)
The spin states of the particles produce an additional complication, but
before adding this complication, consider a solution for spinless particles.
Example 13.2. Two Identical Spin-0 Particles in an Infinite
One-Dimensional Square Well
Two identical spin-0 particles are confined in an infinite one-dimensional
square well with width a. Find the energy levels and corresponding wave
functions, and determine the ground state.
The individual wave functions for the infinite one-dimensional square
well are
ψ(x) = r
2
a
sin nπx
a

with energy
En =
π
2ℏ
2
2ma2
n
2
Since the particles have spin 0, they are bosons, and their wave function
must be symmetric as in Equations (13.10) and (13.12). Therefore, the total
wave function is
ψmn(x1, x2) = 1
√
2
2
a
h
sin mπx1
a

sin nπx2
a

+ sin nπx1
a

sin mπx2
a
i
for m ̸= n, and for m = n the solution is
ψnn =
2
a
sin nπx1
a

sin nπx2
a

with, in either case, a corresponding energy of
Emn = Em + En
=
π
2ℏ
2
2ma2
[m2 + n
2
]
The ground-state energy is then
E11 =
π
2ℏ
2
ma2
and the ground-state wave function is
ψ11 =
2
a
sin πx1
a

sin πx2
a

This was the wave function used in Example 13.1.Multiparticle Schr¨odinger equation 321
What happens when the particles have spin? As a specific example,
consider the case of two spin-1/2 particles. Recall from Chapter 8 that the
spin states can be expressed in terms of the total spin quantum number
for the two particles s and the z component of this total spin ms. These
states, in turn, are related to the “spin up” and “spin down” states of the
individual particles through the relations:
| 1 1⟩ = | ↑ ↑⟩
| 1 0⟩ =
1
√
2
| ↑ ↓⟩ +
1
√
2
| ↓ ↑⟩
| 1 − 1⟩ = | ↓ ↓⟩
| 0 0⟩ =
1
√
2
| ↑ ↓⟩ − 1
√
2
| ↓ ↑⟩
where the states on the left-hand side of these equations are the |s ms⟩
states, and the states on the right-hand side are the spin up or spin down
states of the two individual particles.
Now note an important point: All three of the triplet states (i.e., the
states with s = 1) are symmetric under interchange of the two particles,
while the singlet state (s = 0) is antisymmetric under interchange of the
two particles. When the exchange operator is applied to two particles, it in￾terchanges both their spatial positions and their spins (Figure 13.2). Hence,
in considering whether a wave function is symmetric or antisymmetric un￾der particle exchange, the full wave function must include both the spatial
wave function and the spin wave function. For two spin-1/2 particles, for
example, we write the full wave function |1 2⟩ as the product of the spatial
part of the wave function and spin part of the wave function:
|1 2⟩ ⇒ ψ(r1, r2)|s ms⟩
and we require that this total wave function be symmetric for bosons and
antisymmetric for fermions. Since the spatial part of the wave function
can be either symmetric or antisymmetric, and the spin part of the wave
function can be either symmetric or antisymmetric, there are only four
possibilities:
ψ(r1, r2) is symmetric, |s ms⟩ is symmetric → total wave function is sym￾metric
ψ(r1, r2) is antisymmetric, |s ms⟩ is symmetric → total wave function is
antisymmetric
ψ(r1, r2) is symmetric, |s ms⟩ is antisymmetric → total wave function is
antisymmetric322 Quantum Mechanics: An Accessible Introduction
1
12
2
2
1
Fig. 13.2 The exchange operator interchanges both the positions and spins of the two
particles.
ψ(r1, r2) is antisymmetric, |s ms⟩ is antisymmetric → total wave function
is symmetric.
Thus, for bosons the spatial part of the wave function and the spin part
of the wave function must either be both symmetric or both antisymmet￾ric. For fermions, a symmetric spin state implies an antisymmetric spatial
wave function, and an antisymmetric spin state implies a symmetric spatial
wave function. Thus, two spin-1/2 particles in the triplet state will have
an antisymmetric spatial wave function, while two spin-1/2 particles in the
singlet state will have a symmetric spatial wave function. It is impossi￾ble to determine the spatial wave function and spin state in isolation; the
knowledge of one is needed to determine the possible choices for the other.
Example 13.3. Two Identical Spin-1/2 Particles in an Infinite
One-Dimensional Square Well
Two identical spin-1/2 particles are confined in an infinite one-dimensional
square well with width a. Find the spatial wave function and energy for
the lowest-energy singlet state and lowest-energy triplet state, respectively.
The singlet state has an antisymmetric spin state and, therefore, a sym￾metric spatial wave function. Thus, the lowest energy state is the same asMultiparticle Schr¨odinger equation 323
in Example 13.2: the state m = n = 1:
ψ11 =
2
a
sin πx1
a

sin πx2
a

with energy
E11 =
π
2ℏ
2
ma2
For the triplet state, the spin state is symmetric, so the spatial wave
function must be antisymmetric. For this case, m = n is not allowed, and
the lowest energy state corresponds to the antisymmetric wave function
with m = 1, n = 2:
ψ12(x1, x2) = 1
√
2
2
a

sin πx1
a

sin 
2πx2
a

− sin 
2πx1
a

sin πx2
a


with energy
E12 =
π
2ℏ
2
2ma2
[12 + 22
]
=
5π
2ℏ
2
2ma2
The requirement that the fermion states must be antisymmetric has a
profound effect on the behavior of electrons in atoms. This will be ex￾plored in more detail in the next section; here we examine the simplest
multielectron atom: the helium atom.
Example 13.4. The Ground State of the Helium Atom
The full potential for the two electrons in a helium atom is given by Equa￾tion (13.3):
V (r1, r2) = −
2e
2
4πϵ0
1
r1
−
2e
2
4πϵ0
1
r2
+
e
2
4πϵ0
1
|r1 − r2|
(13.13)
As a first approximation, we neglect the final term which represents the
mutual repulsion between the two electrons. In this limit the electrons
are treated as independent particles which each feel the central Coulomb
potential produced by the nucleus with charge +2e.
Writing the spatial part of the one-particle wave function in the standard
form ψnlml
, the lowest-energy wave function for a single electron in the
potential V = −2e
2/4πϵ0r is
ψ
He
100 =
1
√
π

2
a0
3/2
e
−2r/a0324 Quantum Mechanics: An Accessible Introduction
with energy
E
He
1 = 4E
H
1
where the “He” superscript refers to the wave function and energy of a
single electron in the Coulomb potential of the helium nucleus, and the
“H” superscript refers to the corresponding quantities in hydrogen. Since
EH
1
is the ground-state energy of hydrogen, we have EH
1 = −13.6 eV, so
EHe
1 = −54.4 eV.
For the helium atom to be in the lowest possible energy state, both
electron wave functions must correspond to ψ
He
100, so the spatial part of the
wave function is symmetric:
ψ(r1, r2) = ψ
He
100(r1)ψ
He
100(r2)
=
8
πa3
0
e
−2r1/a0 e
−2r2/a0
(13.14)
Since the spatial part of the wave function is symmetric, and the electrons
are fermions, which must have an antisymmetric total wave function, the
spin part of the wave function must be antisymmetric. Thus, the two
electrons in the helium atom must be in the singlet state:
|0 0⟩ =
1
√
2
| ↑ ↓⟩ − 1
√
2
| ↓ ↑⟩ (13.15)
In elementary explanations of atomic structure, it is often stated that the
atomic electrons fill the lowest possible energy states (in this case, the two
states with n = 1, l = 0, ml = 0) but then to fulfill the Pauli exclusion prin￾ciple, the electrons must have opposite spins. However, Equation (13.15)
shows that this explanation is an oversimplification: the two electrons are
not forced into a state, for instance, where electron 1 has spin up and elec￾tron 2 has spin down. Rather, they are forced into the singlet spin state
with total spin s = 0 and ms = 0; the spins of the electrons are a mixture
of | ↑ ↓⟩ and | ↓ ↑⟩.
The total energy corresponding to the spatial wave function in Equa￾tion (13.14) is E = 2EHe
1 = −108.8 eV, while the true ground-state energy
of helium is −79.0 eV. Thus, our estimate of the ground-state energy is
rather far off the mark. However, this estimate can be improved by treat￾ing the electron-electron repulsion (the last term in Equation 13.13) as a
perturbation and applying first-order perturbation theory.Multiparticle Schr¨odinger equation 325
The change in the energy due to this repulsion is then
E
(1) =
Z
d
3
r1 d
3
r2

8
πa3
0
e
−2r1/a0 e
−2r2/a0
  e
2
4πϵ0
1
|r1 − r2|


8
πa3
0
e
−2r1/a0 e
−2r2/a0

=
5
4
e
2
4πϵ0a0
= 34.0 eV
As expected, this change in the energy is positive since it represents a repul￾sion between the two electrons. Adding it to the energy of the unperturbed
two-particle wave function, we get an estimate of the total ground-state
energy: E = −108.8 eV + 34.0 eV = −74.8 eV. This differs from the true
ground-state energy by about 5%, which is not bad agreement (although
the variational principle, Chapter 10, does provide a better estimate for
this energy).
These arguments that we have derived for the two-particle wave function
can be extended to systems of more particles. For instance, the total wave
function for three fermions must be antisymmetric under interchange of any
two of the particles. If the spin part is symmetric, then this implies, for
example,
ψ(r1, r2, r3) = −ψ(r2, r1, r3) = −ψ(r1, r3, r2)
and so on. If ψ1(r), ψ2(r), ψ3(r) are three different solutions to the one￾particle Schr¨odinger equation, then the fully antisymmetric spatial wave
function is given by
ψ(r1, r2, r3) = 1
√
6
[ψ1(r1)ψ2(r2)ψ3(r3) − ψ1(r2)ψ2(r1)ψ3(r3)
− ψ1(r1)ψ2(r3)ψ3(r2) − ψ1(r3)ψ2(r2)ψ3(r1)
+ ψ1(r2)ψ2(r3)ψ3(r1) + ψ1(r3)ψ2(r1)ψ3(r2)]
This can be written in a particularly compact form as a determinant:
ψ(r1, r2, r3) = 1
√
6






ψ1(r1) ψ1(r2) ψ1(r3)
ψ2(r1) ψ2(r2) ψ2(r3)
ψ3(r1) ψ3(r2) ψ3(r3)





326 Quantum Mechanics: An Accessible Introduction
which is called a Slater determinant. Of course, the usefulness of this
approach diminishes as the number of particles increases. For the uranium
atom, for instance, the Slater determinant for the electrons is a 92 × 92
determinant, which expands out into 92! ∼ 10142 terms. (This expansion
written out would far exceed the length of the entire visible universe.)
Clearly, other approaches are called for.
13.2 Multielectron Atoms
The electron in hydrogen is characterized by four quantum numbers: n,
l, ml
, and ms. For electrons in multielectron atoms, the electron-electron
interactions alter the wave functions and energy levels, and it is not possible
to solve the Schr¨odinger equation analytically. On the other hand, the
electrons in a multielectron atom can still be characterized by the same set
of quantum numbers, and the Pauli exclusion principle prevents any two
electrons from sharing the same complete set of quantum numbers.
Recall that for the hydrogen atom, the energy of a given state is entirely
determined by the principle quantum number n; all l, ml
, and ms states for
a given n have the same energy (aside from the small perturbations which
were discussed in Chapter 9). In multielectron atoms, the electron-electron
interactions break this degeneracy so that the energy of a given electron
depends on both n and l. However, the various ml and ms states for a given
n and l are still degenerate in energy (since they represent quantities which
depend on the orientation of the coordinate system). For this reason, the
set of all possible ml and ms states for a fixed n and l is called a subshell;
each subshell corresponds to a distinct energy level. Since ml ranges from
−l to +l, and there are two spin states for each value of n, l, and ml
, a
given subshell can hold 2(2l + 1) electrons. For a given value of n, the set
of all possible l, ml
, and ms states is called a shell; each shell can hold 2n
2
electrons (Problem 13.7).
The notation which indicates the number of electrons occupying each
subshell in a multielectron atom is rather arcane. Unfortunately, it is also
rather standard, so we shall use it here. A given n, l subshell is denoted by
a number (which gives n) and a letter (which gives l, in accordance with
the previously-used notation: l = 0 is denoted by s, l = 1 is denoted by p,
l = 2 is denoted by d, and so on). So the first few subshells in an atom are:Multiparticle Schr¨odinger equation 327
1s → n = 1, l = 0
2s → n = 2, l = 0
2p → n = 2, l = 1
3s → n = 3, l = 0
3p → n = 3, l = 1
3d → n = 3, l = 2
The number of electrons occupying each subshell is indicated by a super￾script. For instance, the ground state of boron is written as
1s
2
2s
2
2p
1
(13.16)
indicating that two electrons have n = 1 and l = 0, two electrons have
n = 2 and l = 0, and one electron has n = 2 and l = 1.
Just as in hydrogen, the higher n states have higher energy, but what
about the l states? In general, states with higher l have wave functions
which are peaked further from the nucleus (see, for example, Figure 6.7).
Thus, the lower l states “feel” a stronger Coulomb attraction and have
lower energy. For example, in the ground state of the lithium atom, which
has three electrons, the first two electrons fall into the 1s subshell, and the
third electron can have either n = 2, l = 0 or n = 2, l = 1. Our argument
indicates that the n = 2, l = 0 state has the lower energy, so the ground
state of lithium is
1s
2
2s
1
In general then, subshells are filled first from lower n to higher n, and for a
given value of n, from lower l to higher l; this is called the Aufbau principle.
Thus, we expect the subshells to be filled in the order: 1s, 2s, 2p, 3s, 3p,
3d, 4s, . . . . This simple rule works well for the lightest atoms, but it breaks
down at the 3d state. At this point screening by the inner electrons becomes
so important that the n = 4, l = 0 state is pulled below the n = 3, l = 2
state, so that the order in which the subshells are actually filled is: 1s, 2s,
2p, 3s, 3p, 4s, 3d, . . . . For heavier elements, the order in which the subshells
are filled becomes even more complicated.
This filling of subshells and shells is the basis for all of chemistry. A shell
with a full set of electrons, called a closed shell, plays no role in binding to
other atoms; it is the electrons in a partially filled shell which determine
the chemical behavior of an atom. (Note that it is a filled shell, not a filled
subshell, which renders the electrons inactive as far as chemical activity is
concerned.) Atoms consisting entirely of closed shells are chemically inert.
Because these atoms cannot bind even to each other, the corresponding328 Quantum Mechanics: An Accessible Introduction
elements are all gasses at room temperature: the “noble gasses.” The first
few such atoms with their electron configurations are:
helium 1s
2
neon 1s
2
2s
2
2p
6
argon 1s
2
2s
2
2p
6
3s
2
3p
6
Note that the n = 3 shell for argon is considered closed despite the fact
that there are no electrons in the 3d subshell. As noted earlier this is the
point at which our simple rules for filling subshells break down, with the
3d states having higher energy than the 4s states.
The alkali metals (lithium, sodium, potassium, etc.) have a single elec￾tron in an unfilled shell, making them very reactive as electron donors:
lithium 1s
2
2s
sodium 1s
2
2s
2
2p
6
3s
potassium 1s
2
2s
2
2p
6
3s
2
3p
6
4s
Similarly, the halogens (fluorine, chlorine, bromine, . . .) are one electron
short of a filled shell, rendering them prone to grabbing electrons from
other atoms. This shell filling, of course, is what produces the periodic
table.
A given atom can also be characterized by its angular momentum states.
These states are labeled by the quantum numbers L, S, and J, which
correspond to the total orbital angular momentum for the electrons in the
atom L, the total spin angular momentum quantum number for the atomic
electrons S, and the total angular momentum J. (We use uppercase letters
to denote total angular momenta, and lowercase letters to denote angular
momenta of individual electrons. Note that the angular momentum of the
nucleus is ignored here.) The way in which the individual spins and orbital
angular momenta of the electrons in an atom couple to give L, S, and J
depends on the number of electrons in the atom. For the lightest elements,
it is a good approximation to assume that all of the individual orbital
angular momenta couple to give the value for L, and all of the individual
spin angular momenta couple to give the value for S. These total values
for L and S then couple, in accordance with the relation
|L − S| ≤ J ≤ L + S
to give the total angular momentum J. This coupling scheme is called L-S
coupling or Russell–Saunders coupling, and it is the only one we will consider
in detail here. For some heavy elements, it is a better approximation toMultiparticle Schr¨odinger equation 329
assume that the individual l and s of each electron couple to give a distinct
total angular momentum j for each electron; all of these j’s then couple
to give the total J. This is called j-j coupling and will not be considered
further. While a given atom can have a variety of values for L, S, and J,
the ground state of a given atom always has a unique set of these quantum
numbers. (Note that the values of L, S, and J for the ground state of an
atom have no particular importance for its chemical behavior.)
Consider first the simplest case, hydrogen. The ground state has a
single electron with l = 0 and s = 1/2, which means that the total orbital
angular momentum and total spin angular momentum must also be L = 0
and S = 1/2. These can couple to give only a single value for J, namely,
J = 1/2. This is written in the rather unusual (but standard!) notation
introduced in Chapter 9; the value for L is written as a letter (in this case
S), and the value of J is written as a subscript to give S1/2. Now we must
add a superscript to denote the value of S, but instead of writing the value
of S, we write the value of 2S + 1 as an upper left-hand superscript (don’t
blame me; I didn’t invent this). Thus, the full set of values for L, S, and J
are given as
2S+1LJ
In this notation, the ground state of hydrogen is written as
2S1/2
(Note that capital letters S, P, D, . . . denote the total orbital angular mo￾mentum of an atom, while small letters s, p, d, . . . such as we used in de￾scribing the electron configuration, refer to the angular momentum states
of individual electrons.)
Moving on to helium, recall from the previous section that the electrons
in the ground state must be in the singlet state, so that S = 0. Further,
both electrons occupy l = 0 states, so they can only couple to give L = 0.
Finally S = 0 and L = 0 can only give J = 0, so we get
1S0
as the ground state of helium. This result can be generalized: the electrons
in a closed subshell always pair off to give L = 0, S = 0, and J = 0;
it is the electrons in partially-filled subshells which then determine the
total angular momentum state. (Note the difference from chemistry, where
electrons become chemically irrelevant only if the full shell is filled, not a
subshell.)330 Quantum Mechanics: An Accessible Introduction
Hydrogen and helium are relatively straightforward examples in the
sense that the angular momenta can couple to give only a single unique
set of quantum numbers. Now consider an example where this is not the
case. Boron has 5 electrons, in the configuration shown in Equation (13.16).
The closed subshells contribute nothing to the angular momentum, which
is determined entirely by the single electron with l = 1 and spin 1/2. Thus,
we must have L = 1 and S = 1/2. However, this leads to two possible
values for J: J = 1/2 or J = 3/2. Which is the lowest energy state?
To determine the ground state for boron (and other atoms), a set of
empirical rules (called Hund’s rules) provides a guide to choosing the values
of S, L, and J that give the lowest energy state. These rules are applied in
the following order:
Hund’s Rule #1: Given more than one allowed value for S, choose the
largest possible value.
Hund’s Rule #2: Given more than one allowed value for L, choose the
largest possible value.
Hund’s Rule #3: Given more than one allowed value for J, choose the
smallest possible value for J if the subshell under consideration is less than
half full, and choose the largest possible value for J if the subshell is more
than half full.
Applying these rules to the case of boron, we see that Rule #1 and
Rule #2 are irrelevant; we have only a single possible value for S and for
L. It is Rule #3 which determines the ground state. The 2p subshell can
hold six electrons, so with only a single electron, it is clearly less than half
full. Therefore, Rule #3 tells us to choose the smallest possible value for
J, which in this case is J = 1/2. This gives the ground state of boron:
2P1/2
When there is more than one electron in an unfilled shell, things become
much more complex as illustrated in the next example.
Example 13.5. The Ground State of Carbon
The electron configuration for carbon is
1s
2
2s
2
2p
2Multiparticle Schr¨odinger equation 331
The unfilled subshell contains two electrons, each with spin 1/2 and l = 1.
Thus, they can couple to give
L = 0, 1, 2
and
S = 0, 1
Together, these yield six possible pairs for L and S:
L = 0, S = 0 (13.17)
L = 1, S = 0 (13.18)
L = 2, S = 0 (13.19)
L = 0, S = 1 (13.20)
L = 1, S = 1 (13.21)
L = 2, S = 1 (13.22)
However, not all of these possible states are allowed; some of them can
only be obtained by putting electrons into the same ml and ms states,
violating the exclusion principle. This is a subtle point which requires
further exploration. Each electron can have ml = −1, 0, or 1, and ms =
+1/2 or −1/2. We write the ml
, ms state for the two electrons in Dirac
notation as |ml(1) ms(1) ml(2) ms(2)⟩, where (1) and (2) denote the first
and second electron, respectively. To avoid confusion, we use the numerical
value for ml and arrow notation for ms. In this notation, for instance, a
state for which the first electron has ml = 1, ms = 1/2 and the second
electron has ml = 0, ms = −1/2 would be written as
|1 ↑ 0 ↓⟩
We can now catalog all possible states for the two electrons in terms
of their ml and ms values. In doing so we recall that states for which the
two electrons have the same values for ml and ms are not allowed by the
exclusion principle. For example, the state |0 ↑ 0 ↑⟩ is excluded. Further,
we don’t want to double-count states which are obtained by interchanging
the two electrons; e.g., the states |1 ↑ 0 ↓⟩ and |0 ↓ 1 ↑⟩ are identical, so
we will list only one of them. With these cautionary notes, we proceed to
list all of the allowed states for ml and ms for the two electrons:332 Quantum Mechanics: An Accessible Introduction
|1 ↑ 1 ↓⟩
|1 ↑ 0 ↑⟩
|1 ↑ 0 ↓⟩
|1 ↑ −1 ↑⟩
|1 ↑ −1 ↓⟩
|1 ↓ 0 ↑⟩
|1 ↓ 0 ↓⟩
|1 ↓ −1 ↑⟩
|1 ↓ −1 ↓⟩
|0 ↑ 0 ↓⟩
|0 ↑ −1 ↑⟩
|0 ↑ −1 ↓⟩
|0 ↓ −1 ↑⟩
|0 ↓ −1 ↓⟩
| − 1 ↑ −1 ↓⟩
For each of these states, we then determine the total values ML and MS,
which are simply the sums ML = ml(1) + ml(2) and MS = ms(1) + ms(2):
|1 ↑ 1 ↓⟩ → ML = 2, MS = 0 (13.23)
|1 ↑ 0 ↑⟩ → ML = 1, MS = 1 (13.24)
|1 ↑ 0 ↓⟩ → ML = 1, MS = 0 (13.25)
|1 ↑ − 1 ↑⟩ → ML = 0, MS = 1 (13.26)
|1 ↑ − 1 ↓⟩ → ML = 0, MS = 0 (13.27)
|1 ↓ 0 ↑⟩ → ML = 1, MS = 0 (13.28)
|1 ↓ 0 ↓⟩ → ML = 1, MS = −1 (13.29)
|1 ↓ − 1 ↑⟩ → ML = 0, MS = 0 (13.30)
|1 ↓ − 1 ↓⟩ → ML = 0, MS = −1 (13.31)
|0 ↑ 0 ↓⟩ → ML = 0, MS = 0 (13.32)
|0 ↑ − 1 ↑⟩ → ML = −1, MS = 1 (13.33)
|0 ↑ − 1 ↓⟩ → ML = −1, MS = 0 (13.34)
|0 ↓ − 1 ↑⟩ → ML = −1, MS = 0 (13.35)
|0 ↓ − 1 ↓⟩ → ML = −1, MS = −1 (13.36)
| − 1 ↑ − 1 ↓⟩ → ML = −2, MS = 0 (13.37)
Now note an important point: some of the L, S states listed in Equa￾tions (13.17)–(13.22) will lead to values of ML and MS which do not appear
in Equations (13.23)–(13.37). These values of L and S must be excluded;
the physical reason they cannot exist is that they violate the exclusion prin￾ciple. For instance, one of our six L, S pairs is L = 2, S = 1. If this was aMultiparticle Schr¨odinger equation 333
possible state for the electrons, then it would lead to all possible pairs of the
states ML = −2, −1, 0, 1, 2 and MS = −1, 0, 1 in Equations (13.23)–(13.37).
While some of these states are observed, others are not. For instance, we
do not see ML = 2, MS = 1. The reason for this is that this state can arise
only if both electrons have ml = 1 and ms = 1/2; however, the exclusion
principle prevents both electrons from being in this same state. Thus, the
state L = 2, S = 1 is ruled out. The task is then to find a subset of the L,
S states from the six given in Equations (13.17)–(13.22) which produces all
of the ML and MS states in Equations (13.23)–(13.37), but which does not
produce any “extra” ML, MS states not on this list. It’s a bit like solving
a puzzle.
Having ruled out the state L = 2, S = 1, we can now rule in several
other states. The state L = 1, S = 1 must be allowed, since this is the
only other L, S state which can give us ML = 1, MS = 1, which is seen in
Equation (13.24). This L, S state then produces all of the following values
of ML and MS:
ML = −1, MS = −1 (13.38)
ML = −1, MS = 0 (13.39)
ML = −1, MS = 1 (13.40)
ML = 0, MS = −1 (13.41)
ML = 0, MS = 0 (13.42)
ML = 0, MS = 1 (13.43)
ML = 1, MS = −1 (13.44)
ML = 1, MS = 0 (13.45)
ML = 1, MS = 1 (13.46)
Similarly, the state L = 2, S = 0 is the only remaining state which can
give ML = 2, S = 0, seen in Equation (13.23). This state produces the
following five ML, MS states:
ML = −2, MS = 0 (13.47)
ML = −1, MS = 0 (13.48)
ML = 0, MS = 0 (13.49)
ML = 1, MS = 0 (13.50)
ML = 2, MS = 0 (13.51)
When we remove the 14 states given by Equations (13.38)–(13.51) from the
list of states given by Equations (13.23)–(13.37), we are left with only a334 Quantum Mechanics: An Accessible Introduction
single state to account for: ML = 0, MS = 0. We can produce this state
(and only this state) by taking L = 0, S = 0.
Therefore, of the six possible pairs of L, S states identified in Equa￾tions (13.17)–(13.22), only three are actually allowed:
L = 2, S = 0
which can give only J = 2,
L = 0, S = 0
which can give only J = 0, and
L = 1, S = 1
which can give J = 0, 1, or 2.
Now Hund’s rules can be used to find which of these states is the ground
state. Hund’s Rule #1 instructs us to choose the state with the largest S,
which is L = 1, S = 1. Hund’s Rule #2 is irrelevant, since we have only a
single L value (L = 1) corresponding to S = 1. Finally, the 2p subshell can
hold 6 electrons, and it contains only 2 in this case, so it is less than half
full. Thus, Hund’s Rule #3 indicates that the ground state is the lowest
allowed J state: J = 0. Therefore, the ground state is L = 1, S = 1, J = 0,
written as
3P0
Clearly, complex calculations of the sort given in Example 13.5 arise
only when there are two are more electrons in an unfilled subshell. Atoms
in which all of the subshells are filled have L = 0, S = 0, and J = 0.
Note that this includes atoms which are not chemically “inert”, since an
atom can have all of its subshells filled but still have an unfilled shell. For
instance, beryllium (with four electrons) has the electron configuration
1s
2
2s
2
Both of its subshells are filled, giving a ground-state angular momentum
of 1S0. However, the n = 2 shell is unfilled (it can hold 8 electrons) so
beryllium is quite chemically reactive. Similarly, any atom with a single
electron in an unfilled subshell will have the angular momentum quantum
numbers of that electron, as in the case of boron considered above.
We have barely scratched the surface of the study of multielectron
atoms. Atomic physics remains an active area of research with many prob￾lems still being explored. However, almost this entire field traces back to
fundamental concepts from quantum mechanics.Multiparticle Schr¨odinger equation 335
PROBLEMS
13.1 Consider the two-particle Hamiltonian given by
H = −
ℏ
2
2m
∇2
1 −
ℏ
2
2m
∇2
2 + V (r1, r2)
Show that the exchange operator E12 commutes with H as long
as the two-particle potential has the property that V (r1, r2) =
V (r2, r1).
13.2 Two identical spin-1/2 particles with mass m are in a one￾dimensional infinite square-well potential with width a, so V (x) = 0
for 0 ≤ x ≤ a, and there are infinite potential barriers at x = 0
and x = a. The particles do not interact with each other; they see
only the infinite square-well potential.
(a) Calculate the energies of the three lowest-energy singlet states.
(b) Calculate the energies of the three lowest-energy triplet states.
(c) Suppose that the particles are in a state with wave function
ψ(x1, x2) = 1
√
2
2
a

sin
πx1
a
sin
7πx2
a
+ sin
πx2
a
sin
7πx1
a

where x1 is the position of particle 1 and x2 is the position of
particle 2. Are the particles in a triplet spin state or a singlet spin
state? Explain.
13.3 Two identical spin-0 particles with mass m are confined inside a
three-dimensional rectangular box given by 0 ≤ x ≤ a, 0 ≤ y ≤ b,
and 0 ≤ z ≤ c, where a < b < c, and the potential barriers at the
walls of the box are infinitely high. The particles do not interact
with each other; they see only the potential of the box. Write down
the normalized wave function ψ(x1, y1, z1, x2, y2, z2) for the ground
state, and indicate the energy of the ground state.
13.4 (a) Two identical spin-1/2 particles are confined inside of the rect￾angular box from Problem 13.3. The particles do not interact with
each other; they see only the potential of the box. Write down the
normalized spatial part of the lowest-energy singlet wave function.
What is the energy of this state?
(b) Write down the normalized spatial part of the lowest-energy
triplet wave function. What is the energy of this state?
(c) What is the total spin s of the ground-state wave function for
the system?336 Quantum Mechanics: An Accessible Introduction
13.5 Two identical spin-1/2 particles are confined to an infinite one￾dimensional square well of width a with infinite potential barriers
at x = 0 and x = a. The potential is V (x) = 0 for 0 ≤ x ≤ a.
Suppose that the particles interact weakly by the potential V1(x) =
Kδ(x1−x2), where x1 and x2 are the positions of the two particles,
K is a constant, and δ is the Dirac delta function. This represents
a very short-range weak force between the two particles.
(a) Using first-order perturbation theory, find the perturbation to
the energy of the lowest-energy singlet state.
(b) Show that the first-order perturbation to the energy of the
lowest-energy triplet state is zero.
(c) What is the physical reason for the answer in part (b)?
13.6 Two identical spin-1/2 particles are in the one-dimensional simple
harmonic oscillator potential V (x) = (1/2)Kx2
. The particles do
not interact with each other; they see only the harmonic oscillator
potential. The particles are in the lowest-energy triplet state, with
s = 1.
(a) Write down the normalized spatial part of the wave function.
(b) Calculate the energy of this state.
(c) If the positions of both particles are measured, what is the
probability that both particles will be located on the right-hand
side of the minimum in the potential (i.e., the probability that
both particles have x > 0)?
13.7 Show that the n shell in an atom can hold 2n
2
electrons.
13.8 Sodium has Z = 11. Determine the ground-state electron configu￾ration.
In Problems 13.9–13.12, express all angular momentum
states in the notation 2S+1LJ .
13.9 Determine the ground-state L, S, and J values for
(a) calcium which has the electron configuration
1s
2
2s
2
2p
6
3s
2
3p
6
4s
2
(b) yttrium which has the electron configuration
1s
2
2s
2
2p
6
3s
2
3p
6
3d
10 4s
2
4p
6
4d
1
5s
2Multiparticle Schr¨odinger equation 337
13.10 Consider the excited state of beryllium with the electron configu￾ration
1s
2
3p
1
3d
1
Determine all possible L, S, and J values. Note that the Pauli
exclusion principle for the two n = 3 electrons can be ignored;
why?
13.11 Zirconium (Z = 40) consists of closed subshells plus 2 electrons in
an unfilled d subshell. Derive the set of allowed L, S, and J values,
and determine which state has the lowest energy.
13.12 The electron configuration for nitrogen is
1s
2
2s
2
2p
3
Calculate L, S, and J for the ground state.This page intentionally left blankChapter 14
Modern applications of quantum
mechanics
The first half of the 20th century saw two revolutions in physics, culminat￾ing in the theories of quantum mechanics and general relativity. Of these
two, quantum mechanics has certainly had a more profound impact on
the subsequent development of physics. Quantum mechanics provides the
basis for nuclear physics, particle physics, and solid state physics, with ap￾plications in almost all other fields of physics. Furthermore, it has yielded a
surprising number of practical applications. In this chapter we examine just
two of these, in which the use of quantum mechanics is particularly straight￾forward: magnetic resonance imaging and quantum computing. Magnetic
resonance imaging is already a well-developed technology, while quantum
computing is still very much in the formative stage. These are presented
merely as representative examples; there are many others.
14.1 Magnetic Resonance Imaging
Imagine that a patient needs to undergo a magnetic resonance imaging
(MRI) scan (Figure 14.1). The patient first removes any objects that can
affect or be affected by magnetic fields (jewelry, credit cards, metallic ob￾jects), and then lies on a padded bench which slides into a long tube. The
only sounds are occasional loud thumping noises. After 30–90 minutes, the
patient slides back out again, and the exam is finished.
The development of magnetic resonance imaging technology represents
an enormous advancement in diagnostic medicine. MRI scans are among
the least invasive and safest of all medical tests. Unlike X-rays, they appear
to have absolutely no harmful effects, and they allow physicians to image
soft tissues, especially brain and nerve tissue, which are difficult to examine
with conventional X-rays. Real-time imagining of the brain has opened
339340 Quantum Mechanics: An Accessible Introduction
Fig. 14.1 A magnetic resonance imaging (MRI) machine.
B0
z
z
y
x
ˆ
Fig. 14.2 The protons in hydrogen placed in a magnetic field B0 = B0zˆ will line up
parallel or antiparallel to the field.
up new areas of research in neuroscience, as investigators are able to see
different parts of the brain “light up” in response to different stimuli. And
it’s all derived from quantum mechanics.
Magnetic resonance imaging involves the interaction of external mag￾netic fields with the protons in hydrogen atoms. Consider a hydrogen atom
placed in a strong magnetic field (Figure 14.2). The proton magnetic mo￾ment µp
is given by an expression similar to that for the electron magneticModern applications of quantum mechanics 341
moment in Equation (8.7):
µp =
gpµB
ℏ
me
mp
S (14.1)
where gp = 5.59 is determined experimentally. The factor multiplying S
is positive in this equation and negative in Equation (8.7) because the
proton and electron have opposite charges, and the ratio of me to mp in
Equation (14.1) arises from the fact that the magnetic moment is inversely
proportional to the mass of the particle (Equation (8.5)). As before, µB is
the Bohr magneton, µB = 9.3 × 10−24 A·m2
, and S is the spin.
Recall from Chapter 8 that the potential experienced by the proton in
an external magnetic field B is
V = −µp
·B
If, for instance, B is a static field in the z direction with magnitude B0,
B0 = B0zˆ
then the protons will be forced into eigenstates of the Hamiltonian
and will line up with spins either in the +z direction with energy
E = −(gpµB/2)(me/mp)B0, or in the −z direction with energy E =
(gpµB/2)(me/mp)B0 (Figure 14.2).
Now suppose that we add a perturbation in the form of an electromag￾netic wave. The magnetic field generated by this wave will have the form
B1 cos(ωt). This applied magnetic field can be chosen to be perpendicular
to the z-axis; for simplicity we will take it to be in the x direction, so that
B1 = B1 cos(ωt)ˆx
What happens to the proton spins when this oscillating magnetic field is ap￾plied? This problem was previously discussed in Example 11.2 for the case
of an electron. It was found that the applied field produces a nonzero prob￾ability for the electron to flip into the opposite z spin state (Figure 14.3).
Using the results of Example 11.2, but replacing the electron magnetic
moment with the proton magnetic moment, gives
P(i → f) =
B2
1µ
2
p
4ℏ
2
sin2
[(ω − ω0)t/2]
[(ω − ω0)/2]2
(14.2)
where P(i → f) is the transition probability for a proton to go from a lower
energy (spin up) state to a higher energy (spin down) state. The frequency
ω0 in this case is
ω0 = 2µB(gp/2)(me/mp)B0/ℏ342 Quantum Mechanics: An Accessible Introduction
z
y
x
B1
 cos(vt)x
B0
z
ˆ
ˆ
Fig. 14.3 An oscillating magnetic field in the ˆx direction causes some of the proton
spins to flip.
The important point is that the transition probability in Equation (14.2)
is sharply peaked around ω ≈ ω0. In order to drive a large number of
transitions, the applied frequency of the radiation should be close to this
resonance frequency. A typical MRI field strength is B0 = 1.5 T; using this
value, we obtain ω0 = 4.0 × 108
sec−1
, corresponding to a frequency of
ν = ω/2π = 6.4 × 107 Hz
Thus, the applied frequency needs to be in the MHz region, corresponding
to radio frequencies.
After the spins flip into the high-energy state, they will relax back into
the low-energy state. As they do so, they will develop a spin component
(and therefore a magnetic moment component) perpendicular to the strong
static magnetic field B0zˆ, causing them to precess about this field (Fig￾ure 14.4). We examined spin precession in Chapter 8, where we found that
the angular frequency of precession for an electron with spin perpendicular
to the magnetic field B was ω = 2µBB/ℏ. Again, we must change the
electron magnetic moment µB to the proton magnetic moment µp, so that
the precession frequency for the protons is
ω = 2µpB0/ℏ = 2µB(gp/2)(me/mp)B0/ℏ
In fact, this is exactly the same as the applied frequency that maximized
the probability for the protons to flip! As the protons precess, they emit ra￾diation at the precession frequency. As noted, this frequency is in the MHz
range, so that the precessing protons give off electromagnetic radiation at
radio frequencies. This radiation can then be detected and used to map the
emitting protons. Thus, MRI allows the direct imaging of hydrogen atomsModern applications of quantum mechanics 343
z
y
x
⇒ ⇒
B0
zˆ
Fig. 14.4 As the protons relax back into the lower-energy spin state, they precess about
the static magnetic field.
in the body (Figure 14.5). Tuning MRI to detect hydrogen atoms makes
sense, since hydrogen is the most abundant element (by number) in the hu￾man body. (This picture is an oversimplification, since the protons actually
precess about the combined total magnetic field, B = B0 + B1 cos(ωt), but
it gives a reasonably accurate picture of how MRI works.)
MRI has several advantages over X-rays. Perhaps the biggest advan￾tage is one of safety: X-rays ionize atoms in the body, leading to the danger
of cancer at low doses and actual destruction of tissue at high doses. In
contrast, no health risk from strong magnetic fields has ever been demon￾strated. MRI images soft tissues more effectively than X-rays, which scatter
less effectively off of low-density tissues than off of high-density materials
such as bone. Furthermore, since MRI couples to hydrogen atoms, it can
actually provide information on the chemical content of body tissues. The
major drawback of MRI (compared with conventional X-rays) is its high
cost.
It is amusing to note that MRI was originally (and accurately) called
“nuclear magnetic resonance,” since it relies on the resonant flip of the
atomic nuclei in magnetic fields, with subsequent precession and re-emission
of radiation at the resonant frequency. However, patients were disturbed by
the use of the word “nuclear,” which conjured images of nuclear weapons,
nuclear waste, etc. This was particularly unfortunate given that the process
itself is so noninvasive and benign. Hence it was repackaged as “magnetic
resonance imaging,” avoiding the negative connotations of the word “nu￾clear.”344 Quantum Mechanics: An Accessible Introduction
Fig. 14.5 An example of the image produced by an MRI machine.
14.2 Quantum Computing
We now examine a more recent, and completely different, application of
quantum mechanics: quantum computing. Classical computing is based on
binary digits or bits. For instance, a two-bit computer can be in one of the
following four states:
0 0
0 1
1 0
1 1
where 0 and 1 can represent, electronically, circuits which are “on” or “off”
or, logically, states that are “true” or “false.” A sequence of n bits can be
in 2n possible states; this provides a measure of the information storage in
such a system. Note, however, that the system can be in only one of theseModern applications of quantum mechanics 345
states at any given time, so the computer can operate on only one state at
a time.
Now consider a quantum analog: a system of two spin-1/2 particles.
Just as in the case of the two-bit circuit, each particle can be in one of two
states, so there are four possible states all together:
| ↓ ↓⟩
| ↓ ↑⟩
| ↑ ↓⟩
| ↑ ↑⟩
Now “spin down” and “spin up” represent the “0” and “1” states, respec￾tively, of a classical computer. These quantum bits are called qubits. Note,
however, that the system need not be in a single state; it can be in a
superposition of all four states, e.g.,
|ψ⟩ = a1| ↓ ↓⟩ + a2| ↓ ↑⟩ + a3| ↑ ↓⟩ + a4| ↑ ↑⟩
It is possible then to access all four of these spin states simultaneously,
since each of them contributes to |ψ⟩. One can also imagine operating on
this linear combination of spin states to obtain a second linear combination
of the spin states for the two particles. This represents a radical degree
of parallel computing: all four two-qubit states can be manipulated simul￾taneously. This parallelism becomes more pronounced as the number of
qubits increases; with ten qubits, for example, a million spin states can be
accessed simultaneously!
It is possible to carry this analogy further and actually perform logical
operations on the qubits. First, recall the sort of logic gates that are possible
in a classical computer. Binary gates such as AND and OR take two bits
and produce a single output bit (Figure 14.6). If 1 and 0 represent “true”
and “false,” respectively, then the AND gate produces an output of 1 if and
only if both input bits are 1; otherwise it produces 0. Similarly, the OR
gate produces 1 if either bit is 1; it produces 0 only if both bits are 0. A
third example is the XOR, or exclusive OR gate, which is identical to the
OR gate with the exception that it produces a “false” output if both inputs
are “true.”
In order to produce the quantum analog of these logic gates, we first
need a slightly different representation of our four two-particle spin states.346 Quantum Mechanics: An Accessible Introduction
0
0
0
0
0
1
1
0
0
1
1
1
AND
0
0
0
0
1
1
1
1
0
1
1
1
OR
0
0
0
0
1
1
1
1
0
1
0
1
XOR
Fig. 14.6 The classical AND, OR, and XOR gates take in two bits and produce a one-bit
output.
We represent the four states as column vectors in the following way:
| ↓ ↓⟩ ⇔


1
0
0
0


(14.3)
| ↓ ↑⟩ ⇔


0
1
0
0


(14.4)
| ↑ ↓⟩ ⇔


0
0
1
0


(14.5)
| ↑ ↑⟩ ⇔


0
0
0
1


(14.6)
As noted, the spin-down state represents a “0” or “false” bit, and the
spin-up state represents a “1” or “true” state. A logic gate can then be
represented as multiplication by a 4 ×4 matrix. As an example, the matrixModern applications of quantum mechanics 347
representing the XOR gate is
UXOR =


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


Using this matrix representation as well as the column vector representa￾tions in Equations (14.3)–(14.6), we can derive how UXOR operates on our
four spin states:
UXOR| ↓ ↓⟩ = | ↓ ↓⟩
UXOR| ↓ ↑⟩ = | ↓ ↑⟩
UXOR| ↑ ↓⟩ = | ↑ ↑⟩ (14.7)
UXOR| ↑ ↑⟩ = | ↑ ↓⟩
In what sense can this result be treated as an XOR logic gate? The two
inputs are simply the spin states of the two particles. The output of the logic
gate is read off of the spin state of the second particle, while the spin state
of the first particle is left unchanged. For instance, in Equation (14.7), the
input spins of the two particles represent “true” and “false,” respectively, so
the XOR output should be “true.” Hence, the spin of the second particle is
set to spin up, while the spin of the first particle remains unchanged by the
operator. Clearly, this differs from a classical logic gate in that there are two
outputs rather than one: the spin of the first particle (which never changes)
and the spin of the second particle (which corresponds to the output of the
classical XOR gate). There is a reason for this: quantum mechanics is
invariant under time reversal, so any quantum mechanical operation must
be reversible. An operation such as a classical logic gate, which takes two
inputs and produces only a single output, reduces the total information
in the system; one cannot, in general, reconstruct the input values that
go into a classical logic gate if only the output is known. Hence, quantum
mechanical logic gates must have two outputs. Note, as emphasized earlier,
that the quantum XOR gate can operate on a linear superposition of spin
states, producing a linear superposition of outputs.
It is also possible to produce quantum logic circuits with no classical
analog. Consider, instead of a two-qubit system, a single-qubit system with
the two possible states
| ↑ ⟩ ⇔ 
1
0

→ TRUE
| ↓ ⟩ ⇔ 
0
1

→ FALSE348 Quantum Mechanics: An Accessible Introduction
The NOT gate gives an output of TRUE if the input is FALSE and FALSE
if the input is TRUE. In matrix form, this operator can be written as
UNOT =

0 1
1 0
The NOT gate is a well-behaved classical logic gate. Now, however, consider
the √
NOT gate, given by
U√
NOT =
1
2

1 − i 1 + i
1 + i 1 − i

It is possible to show (Problem 14.7) that U√
NOT U√
NOT = UNOT, so that
applying the operation √
NOT twice yields NOT. There is, however, no
classical logic gate with this property.
This all sounds fine in theory, but is it actually possible to design a quan￾tum computing system to perform useful calculations? A breakthrough in
this area was achieved in 1994 at Bell Labs by Peter Shor, who devised a
quantum algorithm for factoring prime numbers. This algorithm was suc￾cessfully implemented in 2001 at the IBM Almaden Research Center. The
IBM scientists constructed a molecule consisting of five fluorine-19 atoms
and two carbon-13 atoms, with the spins of the atomic nuclei serving as
the qubits. These nuclear spins were manipulated using nuclear magnetic
resonance technology similar to that described in the previous section. This
quantum computer succeeded in factoring the number 15 (into 3 and 5).
Since then, work in this field has accelerated enormously, becoming an area
of intense current research.
PROBLEMS
14.1 Oxygen is the second most abundant element in the human body
(by number) and the most abundant by mass. However, MRI de￾tection of oxygen atoms is not practical. Why?
14.2 Electrons in hydrogen have a much larger magnetic moment (both
orbital and spin) than the magnetic moment of the proton. Why
then are MRI machines not tuned, for example, to the resonant
frequency of the spin magnetic moment of the electron rather than
the proton?
14.3 Consider an MRI machine with a 1.5 T static field. How far
from the resonant frequency would one have to be in order for theModern applications of quantum mechanics 349
spin-flip probability to decrease from its maximum value to each
of the following?
(a) one-half of the maximum value
(b) zero
14.4 The random thermal energy of each molecule in the human body
is roughly E ≈ kT, where k is Boltzmann’s constant (k = 1.38 ×
10−23 J K−1
) and T is the temperature. Compare this thermal
energy to the potential energy experienced by a proton in a 1.5 T
MRI machine. What does the answer say about the efficiency with
which protons will align into lower energy states in such a magnetic
field?
14.5 (a) Verify that the matrix corresponding to UNOT produces the
correct output when applied to the | ↓ ⟩ and | ↑ ⟩ states.
(b) Compute the matrix corresponding to U
2
NOT, and calculate the
result when it is applied to | ↓ ⟩ and | ↑ ⟩. What logical operation
does U
2
NOT correspond to?
14.6 (a) Show explicitly that the classical XOR gate cannot be inverted.
(b) Calculate the matrix corresponding to the inverse of the quan￾tum XOR gate.
14.7 Show that U√
NOT U√
NOT = UNOT.
14.8 Apply UXOR to the mixed state (1/
√
2)(| ↓ ↓⟩ + | ↑ ↑⟩). Explain
what the result means.This page intentionally left blankChapter 15
Relativistic quantum mechanics
The theory of quantum mechanics that we have developed thus far is based
on the nonrelativistic definition of energy, namely,
E =
p
2
2m
+ V (15.1)
The replacement of p, V , and E with the appropriate operators leads to
the Schr¨odinger equation. However, special relativity, which predates the
Schr¨odinger equation by 20 years, indicates that Equation (15.1) is only
an approximation valid at low velocities. When particle velocities become
comparable to the speed of light, this equation breaks down. In this chapter
we will examine what happens when we attempt to incorporate special
relativity into quantum mechanics; the result is called relativistic quantum
mechanics.
15.1 The Klein–Gordon Equation
Derivation of the Klein–Gordon Equation
As noted, the relationship between momentum and energy given by Equa￾tion (15.1) is valid only in the limit of low velocities, v ≪ c, where c is the
speed of light. In special relativity, Einstein generalized this equation to
give the correct relation between p and E at all velocities:
E
2 = p
2
c
2 + m2
c
4
(15.2)
where we have assumed a free particle with no potential (we will assume
V = 0 throughout this chapter), and m is the mass of the particle at rest,
which is a constant. (In dealing with relativistic quantities, it is possible
to simplify the equations considerably by setting c = 1. We will resist
the urge to do that here, but it is important to be aware that it is often
351352 Quantum Mechanics: An Accessible Introduction
done.) In the limit where v ≪ c, it is possible to show (Problem 15.1) that
Equation (15.2) reduces to
E =
p
2
2m
+ mc2
(15.3)
This equation is similar to Equation (15.1) for the case V = 0, but there
is an extra term on the right-hand side of Equation (15.3), corresponding
to an extra contribution to the energy: E = mc2
. In special relativity,
this is called the rest energy of the particle, and it must be included in the
total energy. Note that nonrelativistic quantum mechanics ignores this rest
energy, but it is included in the equations of relativistic quantum mechanics.
In order to derive an equation for the wave function that corresponds
to Equation (15.2), we follow a procedure very similar to our “derivation”
of the Schr¨odinger equation in Chapter 3. Assume that we have a wave
function ϕ(r, t) that is an eigenfunction of the energy operator iℏ(∂/∂t)
with eigenvalue E, and also an eigenfunction of the momentum operator
−iℏ∇ with eigenvalue p. In that case, we have

iℏ
∂
∂t2
ϕ = E
2ϕ
and
(−iℏ∇)
2
ϕ = p
2ϕ
and we can reproduce Equation (15.2) by writing

iℏ
∂
∂t2
ϕ = (−iℏ∇)
2
c
2ϕ + m2
c
4ϕ (15.4)
As in the derivation of the Schr¨odinger equation, we now make the assump￾tion that Equation (15.4) is always valid, regardless of whether or not ϕ
is an eigenfunction of energy or momentum. Simplifying Equation (15.4)
gives
1
c
2
∂
2ϕ
∂t2
− ∇2ϕ +
m2
c
2
ℏ
2
ϕ = 0 (15.5)
Equation (15.5) is called the Klein–Gordon equation.
The Klein–Gordon equation describes a particle with spin 0, which lim￾its its usefulness, since the particles of greatest interest (e.g., the electron,
proton, etc.) all have spin 1/2. Further, this equation leads to some prob￾lems connected with the interpretation of probabilities. To see this we need
to digress.Relativistic quantum mechanics 353
Probability Densities and Currents
For the Schr¨odinger equation, the probability density is given by |ψ|
2
. How￾ever, it is not true that the corresponding quantity for the Klein–Gordon
equation is |ϕ|
2
. To find the probability density in this case, we need to
introduce a new quantity called the probability current.
We argue in analogy to a classical fluid. For a fluid with density ρ and
velocity v, the rate ∂ρ/∂t at which the density changes at a fixed point is
given by
∂ρ
∂t + ∇·(ρv) = 0 (15.6)
The validity of this equation can be seen by integrating it over a closed
volume V , and using the divergence theorem to transform the integral of
∇·(ρv) into an integral over the surface:
Z
V
∂ρ
∂t +
Z
A
(ρv)·dA = 0 (15.7)
The first term in this equation is just the rate at which the total mass
inside the closed surface changes; the second term is the rate at which
mass is crossing the surface. Thus, Equation (15.7) (or equivalently, Equa￾tion (15.6)) simply says that the rate at which mass increases or decreases
inside of a bounded region (the first term) is just given by the rate at
which mass crosses the boundary of the region (the second term). There￾fore, Equation (15.6) is called the continuity equation.
In quantum mechanics, probability can be treated in exactly the same
way. The quantity equivalent to the density ρ is just the probability density
(which for the Schr¨odinger equation is ρ = |ψ|
2
), and we can define a
probability current J that satisfies the continuity equation for probabilities:
∂ρ
∂t + ∇·J = 0 (15.8)
As an example, we determine the expression corresponding to J for the
Schr¨odinger wave function.
Example 15.1. The Nonrelativistic Probability Current
What is the value for J arising from the nonrelativistic Schr¨odinger equa￾tion?
Substituting ρ = ψ
∗ψ into Equation (15.8) gives
ψ
∗ ∂ψ
∂t + ψ
∂ψ∗
∂t + ∇·J = 0 (15.9)354 Quantum Mechanics: An Accessible Introduction
The first two terms can be simplified using the nonrelativistic Schr¨odinger
equation, which can be written, in the absence of a potential, as
iℏ
∂ψ
∂t = −
ℏ
2
2m
∇2ψ
Multiplying by −iψ∗/ℏ gives the first term in Equation (15.9):
ψ
∗ ∂ψ
∂t =
iℏ
2m
ψ
∗∇2ψ
and the complex conjugate of this equation gives the second term in Equa￾tion (15.9):
ψ
∂ψ∗
∂t =
−iℏ
2m
ψ∇2ψ
∗
Substituting these expressions into Equation (15.9) gives
∇·J =
iℏ
2m
(ψ∇2ψ
∗ − ψ
∗∇2ψ)
which can be integrated to give the expression for J:
J =
iℏ
2m
(ψ∇ψ
∗ − ψ
∗∇ψ) (15.10)
Taking the same expression for J as given in Equation (15.10), but
using the Klein–Gordon equation instead of the Schr¨odinger equation, we
can derive an expression for ρ that satisfies the continuity equation (see
Problem 15.4):
ρ =
iℏ
2mc2

ϕ
∗ ∂ϕ
∂t − ϕ
∂ϕ∗
∂t 
(15.11)
Note that this expression for ρ is quite different from our familiar expres￾sion ρ = ψ
∗ψ. In particular, the expression for ρ given by Equation (15.11)
can be negative, which is clearly a “bad thing.” Note further that in
using Equation (15.2), we have inadvertently introduced negative energy
solutions! Equation (15.2) corresponds to both E =
p
p
2c
2 + m2c
4 and
E = −
p
p
2c
2 + m2c
4.
Example 15.2. Solution to the Klein–Gordon Equation for a
Particle at Rest
Consider a particle at rest for which p = 0. We will solve the Klein–Gordon
equation for this particle.Relativistic quantum mechanics 355
Since the momentum is zero, we have −iℏ∇ϕ = 0, and Equation (15.5)
becomes
1
c
2
∂
2ϕ
∂t2
+
m2
c
2
ℏ
2
ϕ = 0
The most general solution to this equation is
ϕ = A1e
imc2
t/ℏ + A2e
−imc2
t/ℏ
(15.12)
where A1 and A2 are unknown constants. Applying the energy operator
iℏ(∂/∂t) to each term in Equation (15.12), we see that the first term corre￾sponds to a state with negative energy, E = −mc2
, while the second term
corresponds to a state with positive energy, E = mc2
.
Because the Klein–Gordon equation contains a second derivative with
respect to time, two boundary conditions are necessary to determine the
solution: both ϕ and ∂ϕ/∂t must be specified. This is clear, for exam￾ple, in the solution given by Equation (15.12); two boundary conditions
are necessary to determine the two unknown constants. This represents an
additional degree of freedom not present in the Schr¨odinger equation. It is
reasonable, therefore, to see if it is possible to find an equation correspond￾ing to relativistic dynamics that contains only first derivatives with respect
to time; the result will be the Dirac equation.
15.2 The Dirac Equation
Consider what happens if we try to construct an operator equation corre￾sponding to Equation (15.2) but restrict the equation to be first order in
all of the operators. As a first attempt, we write

iℏ
∂
∂t
ψ =

−iℏc

α1
∂
∂x + α2
∂
∂y + α3
∂
∂z 
+ βmc2

ψ
where α1, α2, α3, and β are constants to be determined. In order to
find the values of these constants, we square the operator on both sides of
the equation, and require the final result to reduce to the Klein–Gordon
equation:
−ℏ
2 ∂
2ψ
∂t2
=

−iℏc
X
3
j=1
αj∇j + βmc2


 
−iℏc
X
3
k=1
αk∇k + βmc2
!
ψ
=

−ℏ
2
c
2X
3
j=1
X
3
k=1
αjαk∇j∇k − iℏmc3X
j
(βαj + αjβ)∇j + β
2m2
c
4

 ψ
(15.13)356 Quantum Mechanics: An Accessible Introduction
where we define ∇1 = ∂/∂x, ∇2 = ∂/∂y, and ∇3 = ∂/∂z. We want this to
reduce to the Klein–Gordon equation, which can be written as
−ℏ
2 ∂
2ϕ
∂t2
= −ℏ
2
c
2∇2ϕ + m2
c
4ϕ
In order for Equation (15.13) to reduce to the Klein–Gordon equation,
the first term on the right-hand side of Equation (15.13) must simplify to
−ℏ
2
c
2∇2ψ, which requires
αjαj = 1 (15.14)
and
αjαk + αkαj = 0, for j ̸= k (15.15)
The second term on the right-hand side of Equation (15.13) must vanish,
which gives
βαj + αjβ = 0 (15.16)
Finally, the last term on the right-hand side of Equation (15.13) must reduce
to m2
c
4ψ, so that
β
2 = 1 (15.17)
To summarize, each of the four constants α1, α2, α3, and β must square
to give 1, but the four constants all anticommute with each other (αi and
αj are said to anticommute if αiαj = −αjαi). In fact, it is impossible
to find four numbers that satisfy these relations! On the other hand, it
is possible to satisfy these relations if we take α1, α2, α3, and β to be
matrices. For example, the Pauli spin matrices from Chapter 8 satisfy
exactly the desired relations: σ
2
x = σ
2
y = σ
2
z = I, and σxσy + σyσx = 0,
σxσz + σzσx = 0, σyσz + σzσy = 0. The problem is that there are only
three of these matrices and we need four. In order to find four mutually
anticommuting matrices that all square to give the identity matrix, the
minimum size of the matrices must be 4 × 4. Thus, the wave function in
our differential equation is no longer a one-component object (as it is in the
Schr¨odinger and Klein–Gordon equations). Instead, it is a four-component
column vector. There are an infinite number of different choices for matrices
satisfying Equations (15.14)–(15.17), but the choice of which ones to use
doesn’t change any physical calculations. The conventional choice is the
following:
αj =

0 σj
σj 0
Relativistic quantum mechanics 357
and
β =

I 0
0 −I

where each symbol stands for a 2 × 2 matrix. Here the σj ’s are the 2 × 2
Pauli spin matrices, and I is the 2 × 2 identity matrix. For example,
α3 =


0 0 1 0
0 0 0 −1
1 0 0 0
0 −1 0 0


and
β =


1 0 0 0
0 1 0 0
0 0 −1 0
0 0 0 −1


With these values for αj and β, we can go back to our original equation
and write
iℏ
∂ψ
∂t = −iℏc(α·∇)ψ + βmc2ψ (15.18)
where α·∇ is shorthand for α1(∂/∂x) + α2(∂/∂y) + α3(∂/∂z); hence, α is
a three-component object whose three components are each 4 × 4 matri￾ces! Equation (15.18) is called the Dirac equation. It forms the basis of
relativistic quantum mechanics, and is perhaps the second most important
equation in this book after the Schr¨odinger equation itself. Of course, as
we have emphasized, the ψ which appears in Equation (15.18) is really a
four-component column vector:
ψ =


ψ1
ψ2
ψ3
ψ4


where each of the four components ψ1, . . . , ψ4, is a function of position and
time. If all of the matrices in the Dirac equation are multiplied out, the
Dirac equation breaks into a set of four differential equations relating these
four components and their derivatives (see Problem 15.6).
To find the probability density and probability current for the Dirac
wave function, we begin with the Dirac equation and derive a relation
which looks like the continuity equation. Starting with Equation (15.18),358 Quantum Mechanics: An Accessible Introduction
we first take the adjoint (i.e., the conjugate transpose) of this equation to
obtain
−iℏ
∂ψ†
∂t = iℏc(∇ψ
†
)·α + ψ
†βmc2
(15.19)
where we have used the fact that all of the αj , β matrices are Hermitian.
Using Equations (15.18) and (15.19) for the time derivatives of ψ and ψ
†
,
∂
∂t(ψ
†ψ) = ψ
† ∂ψ
∂t +
∂ψ†
∂t ψ
= −c∇·(ψ
†αψ) (15.20)
Equation (15.20) looks just like the continuity equation if we take ρ and J
to be given by
ρ = ψ
†ψ
and
J = cψ†αψ
These then are the probability density and probability current for the Dirac
equation. Note that, unlike the case for the Klein–Gordon equation, the
Dirac probability density is always nonnegative, since
ρ = ψ
†ψ = |ψ1|
2 + |ψ2|
2 + |ψ3|
2 + |ψ4|
2
and each of these four terms is nonnegative. This is a good thing, since
probabilities should be positive.
Now consider the solutions of the Dirac equation for a particle at rest.
(The solutions of the Dirac equation for nonzero momentum are derived in
Problem 15.8.) For a particle at rest, p = 0 so the term −iℏc(α·∇)ψ is
zero, and the Dirac equation becomes
iℏ
∂ψ
∂t = βmc2ψ
Multiplying out βψ on the right-hand side gives four ordinary differential
equations:
iℏ
dψ1
dt = mc2ψ1
iℏ
dψ2
dt = mc2ψ2
iℏ
dψ3
dt = −mc2ψ3
iℏ
dψ4
dt = −mc2ψ4Relativistic quantum mechanics 359
Solving for ψ1, ψ2, ψ3, and ψ4 and recombining the solutions back into the
form of a column vector gives four linearly-independent solutions. The first
two are
ψ =


1
0
0
0


e
−imc2
t/ℏ
(15.21)
and
ψ =


0
1
0
0


e
−imc2
t/ℏ
(15.22)
The energies corresponding to these two solutions can be determined by
applying the energy operator iℏ(∂/∂t); we obtain
E = mc2
for both solutions. This is precisely the expected result for the energy of
a particle at rest. But why are there two linearly-independent solutions?
These solutions apparently describe a two-component object. But we are al￾ready familiar with such an object: a spin-1/2 particle! The Dirac equation
describes an elementary particle with spin of 1/2, and the wave function ψ
combines both the spatial and the spin information into a single quantity
called a spinor. Thus, the wave function in Equation (15.21) represents a
particle at rest with ms = +1/2, and the wave function in Equation (15.22)
represents a particle at rest with ms = −1/2. These two solutions can be
combined linearly to yield any other spin state for a spin-1/2 particle.
The other two linearly-independent solutions are
ψ =


0
0
1
0


e
imc2
t/ℏ
and
ψ =


0
0
0
1


e
imc2
t/ℏ360 Quantum Mechanics: An Accessible Introduction
E = 0
Filled
states
e
+
e
–
Fig. 15.1 In a vacuum, all of the negative-energy states are filled with electrons, and
all of the positive-energy states are empty. Moving an electron into a positive-energy
state leaves behind a “hole” in the negative-energy states, corresponding to a positron.
Electron-positron annihilation corresponds to the electron dropping back down and filling
the hole.
which both have negative energy:
E = −mc2
It is tempting to dismiss these as “spurious” solutions with no physical
significance, but Dirac did not do so. Rather, he assumed that these so￾lutions were also valid. If this is the case, where are the negative-energy
electrons? Dirac argued that in an ordinary vacuum, all of the positive￾energy states are empty, while the negative-energy states are filled by a sea
of electrons (Figure 15.1). If an electron is removed from a negative-energy
state and boosted into a positive-energy state, it leaves behind a “hole”
in the negative-energy states. The energy of this “hole” is the negative of
the corresponding negative-energy electron state, so the “hole” has energy
E = −(−mc2
) = mc2
. In this way Dirac postulated the existence of an￾timatter. The holes in the negative-energy states are antielectrons, called
positrons. Note that it is not the electrons in the negative-energy states
that correspond to positrons, but rather the holes in the negative-energy
states generated by removing electrons from them. A positron can annihi￾late with an electron; this corresponds to the electron dropping back down
and filling the vacant negative-energy state, thus eliminating both the elec￾tron and the hole. This prediction of Dirac was confirmed experimentally
in 1932 with the discovery, by Carl Anderson, of the positron.
This is only a small subset of the important results to which the Dirac
equation leads. It is possible, for example, to show that the Dirac equationRelativistic quantum mechanics 361
predicts that gs for the spin magnetic moment of the electron should be
exactly 2 (a prediction which must be modified, by a small amount, using
the more advanced results of quantum field theory). The Dirac equation
forms one of the main pathways leading from classical quantum mechanics
into our modern theories of particle physics.
PROBLEMS
15.1 Show that the relativistic relation between energy and momentum
(Equation (15.2)) reduces to
E =
p
2
2m
+ mc2
for the case when v ≪ c.
15.2 If ϕ is an eigenfunction of both energy and momentum, then an￾other differential equation corresponding to Equation (15.2) is
1
c
2

∂ϕ
∂t 2
− (∇ϕ)
2 +
m2
c
2
ℏ
2
ϕ
2 = 0
Why is this a less desirable equation than the Klein–Gordon equa￾tion?
15.3 (a) If J is the Schr¨odinger probability current, show that
Z
J d
3
r = ⟨v⟩
(b) What are the units of J?
15.4 Using the Klein–Gordon equation, the continuity equation, and the
expression for J from Equation (15.10), derive the Klein–Gordon
probability density:
ρ =
iℏ
2mc2

ϕ
∗ ∂ϕ
∂t − ϕ
∂ϕ∗
∂t 
15.5 Write out explicitly the full 4 × 4 matrices corresponding to α1
and α2.
15.6 Multiply out the matrices in the Dirac equation to express the
Dirac equation as four coupled differential equations for the four
components of ψ: ψ1, ψ2, ψ3, and ψ4.362 Quantum Mechanics: An Accessible Introduction
15.7 Write down the Dirac spinor corresponding to a spin-1/2 particle
at rest with spin in the +x direction and positive energy.
15.8 (a) The general solution for the Dirac equation can be written in
the form
ψ =


ϕ1
ϕ2
χ1
χ2


e
i(p·r−Et)/ℏ
where ϕ1, ϕ2, χ1, and χ2 are numbers independent of r and t.
To take advantage of this form for the Dirac equation, use the
shorthand
ϕ =

ϕ1
ϕ2

and
χ =

χ1
χ2

Using this form for the solution, show that ϕ and χ satisfy the
coupled equations
(E − mc2
)ϕ = c(p·σ)χ
and
(E + mc2
)χ = c(p·σ)ϕ
(b) Use the results from part (a) to show that the general four￾component solution of the Dirac equation may be written as
ψ =


ϕ
c(p·σ)ϕ/(E + mc2
)

 e
i(p·r−Et)/ℏIndex
Addition
of complex numbers, 28
of linear operators, 108
of vectors, 112
Adiabatic change, 265
Adjoint operator, 117–118
Alkali metals, ground state, 328
α decay, 87
Anderson, Carl, 360
Angular frequency, 42
Angular momentum, 129–141
Angular momentum operator,
130–138
Anharmonic oscillator, 226–227
Anomalous magnetic moment, 182
Anticommuting, 356
Antimatter, 360
Antisymmetric wave function, 317,
319
Argon, ground state, 328
Atomic structure, 326–334
Aufbau principle, 327
Balmer series, 20
Balmer, Johann, 20
Basis sets, 120–122
Bell, J.S., 211–212
Beryllium, ground state, 334
Binary gates, classical computing, 345
Blackbody radiation, 3–11
Bohr atom, 19–22
Bohr magneton, 181
Bohr radius, 155
Bohr, Neils, 20
Boltzmann distribution, 8
Boltzmann’s constant, 6
Born approximation, 292–302
scattering from a delta-function
potential, 301–302
scattering from a repulsive
spherical well, 299–300
Born, Max, 51
Boron, atomic structure, 327, 330
Bose–Einstein statistics, 317
Bound states, 88–99
Bra vectors, 172
Bracket, 172
Carbon, ground state, 330–334
Central potentials, 141
Clebsch–Gordon coefficients, 205
Column vectors, 163
Commutators, 109–112
Complex conjugation, 33–34
Complex numbers, 27–34
Complex vector spaces, 113
Composition, 108
Compton effect, 14–17
Compton wavelength, 14
Computing
classical computing, 345–346
quantum computing, 344–348
363364 Quantum Mechanics: An Accessible Introduction
Copenhagen interpretation, 208–211
“Corpuscular theory” of light, 11
Cross section, scattering, 287–292
Davisson–Germer experiment, 18–19
de Broglie wavelength, 17
de Broglie, Louis, 17
Degeneracy, 129
Delta function
See also Dirac delta function
See also Kronecker delta
Delta-function potential, 301–302
Density of states, 295
Derivative operator, 35–36
adjoint of, 118
Differential cross section, 289
Dipole approximation, 278
Dipole–dipole interaction, 206–208
Dirac delta function, 172–174
Dirac equation, 355–361
Dirac notation, 170–172
Dirac probability density, 358
Dual space, 171
Eigenfunctions, 36–38
simultaneous, 110–112
Eigenvalues, 36–38
Einstein, Albert
photoelectric effect, 13–14
special relativity, 351
Einstein–Rosen–Podolsky paradox,
209
Electric field
atom in, 239–241
due to electromagnetic wave
propagation, 277
Electric quadrupole transition, 281
Electromagnetic radiation
electric field due to wave
propagation, 277
selection rules for, 276–281
Electron–positron pair annihilation,
360
Electrons
in multielectron atoms, 326–334
spin angular momentum, 180–185
spin precession, 197–201
spin-orbit coupling, 230–237
spins in a magnetic field, 228–229
spins in an oscillating magnetic
field, 275–276
Stern–Gerlach experiment,
183–185, 194–197
Everett, Hugh, 212
Exchange operator, 315–317
Expectation value, 57–58
Fermi–Dirac statistics, 317
Fermions, 317
Feynmann, Richard, 182
Fine structure, 229–237
Fine-structure constant, 233
First excited state, 65
Forbidden transitions, 276, 281
Fourier series, 121
Frequency, classical harmonic
oscillator, 96
Good quantum numbers, 112
Goudsmit, S.A., 183
Ground state, 63
Hund’s rules, 330
of alkali metals, 328
of argon, 328
of beryllium, 334
of boron, 327, 330
of carbon, 330–334
of helium, 256–261, 323–325,
328–329
of hydrogen, 149–158, 229–239, 329
of lithium, 328
of neon, 328
of noble gases, 328
of potassium, 328
of sodium, 328
H-bar (ℏ), 20
Hamiltonian operator, 60–61
Harmonic oscillator potential, 92–99
ladder operators, 138–141
Heisenberg uncertainty principle,
99–100Index 365
Helium, atomic structure, 328–329
Hermite polynomials, 96
Hermitian operators, 119
Hidden variables formulation,
211–212
Hund’s rules, 330
Hydrogen atom
allowed transitions, 276–281
energy levels, 149–158
fine structure, 229–237
hyperfine structure, 208, 236–237
wave functions, 149–158
Hyperfine structure, 208, 236–237
Identity matrix, 165
Imaginary number, 27
Infinite square well, 88–91
Inhomogeneous magnetic field,
183–184
Inner products, 113–117
in Dirac notation, 171
Interacting spins, 205–208
j-j coupling, 329
Ket vectors, 172
Kirchhoff’s law, 3
Klein–Gordon equation, 351–355
Kronecker delta, 131, 174
L-S coupling, 328
Ladder operators, 134–137
harmonic oscillator, 138–141
Lamb shift, 237–239
Lamb, Willis, 237
Land´e g factor, 246
Laplace’s equation, 149
Legendre polynomials, 149
Light, 11–17
Compton effect, 14–17
Newton’s “corpuscular theory”, 11
photoelectric effect, 12–14
wave–particle duality, 2, 17–18
Linear algebra, 107–122
Linear operators, 35–38
matrix formulation, 163–170
Linear Stark effect, 241
Lithium, atomic structure, 328
Logic gates
classical computing, 344–345
quantum, 345–348
Lyman series, 20
Magnetic dipole transition, 281
Magnetic dipole–dipole interaction,
between two particles, 206–208
Magnetic field
atom in, 241–246
electron spins in, 228–229, 275–276
Magnetic moment, 181–183
Magnetic resonance imaging (MRI),
339–343
Many worlds interpretation, 212–213
Matrix formulation, linear operators,
163–170
Matrix multiplication, 164
Matrix, adjoint of, 169
Matter, wave nature, 17–18
Measurement theory, 208–213
Modern physics, 1
Momentum, 45–47
expectation value of, 57–58
See also Angular momentum
Momentum transfer, 297
MRI (see Magnetic resonance
imaging)
Multielectron atoms, 326–334
Multiparticle Schr¨odinger equation,
313–334
multielectron atoms, 326–334
wave function for identical
particles, 313–326
Neon, ground state, 328
Newton’s “corpuscular theory”, 11
Noble gases, ground state, 328
Noninteracting spins, 202–205
Nonrelativistic probability current,
353–354
Normalization, 52
NOT gate, 348
√
NOT gate, 348366 Quantum Mechanics: An Accessible Introduction
Nuclear magnetic resonance, 343
Observables, 56
One-dimensional harmonic oscillator
potential, 92–99, 138–141
One-dimensional Schr¨odinger
equation, 48
solutions, 48–51, 71–100
One-dimensional square well, 48–51,
88–91
Operators, 35–38
linearity of, 35–36
Orbital angular momentum, 133,
143–149
Orthonormal basis, 120
Parity operator, 37–38
Partial waves, 303–309
Paschen series, 20
Paschen–Back effect, 244
Pauli exclusion principle, 317
Pauli spin matrices, 192, 356–357
Perturbation theory
time-dependent, 265–281
time-independent, 219–246
Perturbation, atomic energy levels,
229–239
Phase velocity, 43
Phipps, T.E., 184
Photoelectric effect, 12–14
Photons, 13
Planck’s constant, 9–11, 13–14
Planck, Max, on spectrum of
blackbody radiation, 8–11
Positrons, 360
Potassium, atomic structure, 328
Precession
spin precession, 197–201
Thomas precession, 231
Prime numbers, quantum algorithm
for factoring, 348
Principal quantum number, 155
Probability current, 353–354, 358
Probability density, 51, 353–354, 358
Proton magnetic moment, 236,
340–341
Quadratic Stark effect, 239–241
Quantization, origins of, 61–66
Quantum computing, 344–348
Quantum dot, 91
Quantum field theory, 182, 237
Quantum harmonic oscillator, 92–99,
138–141
Quantum numbers
good quantum numbers, 112
orbital angular momentum
quantum number, 155
principal quantum number, 155
Qubits, 345
Radial Schr¨odinger equation, 146
Radial wave function, 146
for the hydrogen atom, 156
Radiation
blackbody radiation, 3–11
See also Electromagnetic radiation
Rayleigh–Jeans formula, 7
Rectangular coordinates, Schr¨odinger
equation solution in, 126–129
Recursion relation, 95
Reduced mass, 152
Reflection probability, 81
Relativistic quantum mechanics,
351–361
Dirac equation, 355–361
Klein–Gordon equation, 351–355
Rest energy, 352
Retherford, R.C., 237
Russell–Saunders coupling, 328
Rutherford, Ernest, 19
Rydberg constant, 19–20
s-wave phase shift, 308
s-wave scattering, 303–309
Scattering, 287–309
Born approximation, 292–302
classical, from a hard sphere,
290–292
Compton scattering, 14–17
cross section, definition, 287–290
from a delta-function potential,
301–302Index 367
from an infinitely hard sphere,
308–309
one-dimensional, from
step-function potentials,
77–87
partial waves, 303–309
s-wave scattering, 303–309
three-dimensional repulsive
spherical well, 299–300
Schr¨odinger Equation
defined, 48–49
derivation, 42–48
multiparticle equation, 313–334
one-dimensional, 48–51, 71–100
radial equation, 146
solution in rectangular coordinates,
126–129
solution in spherical coordinates,
141–149
three-dimensional, 125–158
time-independent, 58–61
Schr¨odinger’s cat, 209–211
Selection rules, 276–281
Self-adjoint operator, 119
Semiconductor heterostructures, 71,
91
Separation of variables, 49–50
Shell, 326
Shor, Peter, 348
Simultaneous eigenfunctions, 110–112
Singlet state, 187
Sodium, atomic structure, 328
Spherical Bessel functions, 305
Spherical coordinates, 141–142
Schr¨odinger equation solution in,
141–149
Spherical harmonics, 148
Spin angular momentum, 179–208
evidence for, 180–185
Spin magnetic moment, 182–183,
340–341
Spin operators, 179–180
Spin precession, 197–201
Spin systems with two particles
interacting spins, 205–208
noninteracting spins, 202–205
Spin, matrix representation, 187–194
Spin-1/2 particles, 187–194
Spin–spin interaction in hydrogen,
236–237
Spin-orbit coupling, 229–237
Spin-orbit perturbation, 232
Spinor, 359
Square well
infinite square well, 88–91
two identical particles in, 320
Stark effect, 239–241
Stefan, J., 4
Stefan–Boltzmann law, 4–5
Step-function potentials, scattering
from, 77–87
Stern–Gerlach experiment, 183–185,
194–197
Strong-field Zeeman effect, 244
Subshell, 326
Symmetric wave function, 317, 319
Taylor, J.B., 184
Thomas precession, 231
Thomas, L.H., 231
Three-dimensional delta function, 174
Three-dimensional Schr¨odinger
equation, 125–158
Time-dependent perturbation theory,
265–281
derivation, 266–273
selection rules for electromagnetic
radiation, 276–281
Time-independent perturbation
theory, 219–246
atom in a magnetic field, 241–246
atom in an electric field, 239–241
derivation, 220–226
Stark effect, 239–241
Zeeman Effect, 241–246
Total angular momentum, 185–187
Total cross section, 289
Total magnetic moment, 241–243
Transition probability, 269–273
Transmission probability, 81
Triplet state, 187
Tunnel diode, 87–88368 Quantum Mechanics: An Accessible Introduction
Tunneling,, 84–88
Two-particle Schr¨odinger equation,
314
Two-particle wave function, 314–325
Two-qubit system, 345–347
Ulhenbeck, G., 183
Ultraviolet catastrophe, 8
Unbound states, 72–88
scattering from step-function
potentials, 77–88
tunneling, 84–88
Uncertainty principle, 99–100
Vacuum polarization, 237–238
Vacuum, in quantum field theory, 237
Variational principle, 251–261
helium atom and, 256–261
theory, 252–256
Vector spaces, 112–122
basis sets, 120–122
dual space, 171
inner products, 113–117
Wave function
defined, 41
for identical particles, 313–326
meaning of, 51–58
time-independent, 59–60
Wave number, 42
Wave vector, 43
Wien’s displacement law, 5–6, 10
X-rays, MRI advantages over, 343
XOR logic gate, 345–347
Zeeman effect, 241–246
Zero-point energy, 90, 96
